Bug_ID,Bug_Summary,Bug_Description
HADOOP-13925,"S3Guard: NPE when table is already populated in dynamodb and user specifies ""fs.s3a.s3guard.ddb.table.create=false""","When table is present dynamodb store and already populated, it is possible that users can specify {{fs.s3a.s3guard.ddb.table.create=false}}.  In such cases, {{DynamoDBMetadataStore.get}} would end up throwing NPE as {{table}} object may not be initialized. "
HADOOP-13379,Hadoop: Failed to set permissions of path: \tmp\hadoop-User\mapred\staging\ while running testdriver from eclipse,"Hadoop: Failed to set permissions of path: \tmp\hadoop-User\mapred\staging\

I am trying to work through this tutorial about hadoop and eclipse: http://v-lad.org/Tutorials/Hadoop/. It went fine until the last step ""Running Hadoop Project"". Here, when I run the project in Eclipse, I get the error:

14/11/26 16:25:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/11/26 16:25:24 ERROR security.UserGroupInformation: PriviledgedActionException as:User cause:java.io.IOException: Failed to set permissions of path: \tmp\hadoop-User\mapred\staging\User660196934\.staging to 0700
java.io.IOException: Failed to set permissions of path: \tmp\hadoop-User\mapred\staging\User660196934\.staging to 0700
    at org.apache.hadoop.fs.FileUtil.checkReturnValue(FileUtil.java:691)
    at org.apache.hadoop.fs.FileUtil.setPermission(FileUtil.java:664)
    at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:514)
    at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:349)
    at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:193)
    at org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:126)
    at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:942)
    at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:936)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Unknown Source)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
    at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:936)
    at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:910)
    at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1353)
    at TestDriver.main(TestDriver.java:41)
I had earlier this permission issue (taskTracker could not start because ""Failed to set permissions"" ), but I resolved it using this patch: https://github.com/congainc/patch-hadoop_7682-1.0.x-win. I don't understand why this doesn't work when running the project form Eclipse. How can I solve this issue?

Hadoop-version is 1.2.1


Core-Site.xml

<?xml version=""1.0""?>
<?xml-stylesheet type=""text/xsl"" href=""configuration.xsl""?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<property>
<name>fs.default.name</name>
<value>hdfs://localhost:50000</value>
</property>
 <property>
        <name>fs.file.impl</name>
        <value>com.conga.services.hadoop.patch.HADOOP_7682.WinLocalFileSystem</value>
        <description>Enables patch for issue HADOOP-7682 on Windows</description>
    </property>
<property>
<name>hadoop.tmp.dir</name>
 <value>/tmp/hadoop-${USER}/</value>
 <description>A base for other temporary directories.</description>
</property>
</configuration>
"
HADOOP-13362,DefaultMetricsSystem leaks the source name when a source unregisters,"Ran across a nodemanager that was spending most of its time in GC.  Upon examination of the heap most of the memory was going to the map of names in org.apache.hadoop.metrics2.lib.UniqueNames.  In this case the map had almost 2 million entries.  Looking at a few of the map showed entries like ""ContainerResource_container_e01_1459548490386_8560138_01_002020"", ""ContainerResource_container_e01_1459548490386_2378745_01_000410"", etc.

Looks like the ContainerMetrics for each container will cause a unique name to be registered with UniqueNames and the name will never be unregistered."
HADOOP-12736,TestTimedOutTestsListener#testThreadDumpAndDeadlocks sometimes times out,"Saw this test failure today, the {{@Test(timeout=500)}} seems too aggressive to me.
{noformat}
testThreadDumpAndDeadlocks(org.apache.hadoop.test.TestTimedOutTestsListener)  Time elapsed: 0.521 sec  <<< ERROR!
java.lang.Exception: test timed out after 500 milliseconds
	at jdk.internal.org.objectweb.asm.ByteVector.putShort(ByteVector.java:147)
	at jdk.internal.org.objectweb.asm.ClassWriter.toByteArray(ClassWriter.java:942)
	at java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCodeBytes(InvokerBytecodeGenerator.java:727)
	at java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCode(InvokerBytecodeGenerator.java:618)
	at java.lang.invoke.LambdaForm.compileToBytecode(LambdaForm.java:654)
	at java.lang.invoke.LambdaForm.prepare(LambdaForm.java:635)
	at java.lang.invoke.MethodHandle.<init>(MethodHandle.java:461)
	at java.lang.invoke.BoundMethodHandle.<init>(BoundMethodHandle.java:56)
	at java.lang.invoke.SimpleMethodHandle.<init>(SimpleMethodHandle.java:37)
	at java.lang.invoke.SimpleMethodHandle.make(SimpleMethodHandle.java:41)
	at java.lang.invoke.LambdaForm.createIdentityForms(LambdaForm.java:1778)
	at java.lang.invoke.LambdaForm.<clinit>(LambdaForm.java:1833)
	at java.lang.invoke.DirectMethodHandle.makePreparedLambdaForm(DirectMethodHandle.java:222)
	at java.lang.invoke.DirectMethodHandle.preparedLambdaForm(DirectMethodHandle.java:187)
	at java.lang.invoke.DirectMethodHandle.preparedLambdaForm(DirectMethodHandle.java:176)
	at java.lang.invoke.DirectMethodHandle.make(DirectMethodHandle.java:83)
	at java.lang.invoke.MethodHandles$Lookup.getDirectMethodCommon(MethodHandles.java:1656)
	at java.lang.invoke.MethodHandles$Lookup.getDirectMethodNoSecurityManager(MethodHandles.java:1613)
	at java.lang.invoke.MethodHandles$Lookup.getDirectMethodForConstant(MethodHandles.java:1798)
	at java.lang.invoke.MethodHandles$Lookup.linkMethodHandleConstant(MethodHandles.java:1747)
	at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:477)
	at java.lang.UNIXProcess$Platform.get(UNIXProcess.java:155)
	at java.lang.UNIXProcess.<clinit>(UNIXProcess.java:168)
	at java.lang.ProcessImpl.start(ProcessImpl.java:130)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:868)
	at org.apache.hadoop.util.Shell.run(Shell.java:838)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1117)
	at org.apache.hadoop.util.Shell.checkIsBashSupported(Shell.java:716)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:705)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:98)
	at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
	at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:62)
	at org.apache.hadoop.test.TestTimedOutTestsListener.testThreadDumpAndDeadlocks(TestTimedOutTestsListener.java:163)
{noformat}"
HADOOP-12482,Race condition in JMX cache update,"updateJmxCache() was updated in HADOOP-11301. However the patch introduced a race condition. In updateJmxCache() function in MetricsSourceAdapter.java:

{code:java}
  private void updateJmxCache() {
    boolean getAllMetrics = false;
    synchronized (this) {
      if (Time.now() - jmxCacheTS >= jmxCacheTTL) {
        // temporarilly advance the expiry while updating the cache
        jmxCacheTS = Time.now() + jmxCacheTTL;
        if (lastRecs == null) {
          getAllMetrics = true;
        }
      } else {
        return;
      }

      if (getAllMetrics) {
        MetricsCollectorImpl builder = new MetricsCollectorImpl();
        getMetrics(builder, true);
      }

      updateAttrCache();
      if (getAllMetrics) {
        updateInfoCache();
      }
      jmxCacheTS = Time.now();
      lastRecs = null; // in case regular interval update is not running
    }
  }
{code}

Notice that getAllMetrics is set to true when:
# jmxCacheTTL has passed
# lastRecs == null

lastRecs is set to null in the same function, but gets reassigned by getMetrics().

However getMetrics() can be called from a different thread:
# MetricsSystemImpl.onTimerEvent()
# MetricsSystemImpl.publishMetricsNow()

Consider the following sequence:
# updateJmxCache() is called by getMBeanInfo() from a thread getting cached info. 
** lastRecs is set to null.
# metrics sources is updated with new value/field.
# getMetrics() is called by publishMetricsNow() or onTimerEvent() from a different thread getting the latest metrics. 
** lastRecs is updated (!= null).
# jmxCacheTTL passed.
# updateJmxCache() is called again via getMBeanInfo().
** However because lastRecs is already updated (!= null), getAllMetrics will not be set to true. So updateInfoCache() is not called and getMBeanInfo() returns the old cached info.

We ran into this issue on a cluster where a new metric did not get published until much later.

The case can be made worse by a periodic call to getMetrics() (driven by an external program or script). In such case getMBeanInfo() may never be able to retrieve the new record.

The desired behavior should be that updateJmxCache() will guarantee to call updateInfoCache() once after jmxCacheTTL, if lastRecs has been set to null by updateJmxCache() itself."
HADOOP-11868,Invalid user logins trigger large backtraces in server log,"{code}
WARN sso.CookieValidatorHelpers: Cookie has expired by 25364187 msec
WARN server.AuthenticationFilter: Authentication exception: Invalid Cookie
166 org.apache.hadoop.security.authentication.client.AuthenticationException: Invalid Bouncer Cookie
167     at KerberosAuthenticationHandler.bouncerAuthenticate(KerberosAuthenticationHandler.java:94)
168     at AuthenticationHandler.authenticate(KerberosAuthenticationHandler.java:82)
169     at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:507)
170     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
171     at org.apache.hadoop.yarn.server.timeline.webapp.CrossOriginFilter.doFilter(CrossOriginFilter.java:95)
172     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
173     at org.mortbay.servlet.UserAgentFilter.doFilter(UserAgentFilter.java:78)
174     at GzipFilter.doFilter(GzipFilter.java:188)
175     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
176     at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1224)
177     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
178     at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
179     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
180     at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
181     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
182     at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
183     at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
184     at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
185     at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
186     at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
187     at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
188     at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
189     at org.mortbay.jetty.Server.handle(Server.java:326)
190     at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
191     at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
192     at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
193     at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
194     at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
195     at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
196     at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
 WARN sso.CookieValidatorHelpers: Cookie has expired by 25373197 msec
{code}"
HADOOP-11724,DistCp throws NPE when the target directory is root.,"Distcp throws NPE when the target directory is root. It is due to {{CopyCommitter#cleanupTempFiles}} attempts to delete parent directory of root, which is {{null}}:

{code}
$ hadoop distcp pom.xml hdfs://localhost/
15/03/17 11:17:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/03/17 11:17:45 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, maxMaps=20, sslConfigurationFile='null', copyStrategy='uniformsize', sourceFileListing=null, sourcePaths=[pom.xml], targetPath=hdfs://localhost/, targetPathExists=true, preserveRawXattrs=false}
15/03/17 11:17:45 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/03/17 11:17:45 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/03/17 11:17:45 INFO Configuration.deprecation: io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
15/03/17 11:17:45 INFO Configuration.deprecation: io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
15/03/17 11:17:45 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/03/17 11:17:45 INFO mapreduce.JobSubmitter: number of splits:1
15/03/17 11:17:45 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local992233322_0001
15/03/17 11:17:46 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/03/17 11:17:46 INFO tools.DistCp: DistCp job-id: job_local992233322_0001
15/03/17 11:17:46 INFO mapreduce.Job: Running job: job_local992233322_0001
15/03/17 11:17:46 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/03/17 11:17:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/03/17 11:17:46 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
15/03/17 11:17:46 INFO mapred.LocalJobRunner: Waiting for map tasks
15/03/17 11:17:46 INFO mapred.LocalJobRunner: Starting task: attempt_local992233322_0001_m_000000_0
15/03/17 11:17:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/03/17 11:17:46 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
15/03/17 11:17:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null
15/03/17 11:17:46 INFO mapred.MapTask: Processing split: file:/tmp/hadoop/mapred/staging/lei2046334351/.staging/_distcp-1889397390/fileList.seq:0+220
15/03/17 11:17:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/03/17 11:17:46 INFO mapred.CopyMapper: Copying file:/Users/lei/work/cloudera/s3a_cp_target/pom.xml to hdfs://localhost/pom.xml
15/03/17 11:17:46 INFO mapred.CopyMapper: Skipping copy of file:/Users/lei/work/cloudera/s3a_cp_target/pom.xml to hdfs://localhost/pom.xml
15/03/17 11:17:46 INFO mapred.LocalJobRunner:
15/03/17 11:17:46 INFO mapred.Task: Task:attempt_local992233322_0001_m_000000_0 is done. And is in the process of committing
15/03/17 11:17:46 INFO mapred.LocalJobRunner:
15/03/17 11:17:46 INFO mapred.Task: Task attempt_local992233322_0001_m_000000_0 is allowed to commit now
15/03/17 11:17:46 INFO output.FileOutputCommitter: Saved output of task 'attempt_local992233322_0001_m_000000_0' to file:/tmp/hadoop/mapred/staging/lei2046334351/.staging/_distcp-1889397390/_logs/_temporary/0/task_local992233322_0001_m_000000
15/03/17 11:17:46 INFO mapred.LocalJobRunner: Copying file:/Users/lei/work/cloudera/s3a_cp_target/pom.xml to hdfs://localhost/pom.xml
15/03/17 11:17:46 INFO mapred.Task: Task 'attempt_local992233322_0001_m_000000_0' done.
15/03/17 11:17:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local992233322_0001_m_000000_0
15/03/17 11:17:46 INFO mapred.LocalJobRunner: map task executor complete.
15/03/17 11:17:46 INFO mapred.CopyCommitter: Remove parent: null for hdfs://localhost/
15/03/17 11:17:46 WARN mapred.CopyCommitter: Unable to cleanup temp files
java.lang.NullPointerException
	at org.apache.hadoop.fs.Path.<init>(Path.java:104)
	at org.apache.hadoop.fs.Path.<init>(Path.java:93)
	at org.apache.hadoop.tools.mapred.CopyCommitter.deleteAttemptTempFiles(CopyCommitter.java:141)
	at org.apache.hadoop.tools.mapred.CopyCommitter.cleanupTempFiles(CopyCommitter.java:130)
	at org.apache.hadoop.tools.mapred.CopyCommitter.commitJob(CopyCommitter.java:83)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:538)
15/03/17 11:17:46 INFO mapred.CopyCommitter: Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/lei2046334351/.staging/_distcp-1889397390
15/03/17 11:17:47 INFO mapreduce.Job: Job job_local992233322_0001 running in uber mode : false
15/03/17 11:17:47 INFO mapreduce.Job:  map 100% reduce 0%
15/03/17 11:17:47 INFO mapreduce.Job: Job job_local992233322_0001 completed successfully
15/03/17 11:17:47 INFO mapreduce.Job: Counters: 22
	File System Counters
		FILE: Number of bytes read=103917
		FILE: Number of bytes written=363277
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=163577856
	File Input Format Counters
		Bytes Read=252
	File Output Format Counters
		Bytes Written=70
	org.apache.hadoop.tools.mapred.CopyMapper$Counter
		BYTESSKIPPED=23491
		SKIP=1
{code}

The distcp task can still success. "
HADOOP-11714,Add more trace log4j messages to SpanReceiverHost,Add more trace log4j messages to SpanReceiverHost
HADOOP-11526,Memory leak in Bzip2Compressor and Bzip2Decompressor,"The use of JNI's GetStringUTFChars should be paired with ReleaseStringUTFChars or else the utf-8 char* created by Java's JNI implementation is leaked. It isn't in Bzip2Decompressor.c:

https://apache.googlesource.com/hadoop-common/+/refs/heads/trunk/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/bzip2/Bzip2Decompressor.c#45

A less error-prone way of handling JNI resources like local references and UTF strings is to use a smart pointer like the Apache licensed code in Android's ScopedLocalRef and ScopedUtfChars:

https://android.googlesource.com/platform/libnativehelper/+/jb-mr1.1-dev-plus-aosp/include/nativehelper/ScopedLocalRef.h
https://android.googlesource.com/platform/libnativehelper/+/jb-mr1.1-dev-plus-aosp/include/nativehelper/ScopedUtfChars.h"
HADOOP-11498,Bump the version of HTrace to 3.1.0-incubating,The package is renamed from org.htrace to org.apache.htrace.
HADOOP-11494,Lock acquisition on WrappedInputStream#unwrappedRpcBuffer may race with another thread,"In SaslRpcClient, starting at line 576:
{code}
    public int read(byte[] buf, int off, int len) throws IOException {
      synchronized(unwrappedRpcBuffer) {
        // fill the buffer with the next RPC message
        if (unwrappedRpcBuffer.remaining() == 0) {
          readNextRpcPacket();
        }
{code}
readNextRpcPacket() may assign another ByteBuffer to unwrappedRpcBuffer, making the lock on previous ByteBuffer not useful."
HADOOP-11446,S3AOutputStream should use shared thread pool to avoid OutOfMemoryError,"When working with Terry Padgett who used s3a for hbase snapshot, the following issue was uncovered.
Here is part of the output including the OOME when hbase snapshot is exported to s3a (nofile ulimit was increased to 102400):
{code}
2014-12-19 13:15:03,895 INFO  [main] s3a.S3AFileSystem: OutputStream for key 'FastQueryPOC/2014-12-11/EVENT1-IDX-snapshot/.hbase-snapshot/.tmp/EVENT1_IDX_snapshot_2012_12_11/    650a5678810fbdaa91809668d11ccf09/.regioninfo' closed. Now beginning upload
2014-12-19 13:15:03,895 INFO  [main] s3a.S3AFileSystem: Minimum upload part size: 16777216 threshold2147483647
Exception in thread ""main"" java.lang.OutOfMemoryError: unable to create new native thread
        at java.lang.Thread.start0(Native Method)
        at java.lang.Thread.start(Thread.java:713)
        at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:949)
        at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1360)
        at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:132)
        at com.amazonaws.services.s3.transfer.internal.UploadMonitor.<init>(UploadMonitor.java:129)
        at com.amazonaws.services.s3.transfer.TransferManager.upload(TransferManager.java:449)
        at com.amazonaws.services.s3.transfer.TransferManager.upload(TransferManager.java:382)
        at org.apache.hadoop.fs.s3a.S3AOutputStream.close(S3AOutputStream.java:127)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:54)
        at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:112)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:366)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:356)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:356)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:338)
        at org.apache.hadoop.hbase.snapshot.ExportSnapshot.run(ExportSnapshot.java:791)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.hbase.snapshot.ExportSnapshot.innerMain(ExportSnapshot.java:882)
        at org.apache.hadoop.hbase.snapshot.ExportSnapshot.main(ExportSnapshot.java:886)
{code}
In S3AOutputStream#close():
{code}
      TransferManager transfers = new TransferManager(client);
{code}
This results in each TransferManager creating its own thread pool, leading to the OOME.
One solution is to pass shared thread pool to TransferManager."
HADOOP-11414,FileBasedIPList#readLines() can leak file descriptors,"{code}
          Reader fileReader = new InputStreamReader(
              new FileInputStream(file), Charsets.UTF_8);
          BufferedReader bufferedReader = new BufferedReader(fileReader);
          List<String> lines = new ArrayList<String>();
          String line = null;
          while ((line = bufferedReader.readLine()) != null) {
            lines.add(line);
          }
          bufferedReader.close();
{code}
Since bufferedReader.readLine() may throw IOE, so the close of bufferedReader should be enclosed within finally block."
HADOOP-11409,FileContext.getFileContext can stack overflow if default fs misconfigured,"If the default filesystem is misconfigured such that it doesn't have a scheme then FileContext.getFileContext(URI, Configuration) will call FileContext.getFileContext(Configuration) which in turn calls the former and we loop until the stack explodes."
HADOOP-11368,Fix SSLFactory truststore reloader thread leak in KMSClientProvider,"When a {{KMSClientProvider}} is initialized in _ssl_ mode, It  initializes a {{SSLFactory}} object. This in-turn creates an instance of {{ReloadingX509TrustManager}} which, on initialization, starts a trust store reloader thread.

It is noticed that over time, as a number of short lived {{KMSClientProvider}} instances are created and destroyed, the trust store manager threads are not interrupted/killed and remain in TIMED_WAITING state. A Thread dump shows multiple:
{noformat}
""Truststore reloader thread"" daemon prio=10 tid=0x00007fb1cf942800 nid=0x4e99 waiting on condition [0x00007fb0485f5000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.run(ReloadingX509TrustManager.java:189)
        at java.lang.Thread.run(Thread.java:662)

   Locked ownable synchronizers:
        - None
{noformat}
 
"
HADOOP-11361,Fix a race condition in MetricsSourceAdapter.updateJmxCache,"{noformat}
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.updateAttrCache(MetricsSourceAdapter.java:247)
	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.updateJmxCache(MetricsSourceAdapter.java:177)
	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getAttribute(MetricsSourceAdapter.java:102)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)
{noformat}"
HADOOP-11358,Tests for encryption/decryption with IV calculation overflow,"As discussed in HADOOP-11343, add more tests to cover encryption/decryption with IV calculation overflow"
HADOOP-11355,"When accessing data in HDFS and the key has been deleted, a Null Pointer Exception is shown.","When using the KMS with the file based keystore we can see this error when trying to access an encryption zone that got his key deleted:
{noformat}
KMSClientProvider[http://foo.bar.com:16000/kms/v1/] has been updated.
hdfs@foo:~$ hadoop fs -tail /user/systest/zones/n3bg0hfvyvjwvwuc/terasort/part-00000
-tail: Fatal internal error
java.lang.NullPointerException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
        at org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:157)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:484)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:442)
        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.decryptEncryptedKey(KMSClientProvider.java:716)
        at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.decryptEncryptedKey(KeyProviderCryptoExtension.java:388)
        at org.apache.hadoop.hdfs.DFSClient.decryptEncryptedDataEncryptionKey(DFSClient.java:1317)
        at org.apache.hadoop.hdfs.DFSClient.createWrappedInputStream(DFSClient.java:1384)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:303)
        at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:297)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:297)
        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
        at org.apache.hadoop.fs.shell.Tail.dumpFromOffset(Tail.java:92)
        at org.apache.hadoop.fs.shell.Tail.processPath(Tail.java:73)
        at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:306)
        at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:278)
        at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:260)
        at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:244)
        at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190)
        at org.apache.hadoop.fs.shell.Command.run(Command.java:154)
        at org.apache.hadoop.fs.FsShell.run(FsShell.java:287)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
        at org.apache.hadoop.fs.FsShell.main(FsShell.java:340)
{noformat}
"
HADOOP-11349,RawLocalFileSystem leaks file descriptor while creating a file if creat succeeds but chmod fails.,"{{RawLocalFileSystem}} currently implements some file creation operations as a sequence of 2 syscalls: create the file, followed by setting its permissions.  If creation succeeds, but then setting permission causes an exception to be thrown, then there is no attempt to close the previously opened file, resulting in a file descriptor leak."
HADOOP-11343,Overflow is not properly handled in caclulating final iv for AES CTR,"In the AesCtrCryptoCodec calculateIV, as the init IV is a random generated 16 bytes, 

final byte[] iv = new byte[cc.getCipherSuite().getAlgorithmBlockSize()];
      cc.generateSecureRandom(iv);

Then the following calculation of iv and counter on 8 bytes (64bit) space would easily cause overflow and this overflow gets lost.  The result would be the 128 bit data block was encrypted with a wrong counter and cannot be decrypted by standard aes-ctr.

{code}
/**
   * The IV is produced by adding the initial IV to the counter. IV length 
   * should be the same as {@link #AES_BLOCK_SIZE}
   */
  @Override
  public void calculateIV(byte[] initIV, long counter, byte[] IV) {
    Preconditions.checkArgument(initIV.length == AES_BLOCK_SIZE);
    Preconditions.checkArgument(IV.length == AES_BLOCK_SIZE);
    
    System.arraycopy(initIV, 0, IV, 0, CTR_OFFSET);
    long l = 0;
    for (int i = 0; i < 8; i++) {
      l = ((l << 8) | (initIV[CTR_OFFSET + i] & 0xff));
    }
    l += counter;
    IV[CTR_OFFSET + 0] = (byte) (l >>> 56);
    IV[CTR_OFFSET + 1] = (byte) (l >>> 48);
    IV[CTR_OFFSET + 2] = (byte) (l >>> 40);
    IV[CTR_OFFSET + 3] = (byte) (l >>> 32);
    IV[CTR_OFFSET + 4] = (byte) (l >>> 24);
    IV[CTR_OFFSET + 5] = (byte) (l >>> 16);
    IV[CTR_OFFSET + 6] = (byte) (l >>> 8);
    IV[CTR_OFFSET + 7] = (byte) (l);
  }
{code}"
HADOOP-11333,Fix deadlock in DomainSocketWatcher when the notification pipe is full,"I found some of our DataNodes will run ""exceeds the limit of concurrent xciever"", the limit is 4K.

After check the stack, I suspect that org.apache.hadoop.net.unix.DomainSocket.writeArray0 which called by DomainSocketWatcher.kick stuck:
{quote}
""DataXceiver for client unix:/var/run/hadoop-hdfs/dn [Waiting for operation #1]"" daemon prio=10 tid=0x00007f55c5576000 nid=0x385d waiting on condition [0x00007f558d5d4000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x0000000740df9c90> (a java.util.concurrent.locks.ReentrantLock$NonfairSync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:867)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1197)
        at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:214)
        at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:290)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.add(DomainSocketWatcher.java:286)
        at org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.createNewMemorySegment(ShortCircuitRegistry.java:283)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.requestShortCircuitShm(DataXceiver.java:413)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opRequestShortCircuitShm(Receiver.java:172)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:92)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
--
""DataXceiver for client unix:/var/run/hadoop-hdfs/dn [Waiting for operation #1]"" daemon prio=10 tid=0x00007f7de034c800 nid=0x7b7 runnable [0x00007f7db06c5000]
   java.lang.Thread.State: RUNNABLE
	at org.apache.hadoop.net.unix.DomainSocket.writeArray0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.access$300(DomainSocket.java:45)
	at org.apache.hadoop.net.unix.DomainSocket$DomainOutputStream.write(DomainSocket.java:589)
	at org.apache.hadoop.net.unix.DomainSocketWatcher.kick(DomainSocketWatcher.java:350)
	at org.apache.hadoop.net.unix.DomainSocketWatcher.add(DomainSocketWatcher.java:303)
	at org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.createNewMemorySegment(ShortCircuitRegistry.java:283)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.requestShortCircuitShm(DataXceiver.java:413)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opRequestShortCircuitShm(Receiver.java:172)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:92)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
	at java.lang.Thread.run(Thread.java:745)

""DataXceiver for client unix:/var/run/hadoop-hdfs/dn [Waiting for operation #1]"" daemon prio=10 tid=0x00007f55c5574000 nid=0x377a waiting on condition [0x00007f558d7d6000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x0000000740df9cb0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.add(DomainSocketWatcher.java:306)
        at org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.createNewMemorySegment(ShortCircuitRegistry.java:283)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.requestShortCircuitShm(DataXceiver.java:413)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opRequestShortCircuitShm(Receiver.java:172)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:92)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:232)
        at java.lang.Thread.run(Thread.java:745)
             

""Thread-163852"" daemon prio=10 tid=0x00007f55c811c800 nid=0x6757 runnable [0x00007f55aef6e000]
   java.lang.Thread.State: RUNNABLE 
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$800(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$1.run(DomainSocketWatcher.java:457)
        at java.lang.Thread.run(Thread.java:745)
{quote}"
HADOOP-11266,Remove no longer supported activation properties for packaging from pom,"According to HADOOP-8925, packaging rpm and deb are no longer supported -- both options should be removed from the pom.
"
HADOOP-11228,winutils task: unsecure path should not call AddNodeManagerAndUserACEsToObject,winutils task create path is broken after YARN-2198
HADOOP-11186,"documentation should talk about hadoop.htrace.spanreceiver.classes, not hadoop.trace.spanreceiver.classes","The documentation should talk about hadoop.htrace.spanreceiver.classes, not hadoop.trace.spanreceiver.classes (note the H)"
HADOOP-11183,Memory-based S3AOutputstream,"Currently s3a buffers files on disk(s) before uploading. This JIRA investigates adding a memory-based upload implementation.

The motivation is evidently performance: this would be beneficial for users with high network bandwidth to S3 (EC2?) or users that run Hadoop directly on an S3-compatible object store (FYI: my contributions are made in name of Amplidata). "
HADOOP-11172,Improve error message in Shell#runCommand on OutOfMemoryError,"TestWebHdfsFileSystemContract failed with the following error. But the real reason is not. Instead, it's because of ""max user processes"" of ulimit setting is too low. Need a more informative error message here.

{code}
2014-09-04 20:09:08,396 ERROR mortbay.log (Slf4jLog.java:warn(87)) - /webhdfs/v1/test/testSeek/zero
java.lang.OutOfMemoryError: unable to create new native thread
        at java.lang.Thread.start0(Native Method)
        at java.lang.Thread.start(Thread.java:693)
        at org.apache.hadoop.hdfs.LeaseRenewer.put(LeaseRenewer.java:320)
        at org.apache.hadoop.hdfs.DFSClient.beginFileLease(DFSClient.java:789)
        at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1605)
        at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1526)
        at org.apache.hadoop.hdfs.server.datanode.web.resources.DatanodeWebHdfsMethods.put(DatanodeWebHdfsMethods.java:234)
        at org.apache.hadoop.hdfs.server.datanode.web.resources.DatanodeWebHdfsMethods.access$000(DatanodeWebHdfsMethods.java:86)
        at org.apache.hadoop.hdfs.server.datanode.web.resources.DatanodeWebHdfsMethods$1.run(DatanodeWebHdfsMethods.java:205)
        at org.apache.hadoop.hdfs.server.datanode.web.resources.DatanodeWebHdfsMethods$1.run(DatanodeWebHdfsMethods.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1626)
        at org.apache.hadoop.hdfs.server.datanode.web.resources.DatanodeWebHdfsMethods.put(DatanodeWebHdfsMethods.java:202)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)
        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)
        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)
        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)
        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)
        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)
        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)
        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)
        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)
        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)
        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:699)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1203)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.messageComplete(HttpConnection.java:959)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:792)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
{code}

"
HADOOP-11143,NetUtils.wrapException loses inner stack trace on BindException,"{{NetUtils.wrapException}} is designed to aid debugging by including exception diagnostics in the wrapped & relayed exception.

When a BindException is caught, we build the new exception  but don't include the original as the inner cause.

this means it doesn't get logged, and while the host:port problem may be identifiable, the bit of the code playing up is now harder to track down.
"
HADOOP-11110,JavaKeystoreProvider should not report a key as created if it was not flushed to the backing file,"Testing with the KMS backed by JKS reveals the following:

{noformat}
[root@dlo-4 ~]# hadoop key create testkey -provider kms://http@localhost:16000/kms
testkey has not been created. Mkdirs failed to create file:xxxxx
....<stack trace>....

[root@dlo-4 ~]# hadoop key list -provider kms://http@localhost:16000/kms
Listing keys for KeyProvider: KMSClientProvider[http://localhost:16000/kms/v1/]
testkey
{noformat}

The JKS still has the key in memory and serves it up, but will disappear if the KMS is restarted since it's not flushed to the file."
HADOOP-11105,MetricsSystemImpl could leak memory in registered callbacks,"In {{MetricsSystemImpl.register(final String name, final String description, final T sink)}} method, we will also add a callback function to the {{callbacks}} array list. However, upon unregistering, the callback function is not removed from the list in existing code. As a result, the memory allocated for the callback function could accumulate in the {{MetricsSystemImpl}} list. In one of our cluster, we have seen a case where there are about 874 MB memory retained by {{MetricsSystemImpl}}."
HADOOP-11098,[JDK8] Max Non Heap Memory default changed between JDK7 and 8,"I noticed this because the NameNode UI shows ""Max Non Heap Memory"" which after some digging I found correlates to MaxDirectMemorySize.

JDK7
{noformat}
Heap Memory used 16.75 GB of 23 GB Heap Memory. Max Heap Memory is 23.7 GB.
Non Heap Memory used 57.32 MB of 67.38 MB Commited Non Heap Memory. Max Non Heap Memory is 130 MB. 
{noformat}

JDK8
{noformat}
Heap Memory used 3.02 GB of 7.65 GB Heap Memory. Max Heap Memory is 23.7 GB.
Non Heap Memory used 103.12 MB of 104.41 MB Commited Non Heap Memory. Max Non Heap Memory is -1 B. 
{noformat}

More information in first comment."
HADOOP-11077,NPE if hosts not specified in ProxyUsers,"When using the TokenDelegationAuthenticationFilter, I noticed if I don't specify the hosts for a user/groups proxy user and then try to authenticate, I get an NPE rather than an AuthorizationException."
HADOOP-11056,OsSecureRandom.setConf() might leak file descriptors.,"OsSecureRandom.setConf() might leak resource, the stream is not closed when:

1. if setConf() is called a second time
2. if {{fillReservoir(0);}} throw exception.

 "
HADOOP-11014,Potential resource leak in JavaKeyStoreProvider due to unclosed stream,"From hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/JavaKeyStoreProvider.java :
{code}
  private void writeToNew(Path newPath) throws IOException {
    FSDataOutputStream out =
        FileSystem.create(fs, newPath, permissions);
    try {
      keyStore.store(out, password);
    } catch (KeyStoreException e) {
      throw new IOException(""Can't store keystore "" + this, e);
    } catch (NoSuchAlgorithmException e) {
      throw new IOException(
          ""No such algorithm storing keystore "" + this, e);
    } catch (CertificateException e) {
      throw new IOException(
          ""Certificate exception storing keystore "" + this, e);
    }
    out.close();
{code}
IOException is not among the catch blocks.
According to http://docs.oracle.com/javase/7/docs/api/java/security/KeyStore.html#store(java.io.OutputStream,%20char[]), IOException may be thrown from the store() call. In that case, out would be left unclosed.

In loadFromPath():
{code}
    keyStore.load(fs.open(p), password);
{code}
The InputStream should be closed upon return from load()"
HADOOP-10886,CryptoCodec#getCodecclasses throws NPE when configurations not loaded.,"There are some test cases which will not load the xml defaults. In this case, CryptoCodec#getCodecclasses will fail with NPE.

{noformat}
java.lang.NullPointerException: null
        at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:187)
        at com.google.common.base.Splitter.split(Splitter.java:371)
        at org.apache.hadoop.crypto.CryptoCodec.getCodecClasses(CryptoCodec.java:100)
        at org.apache.hadoop.crypto.CryptoCodec.getInstance(CryptoCodec.java:54)
        at org.apache.hadoop.crypto.CryptoCodec.getInstance(CryptoCodec.java:91)
        at org.apache.hadoop.crypto.TestCryptoStreamsForLocalFS.init(TestCryptoStreamsForLocalFS.java:53)
{noformat}

https://builds.apache.org/job/Hadoop-fs-encryption-nightly/71/"
HADOOP-10840,Fix OutOfMemoryError caused by metrics system in Azure File System,"In Hadoop 2.x the Hadoop File System framework changed and no cache is implemented (refer to HADOOP-6356). This means for every WASB access, a new NativeAzureFileSystem is created, along which a Metrics source created and added to MetricsSystemImpl. Over time the sources accumulated, eating memory and causing Java OutOfMemoryError.

The fix is to utilize the unregisterSource() method added to MetricsSystem in HADOOP-10839."
HADOOP-10645,TestKMS fails because race condition writing acl files,"The {{TestKMS#testACLs()}} test randomly fails because a race condition while updating the acls files which is hot-reloaded.

We should disable the background thread that does the reload and do it manually for the purposes of the test."
HADOOP-10630,Possible race condition in RetryInvocationHandler,"In one of our system tests with NameNode HA setup, we ran 300 threads in LoadGenerator. While one of the NameNodes was already in the active state and started to serve, we still saw one of the client thread failed all the retries in a 20 seconds window. In the meanwhile, we saw a lot of following warning msg in the log:
{noformat}
WARN retry.RetryInvocationHandler: A failover has occurred since the start of this method invocation attempt.
{noformat}

After checking the code, we see the following code in RetryInvocationHandler:
{code}
  while (true) {
      // The number of times this invocation handler has ever been failed over,
      // before this method invocation attempt. Used to prevent concurrent
      // failed method invocations from triggering multiple failover attempts.
      long invocationAttemptFailoverCount;
      synchronized (proxyProvider) {
        invocationAttemptFailoverCount = proxyProviderFailoverCount;
      }
      ......
      if (action.action == RetryAction.RetryDecision.FAILOVER_AND_RETRY) {
            // Make sure that concurrent failed method invocations only cause a
            // single actual fail over.
            synchronized (proxyProvider) {
              if (invocationAttemptFailoverCount == proxyProviderFailoverCount) {
                proxyProvider.performFailover(currentProxy.proxy);
                proxyProviderFailoverCount++;
                currentProxy = proxyProvider.getProxy();
              } else {
                LOG.warn(""A failover has occurred since the start of this method""
                    + "" invocation attempt."");
              }
            }
            invocationFailoverCount++;
          }
     ......
{code}

We can see we refresh the value of currentProxy only when the thread performs the failover (while holding the monitor of the proxyProvider). Because ""currentProxy"" is not volatile,  a thread that does not perform the failover (in which case it will log the warning msg) may fail to get the new value of currentProxy."
HADOOP-10622,Shell.runCommand can deadlock,Ran into a deadlock in Shell.runCommand.  Stacktrace details to follow.
HADOOP-10583,bin/hadoop key throws NPE with no args and assorted other fixups,bin/hadoop key throws NPE.
HADOOP-10562,Namenode exits on exception without printing stack trace in AbstractDelegationTokenSecretManager,Not printing the stack trace makes debugging harder.
HADOOP-10542,Potential null pointer dereference in Jets3tFileSystemStore#retrieveBlock(),"{code}
      in = get(blockToKey(block), byteRangeStart);
      out = new BufferedOutputStream(new FileOutputStream(fileBlock));
      byte[] buf = new byte[bufferSize];
      int numRead;
      while ((numRead = in.read(buf)) >= 0) {
{code}
get() may return null.
The while loop dereferences in without null check."
HADOOP-10533,S3 input stream NPEs in MapReduce job,"I'm running a wordcount MR as follows

hadoop jar WordCount.jar wordcount.WordCountDriver s3n://bucket/wordcount/input s3n://bucket/wordcount/output
 
s3n://bucket/wordcount/input is a s3 object that contains other input files.

However I get following NPE error

12/10/02 18:56:23 INFO mapred.JobClient:  map 0% reduce 0%
12/10/02 18:56:54 INFO mapred.JobClient:  map 50% reduce 0%
        12/10/02 18:56:56 INFO mapred.JobClient: Task Id : attempt_201210021853_0001_m_000001_0, Status : FAILED
java.lang.NullPointerException
        at org.apache.hadoop.fs.s3native.NativeS3FileSystem$NativeS3FsInputStream.close(NativeS3FileSystem.java:106)
        at java.io.BufferedInputStream.close(BufferedInputStream.java:451)
        at java.io.FilterInputStream.close(FilterInputStream.java:155)
        at org.apache.hadoop.util.LineReader.close(LineReader.java:83)
        at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:144)
        at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.close(MapTask.java:497)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:765)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:370)
        at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
        at org.apache.hadoop.mapred.Child.main(Child.java:249)

MR runs fine if i specify more specific input path such as s3n://bucket/wordcount/input/file.txt

MR fails if I pass s3 folder as a parameter


In summary,
This works
 hadoop jar ./hadoop-examples-1.0.3.jar wordcount /user/hadoop/wordcount/input/ s3n://bucket/wordcount/output/

This doesn't work
 hadoop jar ./hadoop-examples-1.0.3.jar wordcount s3n://bucket/wordcount/input/ s3n://bucket/wordcount/output/

(both input path are directories)

"
HADOOP-10526,Chance for Stream leakage in CompressorStream,"In CompressorStream.close , finish() can throw IOException . But out will not be closed in that situation since it is not in finally "
HADOOP-10496,Metrics system FileSink can leak file descriptor.,"{{FileSink}} opens a file.  If the {{MetricsSystem}} is shutdown, then the sink is discarded and the file is never closed, causing a file descriptor leak."
HADOOP-10490,TestMapFile and TestBloomMapFile leak file descriptors.,"Multiple tests in {{TestMapFile}} and {{TestBloomMapFile}} open files but don't close them.  On Windows, the leaked file descriptors cause subsequent tests to fail, because file locks are still held while trying to delete the test data directory."
HADOOP-10457,S3N NPEs if you do a read() after a seek() past the EOF,"if you do a seek past the EOF of an S3n file
# it doesn't throw any exception
# on the next read, you get to see a stack trace"
HADOOP-10419,BufferedFSInputStream NPEs on getPos() on a closed stream,"if you call getPos on a {{ChecksumFileSystem}} after a {{close()}} you get an NPE.

While throwing an exception in this states is legitimate (HDFS does, RawLocal does not), it should be an {{IOException}}"
HADOOP-10346,Deadlock while logging tokens,Ran into a deadlock between two threads that were both wielding Tokens.  One was trying to log a token while the other was trying to set the token service on a different token.
HADOOP-10203,Connection leak in Jets3tNativeFileSystemStore#retrieveMetadata ,"Jets3tNativeFileSystemStore#retrieveMetadata  is leaking connections. 

This affects any client that tries to read many small files very quickly (e.g. distcp from s3 to hdfs with small files blocks due to connection pool starvation). 

This is not a problem for larger files because when the GC runs any connection that's out of scope will be released in #finalize().

We are seeing the following log messages as a symptom of this problem:

{noformat}
13/12/26 13:40:01 WARN httpclient.HttpMethodReleaseInputStream: Attempting to release HttpMethod in finalize() as its response data stream has gone out of scope. This attempt will not always succeed and cannot be relied upon! Please ensure response data streams are always fully consumed or closed to avoid HTTP connection starvation.
13/12/26 13:40:01 WARN httpclient.HttpMethodReleaseInputStream: Successfully released HttpMethod in finalize(). You were lucky this time... Please ensure response data streams are always fully consumed or closed.
{noformat}
"
HADOOP-10177,Create CLI tools for managing keys via the KeyProvider API,"The KeyProvider API provides access to keys, but we need CLI tools to provide the ability to create and delete keys. I'd think it would look something like:

{code}
% hadoop key create key1
% hadoop key roll key1
% hadoop key list key1
% hadoop key delete key1
{code}"
HADOOP-10147,Upgrade to commons-logging 1.1.3 to avoid potential deadlock in MiniDFSCluster,"There is a deadlock in commons-logging 1.1.1 (see LOGGING-119) that can manifest itself while running {{MiniDFSCluster}} JUnit tests.

This deadlock has been fixed in commons-logging 1.1.2.  The latest version available is commons-logging 1.1.3, and Hadoop should upgrade to that in order to address this deadlock."
HADOOP-10126,"LightWeightGSet log message is confusing : ""2.0% max memory = 2.0 GB""","Following message log message from LightWeightGSet is confusing.
{noformat}2013-11-21 18:00:21,198 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 2.0 GB{noformat}, 
where 2GB is max JVM memory, but log message confuses like 2% of max memory is 2GB. 

It can be better like this
""2.0% of max memory 2.0 GB = 40.9 MB"""
HADOOP-10107,Server.getNumOpenConnections may throw NPE,"Found this in [build #5440|https://builds.apache.org/job/PreCommit-HDFS-Build/5440/testReport/junit/org.apache.hadoop.hdfs.server.blockmanagement/TestUnderReplicatedBlocks/testSetrepIncWithUnderReplicatedBlocks/]

Caused by: java.lang.NullPointerException
	at org.apache.hadoop.ipc.Server.getNumOpenConnections(Server.java:2434)
	at org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnections(RpcMetrics.java:74)"
HADOOP-10094,NPE in GenericOptionsParser#preProcessForWindows(),"main() in java guarantees that args is not null, but on some uses of Tool interface from java, people seem to pass around null as args, causing a NPE in GenericOptionsParser. 

Although, passing null is not recommended, we can do a trivial fix. "
HADOOP-10081,Client.setupIOStreams can leak socket resources on exception or error,"The setupIOStreams method in org.apache.hadoop.ipc.Client can leak socket resources if an exception is thrown before the inStream and outStream local variables are assigned to this.in and this.out, respectively.  "
HADOOP-10062,race condition in MetricsSystemImpl#publishMetricsNow that causes incorrect results,"TestMetricsSystemInpl#testMultiThreadedPublish failed with ""Metrics not collected""

{code}
Running org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl
Tests run: 6, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 1.688 sec <<< FAILURE! - in org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl
testMultiThreadedPublish(org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl)  Time elapsed: 0.056 sec  <<< FAILURE!
java.lang.AssertionError: Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Passed
        at org.junit.Assert.fail(Assert.java:93)
        at org.junit.Assert.assertTrue(Assert.java:43)
        at org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl.testMultiThreadedPublish(TestMetricsSystemImpl.java:232)


Results :

Failed tests:
  TestMetricsSystemImpl.testMultiThreadedPublish:232 Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Metric not collected!
Passed

Tests run: 6, Failures: 1, Errors: 0, Skipped: 0

{code}"
HADOOP-10059,RPC authentication and authorization metrics overflow to negative values on busy clusters,The RPC metrics for authorization and authentication successes can easily overflow to negative values on a busy cluster that has been up for a long time.  We should consider providing 64-bit values for these counters.
HADOOP-10017,Fix NPE in DFSClient#getDelegationToken when doing Distcp from a secured cluster to an insecured cluster,"Currently if we run Distcp from a secured cluster and copy data to an insecured cluster, DFSClient#getDelegationToken will throw NPE when processing the NULL token returned by the NN in the insecured cluster. We should be able to handle the NULL token here. "
HADOOP-10011,NPE if the system can't determine its own name and you go DNS.getDefaultHost(null),"In a test case that I am newly writing, on my infamous ""home machine with broken DNS"", I cant call getByName(null) without seeing a stack trace:
Testcase: testNullInterface took 0.014 sec
	Caused an ERROR
null
java.lang.NullPointerException
	at java.net.NetworkInterface.getByName(NetworkInterface.java:226)
	at org.apache.hadoop.net.DNS.getIPs(DNS.java:94)
	at org.apache.hadoop.net.DNS.getHosts(DNS.java:141)
	at org.apache.hadoop.net.DNS.getDefaultHost(DNS.java:218)
	at org.apache.hadoop.net.DNS.getDefaultHost(DNS.java:235)
	at org.apache.hadoop.net.TestDNS.testNullInterface(TestDNS.java:62)"
HADOOP-9974,Maven OutOfMemory exception when building with protobuf 2.5.0,"Recently Hadoop upgraded to use Protobuf 2.5.0. To build the trunk, I updated my installed Protobuf 2.5.0. With this upgrade, I didn't encounter the build failure due to protoc, but failed when building HDFS sub-project. Bellow is failure message. I'm using Mac OS X.

{code}
INFO] Reactor Summary:
[INFO] 
[INFO] Apache Hadoop Main ................................ SUCCESS [1.075s]
[INFO] Apache Hadoop Project POM ......................... SUCCESS [0.805s]
[INFO] Apache Hadoop Annotations ......................... SUCCESS [2.283s]
[INFO] Apache Hadoop Assemblies .......................... SUCCESS [0.343s]
[INFO] Apache Hadoop Project Dist POM .................... SUCCESS [1.913s]
[INFO] Apache Hadoop Maven Plugins ....................... SUCCESS [2.390s]
[INFO] Apache Hadoop Auth ................................ SUCCESS [2.597s]
[INFO] Apache Hadoop Auth Examples ....................... SUCCESS [1.868s]
[INFO] Apache Hadoop Common .............................. SUCCESS [55.798s]
[INFO] Apache Hadoop NFS ................................. SUCCESS [3.549s]
[INFO] Apache Hadoop MiniKDC ............................. SUCCESS [1.788s]
[INFO] Apache Hadoop Common Project ...................... SUCCESS [0.044s]
[INFO] Apache Hadoop HDFS ................................ FAILURE [25.219s]
[INFO] Apache Hadoop HttpFS .............................. SKIPPED
[INFO] Apache Hadoop HDFS BookKeeper Journal ............. SKIPPED
[INFO] Apache Hadoop HDFS-NFS ............................ SKIPPED
[INFO] Apache Hadoop HDFS Project ........................ SKIPPED
[INFO] hadoop-yarn ....................................... SKIPPED
[INFO] hadoop-yarn-api ................................... SKIPPED
[INFO] hadoop-yarn-common ................................ SKIPPED
[INFO] hadoop-yarn-server ................................ SKIPPED
[INFO] hadoop-yarn-server-common ......................... SKIPPED
[INFO] hadoop-yarn-server-nodemanager .................... SKIPPED
[INFO] hadoop-yarn-server-web-proxy ...................... SKIPPED
[INFO] hadoop-yarn-server-resourcemanager ................ SKIPPED
[INFO] hadoop-yarn-server-tests .......................... SKIPPED
[INFO] hadoop-yarn-client ................................ SKIPPED
[INFO] hadoop-yarn-applications .......................... SKIPPED
[INFO] hadoop-yarn-applications-distributedshell ......... SKIPPED
[INFO] hadoop-mapreduce-client ........................... SKIPPED
[INFO] hadoop-mapreduce-client-core ...................... SKIPPED
[INFO] hadoop-yarn-applications-unmanaged-am-launcher .... SKIPPED
[INFO] hadoop-yarn-site .................................. SKIPPED
[INFO] hadoop-yarn-project ............................... SKIPPED
[INFO] hadoop-mapreduce-client-common .................... SKIPPED
[INFO] hadoop-mapreduce-client-shuffle ................... SKIPPED
[INFO] hadoop-mapreduce-client-app ....................... SKIPPED
[INFO] hadoop-mapreduce-client-hs ........................ SKIPPED
[INFO] hadoop-mapreduce-client-jobclient ................. SKIPPED
[INFO] hadoop-mapreduce-client-hs-plugins ................ SKIPPED
[INFO] Apache Hadoop MapReduce Examples .................. SKIPPED
[INFO] hadoop-mapreduce .................................. SKIPPED
[INFO] Apache Hadoop MapReduce Streaming ................. SKIPPED
[INFO] Apache Hadoop Distributed Copy .................... SKIPPED
[INFO] Apache Hadoop Archives ............................ SKIPPED
[INFO] Apache Hadoop Rumen ............................... SKIPPED
[INFO] Apache Hadoop Gridmix ............................. SKIPPED
[INFO] Apache Hadoop Data Join ........................... SKIPPED
[INFO] Apache Hadoop Extras .............................. SKIPPED
[INFO] Apache Hadoop Pipes ............................... SKIPPED
[INFO] Apache Hadoop Tools Dist .......................... SKIPPED
[INFO] Apache Hadoop Tools ............................... SKIPPED
[INFO] Apache Hadoop Distribution ........................ SKIPPED
[INFO] Apache Hadoop Client .............................. SKIPPED
[INFO] Apache Hadoop Mini-Cluster ........................ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:40.880s
[INFO] Finished at: Thu Aug 15 16:02:56 PDT 2013
[INFO] Final Memory: 49M/123M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.5.1:compile (default-compile) on project hadoop-hdfs: Compilation failure
[ERROR] Failure executing javac, but could not parse the error:
[ERROR] 
[ERROR] 
[ERROR] The system is out of resources.
[ERROR] Consult the following stack trace for details.
[ERROR] java.lang.OutOfMemoryError: Java heap space
[ERROR] at com.sun.tools.javac.code.Scope$ImportScope.makeEntry(Scope.java:385)
[ERROR] at com.sun.tools.javac.code.Scope.enter(Scope.java:196)
[ERROR] at com.sun.tools.javac.code.Scope.enter(Scope.java:183)
[ERROR] at com.sun.tools.javac.comp.MemberEnter.importAll(MemberEnter.java:132)
[ERROR] at com.sun.tools.javac.comp.MemberEnter.visitTopLevel(MemberEnter.java:509)
[ERROR] at com.sun.tools.javac.tree.JCTree$JCCompilationUnit.accept(JCTree.java:446)
[ERROR] at com.sun.tools.javac.comp.MemberEnter.memberEnter(MemberEnter.java:387)
[ERROR] at com.sun.tools.javac.comp.MemberEnter.complete(MemberEnter.java:819)
[ERROR] at com.sun.tools.javac.code.Symbol.complete(Symbol.java:384)
[ERROR] at com.sun.tools.javac.code.Symbol$ClassSymbol.complete(Symbol.java:766)
[ERROR] at com.sun.tools.javac.comp.Enter.complete(Enter.java:464)
[ERROR] at com.sun.tools.javac.comp.Enter.main(Enter.java:442)
[ERROR] at com.sun.tools.javac.main.JavaCompiler.enterTrees(JavaCompiler.java:822)
[ERROR] at com.sun.tools.javac.main.JavaCompiler.compile(JavaCompiler.java:727)
[ERROR] at com.sun.tools.javac.main.Main.compile(Main.java:353)
[ERROR] at com.sun.tools.javac.main.Main.compile(Main.java:279)
[ERROR] at com.sun.tools.javac.main.Main.compile(Main.java:270)
[ERROR] at com.sun.tools.javac.Main.compile(Main.java:87)
[ERROR] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[ERROR] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
[ERROR] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
[ERROR] at java.lang.reflect.Method.invoke(Method.java:597)
[ERROR] at org.codehaus.plexus.compiler.javac.JavacCompiler.compileInProcess0(JavacCompiler.java:551)
[ERROR] at org.codehaus.plexus.compiler.javac.JavacCompiler.compileInProcess(JavacCompiler.java:526)
[ERROR] at org.codehaus.plexus.compiler.javac.JavacCompiler.compile(JavacCompiler.java:167)
[ERROR] at org.apache.maven.plugin.AbstractCompilerMojo.execute(AbstractCompilerMojo.java:678)
[ERROR] at org.apache.maven.plugin.CompilerMojo.execute(CompilerMojo.java:128)
[ERROR] at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101)
[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:209)
[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
[ERROR] at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84)
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hadoop-hdfs
{code}"
HADOOP-9954,Hadoop 2.0.5 doc build failure - OutOfMemoryError exception,"When run hadoop build with command line options:
{code}
mvn package -Pdist,native,docs -DskipTests -Dtar 
{code}

Build failed adn OutOfMemoryError Exception is thrown:
{code}
[INFO] --- maven-source-plugin:2.1.2:test-jar (default) @ hadoop-hdfs ---
[INFO] 
[INFO] --- findbugs-maven-plugin:2.3.2:findbugs (default) @ hadoop-hdfs ---
[INFO] ****** FindBugsMojo execute *******
[INFO] canGenerate is true
[INFO] ****** FindBugsMojo executeFindbugs *******
[INFO] Temp File is /var/lib/jenkins/workspace/Hadoop-Client-2.0.5-T-RPM/rpms/hadoop-devel.x86_64/BUILD/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/target/findbugsTemp.xml
[INFO] Fork Value is true
     [java] Out of memory
     [java] Total memory: 477M
     [java]  free memory: 68M
     [java] Analyzed: /var/lib/jenkins/workspace/Hadoop-Client-2.0.5-T-RPM/rpms/hadoop-devel.x86_64/BUILD/hadoop-common/hadoop-hdfs-project/hadoop-hdfs/target/classes
     [java]      Aux: /home/henkins-service/.m2/repository/org/codehaus/mojo/findbugs-maven-plugin/2.3.2/findbugs-maven-plugin-2.3.2.jar
     [java]      Aux: /home/henkins-service/.m2/repository/com/google/code/findbugs/bcel/1.3.9/bcel-1.3.9.jar
 ...
     [java]      Aux: /home/henkins-service/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
     [java] Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded
     [java] 	at java.util.HashMap.<init>(HashMap.java:226)
     [java] 	at edu.umd.cs.findbugs.ba.deref.UnconditionalValueDerefSet.<init>(UnconditionalValueDerefSet.java:68)
     [java] 	at edu.umd.cs.findbugs.ba.deref.UnconditionalValueDerefAnalysis.createFact(UnconditionalValueDerefAnalysis.java:650)
     [java] 	at edu.umd.cs.findbugs.ba.deref.UnconditionalValueDerefAnalysis.createFact(UnconditionalValueDerefAnalysis.java:82)
     [java] 	at edu.umd.cs.findbugs.ba.BasicAbstractDataflowAnalysis.getFactOnEdge(BasicAbstractDataflowAnalysis.java:119)
     [java] 	at edu.umd.cs.findbugs.ba.AbstractDataflow.getFactOnEdge(AbstractDataflow.java:54)
     [java] 	at edu.umd.cs.findbugs.ba.npe.NullDerefAndRedundantComparisonFinder.examineNullValues(NullDerefAndRedundantComparisonFinder.java:297)
     [java] 	at edu.umd.cs.findbugs.ba.npe.NullDerefAndRedundantComparisonFinder.execute(NullDerefAndRedundantComparisonFinder.java:150)
     [java] 	at edu.umd.cs.findbugs.detect.FindNullDeref.analyzeMethod(FindNullDeref.java:278)
     [java] 	at edu.umd.cs.findbugs.detect.FindNullDeref.visitClassContext(FindNullDeref.java:205)
     [java] 	at edu.umd.cs.findbugs.DetectorToDetector2Adapter.visitClass(DetectorToDetector2Adapter.java:68)
     [java] 	at edu.umd.cs.findbugs.FindBugs2.analyzeApplication(FindBugs2.java:979)
     [java] 	at edu.umd.cs.findbugs.FindBugs2.execute(FindBugs2.java:230)
     [java] 	at edu.umd.cs.findbugs.FindBugs.runMain(FindBugs.java:348)
     [java] 	at edu.umd.cs.findbugs.FindBugs2.main(FindBugs2.java:1057)
     [java] Java Result: 1
[INFO] No bugs found

{code}"
HADOOP-9916,Race condition in ipc.Client causes TestIPC timeout,"TestIPC timeouts occasionally, for example: 
[https://issues.apache.org/jira/browse/HDFS-5130?focusedCommentId=13749870&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13749870]
[https://issues.apache.org/jira/browse/HADOOP-9915?focusedCommentId=13753302&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13753302]

Look into the code, there is race condition in oah.ipc.Client, the race condition happen between RPC call thread and connection read response thread:

{code}
        if (status == RpcStatusProto.SUCCESS) {
          Writable value = ReflectionUtils.newInstance(valueClass, conf);
          value.readFields(in);                 // read value
          call.setRpcResponse(value);
          calls.remove(callId);
{code}

Read Thread: 
Connection.receiveRpcResponse-> call.setRpcResponse(value) -> notify Call Thread

Call Thread:
Client.call -> Connection.addCall(retry with the same callId) -> notify read thread

Read Thread:
calls.remove(callId) # intend to remove old call, but removes newly added call...
Connection.waitForWork end up wait maxIdleTime and close the connection. The call never get response and dead.

The problem doesn't show because previously callId is unique, we never accidentally remove newly added calls, but when retry added this race condition became possible.

To solve this, we can simply change order, remove the call first, then notify call thread.
Note there are many places need this order change(normal case, error case, cleanup case)

And there are some minor issues in TestIPC:
1. there are two method with same name:
   void testSerial()
   void testSerial(int handlerCount, boolean handlerSleep, ...)
   the second is not a test case(so should not use testXXX prefix), but somehow it causes testSerial(first one) run two times, see test report:
{code}
  <testcase time=""26.896"" classname=""org.apache.hadoop.ipc.TestIPC"" name=""testSerial""/>
  <testcase time=""25.426"" classname=""org.apache.hadoop.ipc.TestIPC"" name=""testSerial""/>
{code}

2. timeout annotation should be added, so next time related log is available.

"
HADOOP-9908,Fix NPE when versioninfo properties file is missing,When running tests in Eclipse I ran into an NPE in VersionInfo since the version info properties file didn't properly make it to the classpath. This is because getResourceAsStream can return null if the file is not found.
HADOOP-9703,org.apache.hadoop.ipc.Client leaks threads on stop.,"org.apache.hadoop.ipc.Client#stop says ""Stop all threads related to this client."" but does not shutdown the static SEND_PARAMS_EXECUTOR, so usage of this class always leaks threads rather than cleanly closing or shutting down.

"
HADOOP-9635,Fix Potential Stack Overflow in DomainSocket.c,"When I was running on OSX, the DataNode was segfaulting. On investigation, it was tracked down to this code. A potential stack overflow was also identified. 

{code}
   utfLength = (*env)->GetStringUTFLength(env, jstr);
   if (utfLength > sizeof(path)) {
     jthr = newIOException(env, ""path is too long!  We expected a path ""
         ""no longer than %zd UTF-8 bytes."", sizeof(path));
     goto done;
   }
  // GetStringUTFRegion does not pad with NUL
   (*env)->GetStringUTFRegion(env, jstr, 0, utfLength, path);

...

  //strtok_r can set rest pointer to NULL when no tokens found.
  //Causes JVM to crash in rest[0]
   for (check[0] = '/', check[1] = '\0', rest = path, token = """";
       token && rest[0];
        token = strtok_r(rest, ""/"", &rest)) {
{code}"
HADOOP-9593,stack trace printed at ERROR for all yarn clients without hadoop.home set,"This is the problem of HADOOP-9482 now showing up in a different application -one whose log4j settings haven't turned off all Shell logging.

Unless you do that, all yarn clients will have a stack trace at error in their logs, which is generating false alarms and is utterly pointless. Why does this merit a stack trace? Why log it at error? It's not an error for a client app to not have these values set as long as they have the relevant JARs on their classpath. And if they don't, they'll get some classpath error instead"
HADOOP-9560,metrics2#JvmMetrics should have max memory size of JVM,"metrics#JvmMetrics have the max memory size of JVM specified by -Xmx option.
metrics2#JvmMetrics doesn't have it but it should also have max memory size of JVM, because it's useful for users."
HADOOP-9540,Expose the InMemoryS3 and S3N FilesystemStores implementations for Unit testing.,"The stub implementations available for InMemoryFileSytemStores for S3 and S3N are currently restricted in package scope. These are quiet handy utilities for unit testing and nice to be exposed in a public scope. 

Or even conveniently I have added simple wrapper InMemoryFileSystem implementations for these stores so that it can be easily leveraged by any interested developers."
HADOOP-9478,Fix race conditions during the initialization of Configuration related to deprecatedKeyMap,"When we lanuch the client appliation which use kerberos security,the FileSystem can't be create because the exception ' java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.SecurityUtil'.

I check the exception stack trace,it maybe caused by the unsafe get operation of the deprecatedKeyMap which used by the org.apache.hadoop.conf.Configuration.

So I write a simple test case:

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.hdfs.HdfsConfiguration;

public class HTest {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        conf.addResource(""core-site.xml"");
        conf.addResource(""hdfs-site.xml"");
        FileSystem fileSystem = FileSystem.get(conf);
        System.out.println(fileSystem);
        System.exit(0);
    }
}

Then I launch this test case many times,the following exception is thrown:

Exception in thread ""TGT Renewer for XXX"" java.lang.ExceptionInInitializerError
     at org.apache.hadoop.security.UserGroupInformation.getTGT(UserGroupInformation.java:719)
     at org.apache.hadoop.security.UserGroupInformation.access$1100(UserGroupInformation.java:77)
     at org.apache.hadoop.security.UserGroupInformation$1.run(UserGroupInformation.java:746)
     at java.lang.Thread.run(Thread.java:662)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 16
     at java.util.HashMap.getEntry(HashMap.java:345)
     at java.util.HashMap.containsKey(HashMap.java:335)
     at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1989)
     at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1867)
     at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1785)
     at org.apache.hadoop.conf.Configuration.get(Configuration.java:712)
     at org.apache.hadoop.conf.Configuration.getTrimmed(Configuration.java:731)
     at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1047)
     at org.apache.hadoop.security.SecurityUtil.<clinit>(SecurityUtil.java:76)
     ... 4 more
Exception in thread ""main"" java.io.IOException: Couldn't create proxy provider class org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
     at org.apache.hadoop.hdfs.NameNodeProxies.createFailoverProxyProvider(NameNodeProxies.java:453)
     at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:133)
     at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:436)
     at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:403)
     at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:125)
     at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2262)
     at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:86)
     at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2296)
     at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2278)
     at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:316)
     at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:162)
     at HTest.main(HTest.java:11)
Caused by: java.lang.reflect.InvocationTargetException
     at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
     at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
     at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
     at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
     at org.apache.hadoop.hdfs.NameNodeProxies.createFailoverProxyProvider(NameNodeProxies.java:442)
     ... 11 more
Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.SecurityUtil
     at org.apache.hadoop.net.NetUtils.createSocketAddrForHost(NetUtils.java:231)
     at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:211)
     at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:159)
     at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)
     at org.apache.hadoop.hdfs.DFSUtil.getAddressesForNameserviceId(DFSUtil.java:452)
     at org.apache.hadoop.hdfs.DFSUtil.getAddresses(DFSUtil.java:434)
     at org.apache.hadoop.hdfs.DFSUtil.getHaNnRpcAddresses(DFSUtil.java:496)
     at org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:88)
     ... 16 more


If the HashMap used at multi-thread enviroment,not only the put operation be synchronized,the get operation(eg. containKey) should be synchronzied too.

The simple solution is trigger the init of SecurityUtil before creating the FileSystem,but I think it's should be synchronized for get of deprecatedKeyMap.

Thanks. "
HADOOP-9406,hadoop-client leaks dependency on JDK tools jar,"hadoop-client leaks out JDK tools jar as dependency. 

JDK tools jar is defined as a system dependency for hadoop-annotation/jdiff/javadocs purposes, if not done javadoc generation fails.

The problem is that in the way it is defined now, this dependency ends up leaking to hadoop-client and downstream projects that depend on hadoop-client may end up including/bundling JDK tools JAR."
HADOOP-9278,HarFileSystem may leak file handle,TestHarFileSystemBasics fails on Windows due to invalid HAR URI and file handle leak.  We need to change the tests to use valid HAR URIs and fix the file handle leak.
HADOOP-9252,StringUtils.humanReadableInt(..) has a race condition,"humanReadableInt(..) incorrectly uses oneDecimal without synchronization.

Also, limitDecimalTo2(double) correctly uses decimalFormat with synchronization.  However, synchronization can be avoided for a better performance."
HADOOP-9231,Parametrize staging URL for the uniformity of distributionManagement,"The build's {{distributionManagement}} section currently uses parametrization for the snapshot repository. It is convenient and allows to override the value from a developer's custom profile.

The same isn't available for release artifacts to make the parametrization symmetric for both types.  "
HADOOP-9212,Potential deadlock in FileSystem.Cache/IPC/UGI,jcarder found a cycle which could lead to a potential deadlock.
HADOOP-9190,packaging docs is broken,"It looks like after the docs got converted to apt format in HADOOP-8427, mvn site package -Pdist,docs no longer works.   If you run mvn site or mvn site:stage by itself they work fine, its when you go to package it that it breaks.

The error is with broken links, here is one of them:

broken-links>
  <link message=""hadoop-common-project/hadoop-common/target/docs-src/src/documentation/content/xdocs/HttpAuthentication.xml (No such file or directory)"" uri=""HttpAuthentication.html"">
    <referrer uri=""linkmap.html""/>
    <referrer uri=""index.html""/>
    <referrer uri=""single_node_setup.html""/>
    <referrer uri=""native_libraries.html""/>
    <referrer uri=""Superusers.html""/>
    <referrer uri=""service_level_auth.html""/>
    <referrer uri=""deployment_layout.html""/>
  </link>"
HADOOP-9183,Potential deadlock in ActiveStandbyElector,"A jcarder run found a potential deadlock in the locking of ActiveStandbyElector and ActiveStandbyElector.WatcherWithClientRef. No deadlock has been seen in practice, this is just a theoretical possibility at the moment."
HADOOP-9115,Deadlock in configuration when writing configuration to hdfs,"This was noticed when using hive with hadoop-1.1.1 and running 

{code}
select count(*) from tbl;
{code}

This would cause a deadlock configuration. "
HADOOP-9114,"After defined the dfs.checksum.type as the NULL, write file and hflush will through java.lang.ArrayIndexOutOfBoundsException","when I test the characteristic parameter about dfs.checksum.type. The value can be defined as NULL,CRC32C,CRC32. It's ok when the value is CRC32C or CRC32, but the client will through java.lang.ArrayIndexOutOfBoundsException when the value is configured NULL."
HADOOP-8925,Remove the packaging,"Per discussion on HADOOP-8809, now that Bigtop is TLP and supports Hadoop v2 let's remove the Hadoop packaging from trunk and branch-2. We should remove it anyway since it no longer part of the build post mavenization, was not updated post MR1 (there's no MR2/YARN packaging) and is not maintained."
HADOOP-8861,FSDataOutputStream.sync should call flush() if the underlying wrapped stream is not Syncable,"Currently FSDataOutputStream.sync is a no-op if the wrapped stream is not Syncable. Instead it should call flush() if the wrapped stream is not syncable.

This behavior is already present in trunk, but branch-1 does not have this."
HADOOP-8851,Use -XX:+HeapDumpOnOutOfMemoryError JVM option in the forked tests,"This can help to reveal the cause of issue in the event of OOME in tests.
Suggested patch attached."
HADOOP-8801,ExitUtil#terminate should capture the exception stack trace,"ExitUtil#terminate(status,Throwable) should capture and log the stack trace of the given throwable. This will help debug issues like HDFS-3933."
HADOOP-8770,NN should not RPC to self to find trash defaults (causes deadlock),"When transitioning a SBN to active, I ran into the following situation:
- the TrashPolicy first gets loaded by an IPC Server Handler thread. The {{initialize}} function then tries to make an RPC to the same node to find out the defaults.
- This is happening inside the NN write lock (since it's part of the active initialization). Hence, all of the other handler threads are already blocked waiting to get the NN lock.
- Since no handler threads are free, the RPC blocks forever and the NN never enters active state.

We need to have a general policy that the NN should never make RPCs to itself for any reason, due to potential for deadlocks like this."
HADOOP-8727,Gracefully deprecate dfs.umaskmode in 2.x onwards,"While HADOOP-6234 added dfs.umaskmode in 0.21.0, the subsequent HADOOP-6233 simply renamed it, again in 0.21.0, without any deprecation mechanism (understandable).

However, 1.x now carries dfs.umaskmode but there isn't a graceful deprecation when one upgrades to 2.x. We should recreate this prop and add it to the deprecated list."
HADOOP-8721,ZKFC should not retry 45 times when attempting a graceful fence during a failover,"Scenario:
Active NN on machine1
Standby NN on machine2
Machine1 is isolated from the network (machine1 network cable unplugged)
After zk session timeout ZKFC at machine2 side gets notification that NN1 is not there.
ZKFC tries to failover NN2 as active.
As part of this during fencing it tries to connect to machine1 and kill NN1. (sshfence technique configured)
This connection retry happens for 45 times( as it takes  ipc.client.connect.max.socket.retries)
Also after that standby NN is not able to take over as active (because of fencing failure).
Suggestion: If ZKFC is not able to reach other NN for specified time/no of retries it can consider that NN as dead and instruct the other NN to take over as active as there is no chance of the other NN (NN1) retaining its state as active after zk session timeout when its isolated from network

From ZKFC log:
{noformat}
2012-06-21 17:46:14,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 22 time(s).
2012-06-21 17:46:35,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 23 time(s).
2012-06-21 17:46:56,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 24 time(s).
2012-06-21 17:47:17,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 25 time(s).
2012-06-21 17:47:38,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 26 time(s).
2012-06-21 17:47:59,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 27 time(s).
2012-06-21 17:48:20,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 28 time(s).
2012-06-21 17:48:41,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 29 time(s).
2012-06-21 17:49:02,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 30 time(s).
2012-06-21 17:49:23,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: HOST-xx-xx-xx-102/xx.xx.xx.102:65110. Already tried 31 time(s).
{noformat}
 

"
HADOOP-8684,Deadlock between WritableComparator and WritableComparable,"Classes implementing WriableComparable in Hadoop call the method WritableComparator.define() in their static initializers. This means, the classes call the method define() while thier class loading, under locking their class objects. And, the method WritableComparator.define() locks the WritableComaprator class object.

On the other hand, WritableComparator.get() also locks the WritableComparator class object, and the method may create instances of the targeted comparable class, involving loading the targeted comparable class if any. This means, the method might try to lock the targeted comparable class object under locking the WritableComparator class object.

There are reversed orders of locking objects, and you might fall in deadlock."
HADOOP-8660,TestPseudoAuthenticator failing with NPE,"This test started failing recently, on top of trunk:

testAuthenticationAnonymousAllowed(org.apache.hadoop.security.authentication.client.TestPseudoAuthenticator)  Time elapsed: 0.241 sec  <<< ERROR!
java.lang.NullPointerException
        at org.apache.hadoop.security.authentication.client.PseudoAuthenticator.authenticate(PseudoAuthenticator.java:75)
        at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:232)
        at org.apache.hadoop.security.authentication.client.AuthenticatorTestCase._testAuthentication(AuthenticatorTestCase.java:127)
        at org.apache.hadoop.security.authentication.client.TestPseudoAuthenticator.testAuthenticationAnonymousAllowed(TestPseudoAuthenticator.java:65)
"
HADOOP-8632,Configuration leaking class-loaders,"The newly introduced CACHE_CLASSES leaks class loaders causing associated classes to not be reclaimed.

One solution is to remove the cache itself since each class loader implementation caches the classes it loads automatically and preventing an exception from being raised is just a micro-optimization that, as one can tell, causes bugs instead of improving anything.
In fact, I would argue in a highly-concurrent environment, the weakhashmap synchronization/lookup probably costs more then creating the exception itself.

Another is to prevent the leak from occurring, by inserting the loadedclass into the WeakHashMap wrapped in a WeakReference. Otherwise the class has a strong reference to its classloader (the key) meaning neither gets GC'ed.
And since the cache_class is static, even if the originating Configuration instance gets GC'ed, its classloader won't."
HADOOP-8624,ProtobufRpcEngine should log all RPCs if TRACE logging is enabled,"Since all RPC requests/responses are now ProtoBufs, it's easy to add a TRACE level logging output for ProtobufRpcEngine that actually shows the full content of all calls. This is very handy especially when writing/debugging unit tests, but might also be useful to enable at runtime for short periods of time to debug certain production issues."
HADOOP-8566,AvroReflectSerializer.accept(Class) throws a NPE if the class has no package (primitive types and arrays),the accept() method should consider the case where the class getPackage() returns NULL.
HADOOP-8525,Provide Improved Traceability for Configuration,"Configuration provides basic traceability to see where a config setting came from, but once the configuration is written out that information is written to a comment in the XML and then lost the next time the configuration is read back in.  It would really be great to be able to store a complete history of where the config came from in the XML, so that it can then be retrieved later for debugging."
HADOOP-8495,Update Netty to avoid leaking file descriptors during shuffle,Netty 3.2.3.Final has a known bug where writes to a closed channel do not have their futures invoked.  See [Netty-374|https://issues.jboss.org/browse/NETTY-374].  This can lead to file descriptor leaks during shuffle as noted in MAPREDUCE-4298.
HADOOP-8452,DN logs backtrace when running under jsvc and /jmx is loaded,"Running the data node under jsvc and requesting /jmx falls victim to a kernel bug http://marc.info/?l=linux-kernel&m=133788505209725&w=2 which results in EACCES when open()ing /proc/self/fd to attempt to count the open filedescriptors.

Hopefully someday we will have kernels with this bug fixed; in the meantime, the log spew which results is unpleasant:

12270 2012-05-15 21:04:41,683 ERROR org.apache.hadoop.jmx.JMXJsonServlet: getting attribute OpenFileDescriptorCount of java.lang:type=OperatingSystem threw an exception
12271 javax.management.RuntimeErrorException: java.lang.InternalError: errno: 13 error: Unable to open directory /proc/self/fd
12272 
12273         at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:858)
12274         at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:869)
12275         at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:670)
12276         at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:638)
12277         at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:314)
12278         at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:292)
12279         at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:192)
12280         at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
12281         at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
12282         at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
12283         at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
12284         at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:932)
12285         at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
12286         at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
12287         at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
12288         at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
12289         at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
12290         at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
12291         at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
12292         at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
12293         at org.mortbay.jetty.Server.handle(Server.java:326)
12294         at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
12295         at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
12296         at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
12297         at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
12298         at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
12299         at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
12300         at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
12301 Caused by: java.lang.InternalError: errno: 13 error: Unable to open directory /proc/self/fd
12302 
12303         at com.sun.management.UnixOperatingSystem.getOpenFileDescriptorCount(Native Method)
12304         at sun.reflect.GeneratedMethodAccessor42.invoke(Unknown Source)
12305         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
12306         at java.lang.reflect.Method.invoke(Method.java:597)
12307         at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:167)
12308         at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:96)
12309         at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:33)
12310         at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)
12311         at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:65)
12312         at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:216)
12313         at javax.management.StandardMBean.getAttribute(StandardMBean.java:358)
12314         at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:666)
12315         ... 25 more

we should catch the RuntimeErrorException and make it a debug()."
HADOOP-8419,GzipCodec NPE upon reset with IBM JDK,"The GzipCodec will NPE upon reset after finish when the native zlib codec is not loaded. When the native zlib is loaded the codec creates a CompressorOutputStream that doesn't have the problem, otherwise, the GZipCodec uses GZIPOutputStream which is extended to provide the resetState method. Since IBM JDK 6 SR9 FP2 including the current JDK 6 SR10, GZIPOutputStream#finish will release the underlying deflater, which causes NPE upon reset. This seems to be an IBM JDK quirk as Sun JDK and OpenJDK doesn't have this issue."
HADOOP-8361,Avoid out-of-memory problems when deserializing strings,"In HDFS, we want to be able to read the edit log without crashing on an OOM condition.  Unfortunately, we currently cannot do this, because there are no limits on the length of certain data types we pull from the edit log.  We often read strings without setting any upper limit on the length we're prepared to accept.

It's not that we don't have limits on strings-- for example, HDFS limits the maximum path length to 8000 UCS-2 characters.  Linux limits the maximum user name length to either 64 or 128 bytes, depending on what version you are running.  It's just that we're not exposing these limits to the deserialization functions that need to be aware of them."
HADOOP-8179,risk of NPE in CopyCommands processArguments(),"My IDE is warning me that the {{is.close()}} method will NPE if the {{is = src.fs.open(src.path);}} call raises an exception, which could happen if the source path could not be opened. There should be an if (is!=null) wrapper"
HADOOP-8169,javadoc generation fails with java.lang.OutOfMemoryError: Java heap space,"building the docs (mvn package -Pdocs -Dtar -DskipTests) on branch-0.23 results in a javadoc java.lang.OutOfMemoryError: Java heap space. Note this seems to only happen when building with 32 bit java, 64 bit works fine."
HADOOP-8118,Print the stack trace of InstanceAlreadyExistsException in trace level,"There are many InstanceAlreadyExistsException stack traces in the unit tests output like below.
{noformat}
javax.management.InstanceAlreadyExistsException: Hadoop:service=NameNode,name=NameNodeInfo
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:453)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.internal_addObject(DefaultMBeanServerInterceptor.java:1484)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:963)
	...
{noformat}"
HADOOP-8054,NPE with FilterFileSystem,"While running Hive tests, I'm seeing the following exception with 0.23.1,
{noformat}
ava.lang.NullPointerException
        at org.apache.hadoop.fs.FileSystem.getDefaultBlockSize(FileSystem.java:1901)
        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:447)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:351)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:351)
        at org.apache.hadoop.fs.ProxyFileSystem.getFileStatus(ProxyFileSystem.java:247)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:351)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1165)
        at org.apache.hadoop.fs.FileUtil.checkDest(FileUtil.java:390)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:242)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:232)
{noformat}

Did not see this with 0.23.0, though."
HADOOP-8050,Deadlock in metrics,"The metrics serving thread and the periodic snapshot thread can deadlock.
It happened a few times on one of namenodes we have. When it happens RPC works but the web ui and hftp stop working. I haven't look at the trunk too closely, but it might happen there too."
HADOOP-7964,Deadlock in class init.,"After HADOOP-7808, client-side commands hang occasionally. There are cyclic dependencies in NetUtils and SecurityUtil class initialization. Upon initial look at the stack trace, two threads deadlock when they hit the either of class init the same time."
HADOOP-7815,Map memory mb is being incorrectly set by hadoop-setup-conf.sh,"HADOOP-7728 enabled task memory management to be configurable in the hadoop-setup-conf.sh. However, the default value for mapred.job.map.memory.mb is being set incorrectly."
HADOOP-7797,Fix the repository name to support pushing to the staging area of Nexus,"The repository name doesn't match the old one, leading to confusion."
HADOOP-7771,"NPE when running hdfs dfs -copyToLocal, -get etc",NPE when running hdfs dfs -copyToLocal if the destination directory does not exist. The behavior in branch-0.20-security is to create the directory and copy/get the contents from source.
HADOOP-7728,hadoop-setup-conf.sh should be modified to enable task memory manager,The hadoop-setup-conf.sh should be modified such that task memory management is enabled.
HADOOP-7632,NPE in copyToLocal,"[todd@c0309 hadoop-trunk-home]$ ./bin/hadoop fs -copyToLocal /hbase/.META./1028785192/ /tmp/meta/
copyToLocal: Fatal internal error
java.lang.NullPointerException
        at org.apache.hadoop.fs.shell.PathData.getPathDataForChild(PathData.java:182)
        at org.apache.hadoop.fs.shell.CommandWithDestination.processPaths(CommandWithDestination.java:115)
        at org.apache.hadoop.fs.shell.Command.recursePath(Command.java:329)
        at org.apache.hadoop.fs.shell.Command.processPaths(Command.java:302)
        at org.apache.hadoop.fs.shell.CommandWithDestination.processPaths(CommandWithDestination.java:116)
        at org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:272)
        at org.apache.hadoop.fs.shell.Command.processArgument(Command.java:255)
        at org.apache.hadoop.fs.shell.Command.processArguments(Command.java:239)
        at org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:105)
        at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:185)
        at org.apache.hadoop.fs.shell.Command.run(Command.java:149)
"
HADOOP-7602,"wordcount, sort etc on har files fails with NPE","wordcount, sort etc on har files fails with NPE@createSocketAddr(NetUtils.java:137). "
HADOOP-7529,Possible deadlock in metrics2,Lock cycle detected by jcarder between MetricsSystemImpl and DefaultMetricsSystem
HADOOP-7440,HttpServer.getParameterValues throws NPE for missing parameters,"If the requested parameter was not specified in the request, the raw request's getParameterValues function returns null. Thus, trying to access {{unquoteValue.length}} throws NPE."
HADOOP-7381,FindBugs OutOfMemoryError,"When running the findbugs target from Jenkins, I get an OutOfMemory error.
The ""effort"" in FindBugs is set to Max which ends up using a lot of memory to go through all the classes. The jvmargs passed to FindBugs is hardcoded to 512 MB max.

We can leave the default to 512M, as long as we pass this as an ant parameter which can be overwritten in individual cases through -D, or in the build.properties file (either basedir, or user's home directory).
"
HADOOP-7353,Cleanup FsShell and prevent masking of RTE stacktraces,"{{FsShell}}'s top level exception handler catches and displays exceptions.  Unfortunately it displays only the first line of an exception, which means an unexpected {{RuntimeExceptions}} like {{NullPointerException}} only display ""{{cmd: NullPointerException}}"".  This user has no context to understand and/or accurately report the issue.

Found due to bugs such as {{HADOOP-7327}}."
HADOOP-7194,Potential Resource leak in IOUtils.java,"{code:title=IOUtils.java|borderStyle=solid}

try {
      copyBytes(in, out, buffSize);
    } finally {
      if(close) {
        out.close();
        in.close();
      }
    }
{code} 
In the above code if any exception throws from the out.close() statement, in.close() statement will not execute and the input stream will not be closed.
"
HADOOP-7187,Socket Leak in org.apache.hadoop.metrics.ganglia.GangliaContext,"Init method is creating DatagramSocket. But this is not closed any where. 
"
HADOOP-7146,RPC server leaks file descriptors,"Both the Listener and Responder thread call Selector.open but don't have a matching .close(). This causes a leak of anonymous pipes. Not a big deal because people rarely close and re-open servers, but worth fixing."
HADOOP-7122,Timed out shell commands leak Timer threads,"When a shell command times out, the TimerThread used to cause the timeout is leaked."
HADOOP-7118,NPE in Configuration.writeXml,"In HADOOP-7082 I stupidly introduced a regression whereby Configuration.writeXml will throw an NPE if it is called before any .get() call is made, since the properties member is not initialized. This is causing a failure in TestCapacitySchedulerWithJobTracker on my box, but doesn't appear to trigger any failures in the non-contrib tests since .get() is usually called first.

This JIRA is to fix the bug and add a unit test for writeXml in common (apparently it never had a unit test)"
HADOOP-7090,Possible resource leaks in hadoop core code,"It is always a good practice to close the IO streams in a finally block.. 

For example, look at the following piece of code in the Writer class of BloomMapFile 

{code:title=BloomMapFile .java|borderStyle=solid}
    public synchronized void close() throws IOException {
      super.close();
      DataOutputStream out = fs.create(new Path(dir, BLOOM_FILE_NAME), true);
      bloomFilter.write(out);
      out.flush();
      out.close();
    }
{code} 

If an exception occurs during fs.create or on any other line,  out.close() will not be executed..

The following can reduce the scope of resorce leaks..
{code:title=BloomMapFile .java|borderStyle=solid}
    public synchronized void close() throws IOException {
      super.close();
      DataOutputStream out = null;
      try{
          out = fs.create(new Path(dir, BLOOM_FILE_NAME), true);
          bloomFilter.write(out);
          out.flush();
      }finally{
	 IOUtils.closeStream(out);
    }
{code} 

"
HADOOP-7011,KerberosName.main(...) throws NPE,The main method of KerberosName attempts to do short name translation before calling KerberosName.setConfiguration(...).
HADOOP-6975,integer overflow in S3InputStream for blocks > 2GB,S3InputStream has the same integer overflow issue as DFSInputStream (fixed in HDFS-96).
HADOOP-6912,Guard against NPE when calling UGI.isLoginKeytabBased(),NPE can happen when isLoginKeytabBased() is called before a login is performed. See MAPREDUCE-1992 for an example.
HADOOP-6847,Problem staging 0.21.0 artifacts to Apache Nexus Maven Repository,"I get this error:
{noformat}
-mvn-system-deploy:
[artifact:install-provider] Installing provider: org.apache.maven.wagon:wagon-http:jar:1.0-beta-2:runtime
[artifact:deploy] Deploying to https://repository.apache.org/content/repositories/snapshots
[artifact:deploy] Uploading: org/apache/hadoop/hadoop-common-instrumented/0.21.0/hadoop-common-instrumented-0.21.0.jar to apache.snapshots.https
[artifact:deploy] Uploaded 1331K
[artifact:deploy] An error has occurred while processing the Maven artifact tasks.
[artifact:deploy]  Diagnosis:
[artifact:deploy] 
[artifact:deploy] Error deploying artifact 'org.apache.hadoop:hadoop-common-instrumented:jar': Error deploying artifact: Failed to transfer file: https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common-instrumented/0.21.0/hadoop-common-instrumented-0.21.0.jar. Return code is: 400
{noformat}

Note that 400 is ""Bad Request"", not an authentication error (401)."
HADOOP-6833,IPC leaks call parameters when exceptions thrown,"HADOOP-6498 moved the calls.remove() call lower into the SUCCESS clause of receiveResponse(), but didn't put a similar calls.remove into the ERROR clause. So, any RPC call that throws an exception ends up orphaning the Call object in the connection's ""calls"" hashtable. This prevents cleanup of the connection and is a memory leak for the call parameters."
HADOOP-6821,Document changes to memory monitoring,Modify the cluster_setup guide with information about memory monitoring and admin configuration.
HADOOP-6812,fs.inmemory.size.mb not listed in conf. Cluster setup page gives wrong advice.,"http://hadoop.apache.org/common/docs/current/cluster_setup.html

fs.inmemory.size.mb does not appear in any xml file
{noformat}
grep ""fs.inmemory.size.mb"" ./mapred/mapred-default.xml 
[edward@ec src]$ grep ""fs.inmemory.size.mb"" ./hdfs/hdfs-default.xml 
[edward@ec src]$ grep ""fs.inmemory.size.mb"" ./core/core-default.xml 
{noformat}

http://hadoop.apache.org/common/docs/current/cluster_setup.html
Documentation error:
Real-World Cluster Configurations
{noformat}
conf/core-site.xml  	io.sort.factor  	100  	More streams merged at once while sorting files.
conf/core-site.xml 	io.sort.mb 	200 	Higher memory-limit while sorting data.
{noformat}

core --- io.sort.factor					-- should be mapred
core --- io.sort.mb					-- should be mapred
"
HADOOP-6754,DefaultCodec.createOutputStream() leaks memory,"DefaultCodec.createOutputStream() creates a new Compressor instance in each OutputStream. Even if the OutputStream is closed, this leaks memory."
HADOOP-6620,NPE if renewer is passed as null in getDelegationToken,"If renewer is passed as null in getDelegationToken, an NPE is thrown. We should handle null renewer and the token must not be allowed to be renewed if the renewer is null or empty string."
HADOOP-6609,Deadlock in DFSClient#getBlockLocations even with the security disabled,"Here is the stack trace:
""IPC Client (47) connection to XX"" daemon
prio=10 tid=0x00002aaae0369c00 nid=0x655b waiting for monitor entry [0x000000004181f000..0x000000004181fb80]
   java.lang.Thread.State: BLOCKED (on object monitor)
at org.apache.hadoop.io.UTF8.readChars(UTF8.java:210)
- waiting to lock <0x00002aaab3eaee50> (a org.apache.hadoop.io.DataOutputBuffer)
at org.apache.hadoop.io.UTF8.readString(UTF8.java:203)
at org.apache.hadoop.io.ObjectWritable.readObject(ObjectWritable.java:179)
at org.apache.hadoop.io.ObjectWritable.readFields(ObjectWritable.java:66)
at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:638)
at org.apache.hadoop.ipc.Client$Connection.run(Client.java:573)

""IPC Client (47) connection to /0.0.0.0:50030 from job_201002262308_0007""
daemon prio=10 tid=0x00002aaae0272800 nid=0x6556 waiting for monitor entry [0x000000004131a000..0x000000004131ad00]
   java.lang.Thread.State: BLOCKED (on object monitor)
at org.apache.hadoop.io.UTF8.readChars(UTF8.java:210) 
- waiting to lock <0x00002aaab3eaee50> (a org.apache.hadoop.io.DataOutputBuffer)
at org.apache.hadoop.io.UTF8.readString(UTF8.java:203)
at org.apache.hadoop.io.ObjectWritable.readObject(ObjectWritable.java:179)
at org.apache.hadoop.io.ObjectWritable.readFields(ObjectWritable.java:66)
at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:638)
at org.apache.hadoop.ipc.Client$Connection.run(Client.java:573)

""main"" prio=10 tid=0x0000000046c17800 nid=0x6544 in Object.wait() [0x0000000040207000..0x0000000040209ec0]
   java.lang.Thread.State: WAITING (on object monitor)
at java.lang.Object.wait(Native Method) 
- waiting on <0x00002aaacee6bc38> (a org.apache.hadoop.ipc.Client$Call)
at java.lang.Object.wait(Object.java:485)
at org.apache.hadoop.ipc.Client.call(Client.java:854) - locked <0x00002aaacee6bc38> (a org.apache.hadoop.ipc.Client$Call)
at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
at $Proxy2.getBlockLocations(Unknown Source)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
at $Proxy2.getBlockLocations(Unknown Source)
at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:333)
at org.apache.hadoop.hdfs.DFSClient.access$2(DFSClient.java:330)
at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.getBlockAt(DFSClient.java:1606) 
- locked <0x00002aaacecb8258> (a org.apache.hadoop.hdfs.DFSClient$DFSInputStream)
at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1704)
- locked <0x00002aaacecb8258> (a org.apache.hadoop.hdfs.DFSClient$DFSInputStream)
at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1856)
- locked <0x00002aaacecb8258> (a org.apache.hadoop.hdfs.DFSClient$DFSInputStream)
at java.io.DataInputStream.readFully(DataInputStream.java:178)
at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:63)
at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:101)
at org.apache.hadoop.io.UTF8.readChars(UTF8.java:211)
- locked <0x00002aaab3eaee50> (a org.apache.hadoop.io.DataOutputBuffer)
at org.apache.hadoop.io.UTF8.readString(UTF8.java:203)
at org.apache.hadoop.mapred.FileSplit.readFields(FileSplit.java:90)
at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:1)
at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:341)
at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:357)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:317)
at org.apache.hadoop.mapred.Child$4.run(Child.java:211)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:700)
at org.apache.hadoop.mapred.Child.main(Child.java:205)"
HADOOP-6560,HarFileSystem throws NPE for har://hdfs-/foo,"{noformat}
-bash-3.1$ hadoop distcp -Dmapred.job.queue.name=${JOBQ}  har://hdfs-/user/tsz/t10_4.har/t10_4 t10_4_distcp t10_4_distcp
10/01/28 23:20:45 INFO tools.DistCp: srcPaths=[har://hdfs-/user/tsz/t10_4.har/t10_4]
10/01/28 23:20:45 INFO tools.DistCp: destPath=t10_4_distcp
With failures, global counters are inaccurate; consider running with -i
Copy failed: java.lang.NullPointerException
        at org.apache.hadoop.fs.HarFileSystem.decodeHarURI(HarFileSystem.java:184)
        at org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:95)
        ...
{noformat}
"
HADOOP-6439,Shuffle deadlocks on wrong number of maps,"The new shuffle assumes that the number of maps is correct. The new JobSubmitter sets the old value. Something misfires in the middle causing:

09/12/01 00:00:15 WARN conf.Configuration: mapred.job.split.file is deprecated. Instead, use mapreduce.job.splitfile
09/12/01 00:00:15 WARN conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps

But my reduces got stuck at 2 maps / 12 when there were only 2 maps in the job.
"
HADOOP-6343,Stack trace of any runtime exceptions should be recorded in the server logs. ,Hadoop RPC catches any server side exception and throws an IOException. Runtime excpetions should be recorded in the server logs before being thrown as IOException.
HADOOP-6313,Expose flush APIs to application users,"Earlier this year, Yahoo, Facebook, and Hbase developers had a roundtable discussion where we agreed to support three types of flush in HDFS (API1, 2, and 3) and the append project aims to implement API2. Here is a proposal to expose these APIs to application users.
1. Three flush APIs
* API1: flushes out from the address space of client into the socket to the data nodes.   On the return of the call there is no guarantee that that data is out of the underlying node and no guarantee of having reached a DN.  New readers will eventually see this data if there are no failures.
* API2: flushes out to all replicas of the block. The data is in the buffers of the DNs but not on the DN's OS buffers.  New readers will see the data after the call has returned. 
* API3: flushes out to all replicas and all replicas have done posix fsync equivalent - ie the OS has flushed it to the disk device (but the disk may have it in its cache).

2. Support flush APIs in FS
* FSDataOutputStream#flush supports API1
* FSDataOutputStream implements Syncable interface defined below. If its wrapped output stream (i.e. each file system's stream) is Syncable, FSDataOutputStream#hflush() and hsync() call its wrapped output stream's hflush & hsync.
{noformat}
  public interface Syncable {
    public void hflush() throws IOException;  // support API2
    public void hsync() throws IOException;   // support API3
  }
{noformat}
* In each file system, if only hflush() is implemented, hsync() by default calls hflush().  If only hsync() is implemented, hflush() by default calls flush()."
HADOOP-6279,Add JVM memory usage to JvmMetrics,"The JvmMetrics currently publish memory usage from the MemoryMXBean. This is useful, but doesn't include the total heap size (eg as displayed in the JT Web UI).

It would be nice to expose Runtime.getRuntime().maxMemory() as part of JvmMetrics.

It seems that Runtime.getRuntime().totalMemory() (used by the JT for ""memory used"") is the same as the 'memHeapCommittedM' which already exists."
HADOOP-6243,NPE in handling deprecated configuration keys.,"I run TestFileCreation in Eclipse and get a NullPointerException. Debugging shows that {{Configuration.populateDeprecationMapping()}} sets {{Configuration.properties}} to null.
This code was introduced in HADOOP-6105."
HADOOP-6230,"Move process tree, and memory calculator classes out of Common into Map/Reduce.",
HADOOP-6192,Shell.getUlimitMemoryCommand is tied to Map-Reduce,Currently org.apache.hadoop.util.Shell.getUlimitMemoryCommand relies on a MAPREDUCE specific configuration property for the memory limit. We should break the link.
HADOOP-6185,Replace FSDataOutputStream#sync() by hflush(),"This jira aims add hflush() API to FSDataOutputStream and deprecates sync() API.

Note that the change should not commit to the trunk before hdfs append branch is merged to hdfs trunk."
HADOOP-5727,"Faster, simpler id.hashCode() which does not allocate memory","Integer.valueOf allocates memory if the integer is not in the object-cache, which is the vast majority of cases for the task id. It is possible to compute the hash code of an integer without going via the integer cache, and hence avoiding allocating memory."
HADOOP-5687,Hadoop NameNode throws NPE if fs.default.name is the default value,"Throwing NPE is confusing; instead, an exception with a useful string description could be thrown instead."
HADOOP-5652,Reduce does not respect in-memory segment memory limit when number of on disk segments == io.sort.factor,"If the number of on-disk segments is exactly {{io.sort.factor}}, then map output segments may be left in memory for the reduce contrary to the specification in {{mapred.job.reduce.input.buffer.percent}}."
HADOOP-5625,Add I/O duration time in client trace ,"Add I/O duration information into client trace log for analyzing performance.
 "
HADOOP-5607,TestCapacityScheduler fails with NPE,"Observed on Hudson:
{noformat}
java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobInProgress.terminateJob(JobInProgress.java:2117)
	at org.apache.hadoop.mapred.JobInProgress.terminate(JobInProgress.java:2153)
	at org.apache.hadoop.mapred.JobInProgress.kill(JobInProgress.java:2221)
	at org.apache.hadoop.mapred.TestCapacityScheduler$FakeTaskTrackerManager.killJob(TestCapacityScheduler.java:359)
	at org.apache.hadoop.mapred.CapacityTaskScheduler.killJobIfInvalidRequirements(CapacityTaskScheduler.java:1431)
	at org.apache.hadoop.mapred.CapacityTaskScheduler.jobAdded(CapacityTaskScheduler.java:1463)
	at org.apache.hadoop.mapred.JobQueuesManager.jobAdded(JobQueuesManager.java:183)
	at org.apache.hadoop.mapred.TestCapacityScheduler$FakeTaskTrackerManager.submitJob(TestCapacityScheduler.java:387)
	at org.apache.hadoop.mapred.TestCapacityScheduler.submitJob(TestCapacityScheduler.java:625)
	at org.apache.hadoop.mapred.TestCapacityScheduler.testHighMemoryJobWithInvalidRequirements(TestCapacityScheduler.java:1992)
{noformat}

This was introduced by HADOOP-5565. FakeJobInProgress doesn't pass a JobTracker reference to the subtype cstr, so calling kill() derefs the null JT field."
HADOOP-5590,testHighMemoryJobWithInvalidRequirements in TestCapacityScheduler fails with NullPointerException,testHighMemoryJobWithInvalidRequirements fails consistently with NullPointerException when TestCapacityScheduler is run.
HADOOP-5534,Deadlock triggered by FairScheduler scheduler's servlet due to changes from HADOOP-5214.,
HADOOP-5516,TaskMemoryManagerThread crashes in a corner case,"TT's stdout says.
{code}
Exception in thread ""org.apache.hadoop.mapred.TaskMemoryManagerThread"" java.lang.NullPointerException
        at org.apache.hadoop.util.ProcfsBasedProcessTree.getProcessTree(ProcfsBasedProcessTree.java:126)
        at org.apache.hadoop.mapred.TaskMemoryManagerThread.run(TaskMemoryManagerThread.java:200)
{code}

TaskMemoryManager crashes and no further memory management is done."
HADOOP-5491,Better control memory usage in contrib/index,"The combiner was originally designed to work only on the map side. When used on the reduce side, it may use too much memory."
HADOOP-5473,Race condition in command-line kill for a task,"The race condition occurs in following sequence of events:
1. User issues a command-line kill for a RUNNING map-task. JT stores the task in tasksToKill mapping.
2. TT reports the task status as SUCCEEDED.
3. JT creates a TaskCompletionEvent as SUCCEEDED. Also sends a killTaskAction.
4. Reducers fail fetching the map output.
5. finally, the task would fail with Fetch failures. After HADOOP-4759, the task is left as FAILED_UNCLEAN task, since the task is present in tasksToKill mapping."
HADOOP-5459,CRC errors not detected reading intermediate output into memory with problematic length,"It's possible that the expected, uncompressed length of the segment is less than the available/decompressed data. This can happen in some worst-cases for compression, but it is exceedingly rare. It is also possible (though also fantastically unlikely) for the data to deflate to a size greater than that reported by the map. CRC errors will remain undetected because IFileInputStream does not validate the checksum until the end of the stream, and close() does not advance the stream to the end of the segment. The (abbreviated) read loop fetching data in shuffleInMemory:

{code}
int n = input.read(shuffleData, 0, shuffleData.length);
while (n > 0) { 
  bytesRead += n;
  n = input.read(shuffleData, bytesRead, 
                 (shuffleData.length-bytesRead));
} 
{code}

Will read only up to the expected length. Without reading the whole segment, the checksum is not validated. Even if IFileInputStream instances are closed, they should always validate checksums."
HADOOP-5440,Successful taskid are not removed from TaskMemoryManager,"Successfully completed task-attempt-ids are not removed from TaskMemoryManager. This is after refactoring the code in tracker.reportTaskFinished into tip.reportTaskFinished, in HADOOP-4759"
HADOOP-5374,NPE in JobTracker.getTasksToSave() method,
HADOOP-5292,KFS: calling getFileBlockLocations() on 0-length file causes a NPE,"When getFileBlockLocations() in KosmosFileSystem.java is called on a file with 0-length, there is a NPE."
HADOOP-5247,NPEs in JobTracker and JobClient when mapred.jobtracker.completeuserjobs.maximum is set to zero.,
HADOOP-5235,possible NPE in tip.kill(),"There is possibility of NPE with runner.kill() code in TaskTracker.TaskInProgress.kill().
If a killTaskAction is issued for cleanup attempt of a task, forwhich runner is not created, the existing code would through NPE.
"
HADOOP-5234,NPE in TaskTracker reinit action,"I have seen an NPE in TT reinit action.
TT logs :
{noformat}
2009-02-12 12:14:02,859 INFO org.apache.hadoop.mapred.TaskTracker: Error cleaning up task runner: java.lang.NullPointerException
	at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.cleanup(TaskTracker.java:2515)
	at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.jobHasFinished(TaskTracker.java:2381)
	at org.apache.hadoop.mapred.TaskTracker.close(TaskTracker.java:925)
	at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:1830)
	at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:2901)
{noformat}

corresponding code is 
{noformat}
2515            if (localJobConf.getNumTasksToExecutePerJvm() == 1) {
{noformat}
"
HADOOP-5222,Add offset in client trace,"By adding offset in client trace, the client trace information can provide more accurately information about I/O.
It is useful for performance analyzing.

Since there is  no random write now, the offset of writing is always zero.
"
HADOOP-5200,NPE when the namenode comes up but the filesystem is set to file://,"If you bring up a namenode and the conf file points to file:/// as the URI, then the authority is null, breaking code that follows
"
HADOOP-5198,NPE in Shell.runCommand(),"I have seen one of the task failures with following exception:
java.lang.NullPointerException
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:441)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:149)
	at org.apache.hadoop.util.Shell.run(Shell.java:134)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)
	at org.apache.hadoop.util.ProcessTree.isAlive(ProcessTree.java:244)
	at org.apache.hadoop.util.ProcessTree.sigKillInCurrentThread(ProcessTree.java:67)
	at org.apache.hadoop.util.ProcessTree.sigKill(ProcessTree.java:115)
	at org.apache.hadoop.util.ProcessTree.destroyProcessGroup(ProcessTree.java:164)
	at org.apache.hadoop.util.ProcessTree.destroy(ProcessTree.java:180)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.kill(JvmManager.java:377)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.reapJvm(JvmManager.java:249)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.access$000(JvmManager.java:113)
	at org.apache.hadoop.mapred.JvmManager.launchJvm(JvmManager.java:76)
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:411)

"
HADOOP-5154,4-way deadlock in FairShare scheduler,This happened while trying to change the priority of a job from the scheduler servlet.
HADOOP-5150,"""ant binary"" wastes time building documentations that are not needed in the packaging",
HADOOP-5145,Balancer sometimes runs out of memory after days or weeks running,"The culprit is a HashMap called MovedBlocks. By design this map does not get cleaned up between iterations. This is because the deletion of source replicas is done by NN. When next iteration starts, source replicas may not have been deleted, Balancer does not want to schedule them to move again. To prevent running out of memory, Balancer should expire/clean the movedBlocks from some iterations back.
"
HADOOP-5068,testClusterBlockingForLackOfMemory in TestCapacityScheduler fails randomly,testClusterBlockingForLackOfMemory fails randomly when TestCapacityScheduler is run.
HADOOP-5035,Support non Time Series charting and handle data gap more gracefully for Chukwa charts,"Chukwa charting only support time series data because the data structure is a HashMap of Long, Double.
Long is the timestamp (xaxis), and Double is the yaxis value.  The data structure will be changed to HashMap of String, Double.
This will add capability to plot xaxis with any data.

If the yaxis value is not a number, the charting system should skip plotting for this data point."
HADOOP-4977,Deadlock between reclaimCapacity and assignTasks,"I was running the latest trunk with the capacity scheduler and saw the JobTracker lock up with the following deadlock reported in jstack:

Found one Java-level deadlock:
=============================
""18107298@qtp0-4"":
  waiting to lock monitor 0x08085b40 (object 0x56605100, a org.apache.hadoop.mapred.JobTracker),
  which is held by ""IPC Server handler 4 on 54311""
""IPC Server handler 4 on 54311"":
  waiting to lock monitor 0x0808594c (object 0x5660e518, a org.apache.hadoop.mapred.CapacityTaskScheduler$MapSchedulingMgr),
  which is held by ""reclaimCapacity""
""reclaimCapacity"":
  waiting to lock monitor 0x08085b40 (object 0x56605100, a org.apache.hadoop.mapred.JobTracker),
  which is held by ""IPC Server handler 4 on 54311""

Java stack information for the threads listed above:
===================================================
""18107298@qtp0-4"":
	at org.apache.hadoop.mapred.JobTracker.getClusterStatus(JobTracker.java:2695)
	- waiting to lock <0x56605100> (a org.apache.hadoop.mapred.JobTracker)
	at org.apache.hadoop.mapred.jobtracker_jsp._jspService(jobtracker_jsp.java:93)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:324)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)
""IPC Server handler 4 on 54311"":
	at org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.updateQSIObjects(CapacityTaskScheduler.java:564)
	- waiting to lock <0x5660e518> (a org.apache.hadoop.mapred.CapacityTaskScheduler$MapSchedulingMgr)
	at org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.assignTasks(CapacityTaskScheduler.java:855)
	at org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.access$1000(CapacityTaskScheduler.java:294)
	at org.apache.hadoop.mapred.CapacityTaskScheduler.assignTasks(CapacityTaskScheduler.java:1336)
	- locked <0x5660dd20> (a org.apache.hadoop.mapred.CapacityTaskScheduler)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2288)
	- locked <0x56605100> (a org.apache.hadoop.mapred.JobTracker)
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)

Unfortunately I didn't manage to select all of the output by mistake, so some is missing, but it appears that reclaimCapacity locks the MapSchedulingMgr and then tries to lock the JobTracker, whereas the updateQSIObjects called in assignTasks holds a lock on the JobTracker (the JobTracker grabs this lock when it calls assignTasks) and then tries to lock the MapSchedulingMgr. The other thread listed there is a Jetty thread for the web interface and isn't part of the circular locking. The solution to this would be to lock the JobTracker in reclaimCapacity before locking anything else."
HADOOP-4956,NPE when jobdetails.jsp ,"I see exceptions like the one pasted below on the job UI. This happens when tasks fail.
java.lang.NullPointerException
	at org.apache.hadoop.mapred.Counters.incrAllCounters(Counters.java:440)
	at org.apache.hadoop.mapred.JobInProgress.incrementTaskCounters(JobInProgress.java:910)
	at org.apache.hadoop.mapred.JobInProgress.getMapCounters(JobInProgress.java:880)
	at org.apache.hadoop.mapred.jobdetails_jsp._jspService(jobdetails_jsp.java:313)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:324)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)
"
HADOOP-4924,Race condition in re-init of TaskTracker,"The taskReportServer is stopped in the TaskTracker.close() method in a thread. The race condition is:
1) TaskTracker.close() is invoked - this starts a thread to stop the taskReportServer
2) TaskTracker.initialize is invoked - this tries to create a new taskReportServer
Assume that the thread started to stop the taskReportServer gets to start its work after (2) above. The thread will end up stopping the newly created taskReportServer."
HADOOP-4915,Out of Memory error in reduce shuffling phase when compression is turned on,"mapred.compress.map.output is set to true, and the job has 6860 mappers and 300 reducers.

Several reducers failed because:out of memory error in the shuffling phase.
"
HADOOP-4906,TaskTracker running out of memory after running several tasks,"Looks like the TaskTracker isn't cleaning up correctly after completed/failed tasks, I suspect that the JobConfs aren't being deallocated. Eventually the TaskTracker runs out of memory after running several tasks."
HADOOP-4904,Deadlock while leaving safe mode.,"{{SafeModeInfo.leave()}} acquires locks in an incorrect order, which causes the deadlock.
It first acquires the {{SafeModeInfo}} lock, then calls {{FSNamesystem.processMisReplicatedBlocks()}}, which requires the global {{FSNamesystem}} lock.
It should be the other way around: first {{FSNamesystem}} lock, then {{SafeModeInfo}}."
HADOOP-4892,File descriptor leak in Chukwa's ExecPlugin,"Chukwa's ExecPlugin doesn't properly close pipes after running a child process.  For ExecPlugin, this is benign, since it runs in a separate process.  For ExecAdaptor, this is catastrophic, since file descriptors leak. "
HADOOP-4648,Remove ChecksumDistriubtedFileSystem and InMemoryFileSystem,We should remove the obsolete Checksum FileSystems.
HADOOP-4635,Memory leak ?,"I am running a process that needs to crawl a tree structure containing ~10K images, copy the images to the local disk, process these images, and copy them back to HDFS.

My problem is the following : after about 10h of processing, the processes crash, complaining about a std::bad_alloc exception (I use hadoop pipes to run existing software). When running fuse_dfs in debug mode, I get an outOfMemoryError, telling that there is no more room in the heap.

While the process is running, using top or ps, I notice that fuse is using up an increasing amount of memory, until some limit is reached. At that point , the memory used is oscillating. I suppose that this is due to the use of the virtual memory.

This leads me to the conclusion that there is some memory leak in fuse_dfs, since the only other programs running are Hadoop and the existing software, both thoroughly tested in the past.

My problem is that my knowledge concerning memory leak tracking is rather limited, so I will need some instructions to get more insight concerning this issue.

Thank you"
HADOOP-4552,Deadlock in RPC Server,"RPC server could get into a deadlock especially when clients or server are network starved. This is a deadlock between RPC responder thread trying to check if there are any connection to be purged and RPC handler trying to queue a response to be written by the responder.

This was first observed [this thread|http://www.nabble.com/TaskTrackers-disengaging-from-JobTracker-to20234317.html]. "
HADOOP-4523,Enhance how memory-intensive user tasks are handled,"HADOOP-3581 monitors each Hadoop task to see if its memory usage (which includes usage of any tasks spawned by it and so on) is within a per-task limit. If the task's memory usage goes over its limit, the task is killed. This, by itself, is not enough to prevent badly behaving jobs from bringing down nodes. What is also needed is the ability to make sure that the sum total of VM usage of all Hadoop tasks does not exceed a certain limit."
HADOOP-4439,Cleanup memory related resource management,"HADOOP-3759 and HADOOP-3581 introduced memory based resource management. This JIRA is to cleanup certain aspects of the two issues that came up while doing HADOOP-4035, which is filed to support memory based scheduling "
HADOOP-4435,The JobTracker should display the amount of heap memory used,"It would be nice to make the JobTracker UI display the amount of heap memory currently in use. This is similar to the DFS UI that already displays the amount if heap memory used by the NameNode.
"
HADOOP-4377,Race condition creating S3 buffer directory for NativeS3FileSystem,"The buffer directory is checked for existence, then created if it doesn't exist.  But the create can fail if the another process creates it in between.  We can fix this by checking for existence again if the create fails.  I've seen ""Cannot create S3 buffer directory"" occur, and this race is the most plausible explanation."
HADOOP-4374,JVM should not be killed but given an opportunity to exit gracefully,"When the tasktracker picks an idle JVM for purging, it should signal the JVM to exit gracefully, rather than forcefully killing it. This might have the unfortunate side effect of logs not fully flushed yet in some cases."
HADOOP-4358,NPE from CreateEditsLog,"HADOOP-1869 added a call to setAccessTime(long) from the INode cstr, which relies on a non-null value from FSNamesystem::getFSNamesystem.
{noformat}
java.lang.NullPointerException
        at org.apache.hadoop.hdfs.server.namenode.INode.setAccessTime(INode.java:301)
        at org.apache.hadoop.hdfs.server.namenode.INode.<init>(INode.java:99)
        at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.<init>(INodeDirectory.java:45)
        at org.apache.hadoop.hdfs.CreateEditsLog.addFiles(CreateEditsLog.java:68)
        at org.apache.hadoop.hdfs.CreateEditsLog.main(CreateEditsLog.java:214)
{noformat}"
HADOOP-4346,"Hadoop triggers a ""soft"" fd leak. ","
Starting with Hadoop-0.17, most of the network I/O uses non-blocking NIO channels. Normal blocking reads and writes are handled by Hadoop and use our own cache of selectors. This cache suites well for Hadoop where I/O often occurs on many short lived threads. Number of fds consumed is proportional to number of threads currently blocked. 

If blocking I/O is done using java.*, Sun's implementation uses internal per-thread selectors. These selectors are closed using {{sun.misc.Cleaner}}. Looks like this cleaning is kind of like finalizers and tied to GC. This is pretty ill suited if we have many threads that are short lived. Until GC happens, number of these selectors keeps growing. Each selector consumes 3 fds.

Though blocking read and write are handled by Hadoop, {{connect()}} is still the default implementation that uses per-thread selector. 

Koji helped a lot in tracking this. Some sections from 'jmap' output and other info  Koji collected led to this suspicion and will include that in the next comment.

One solution might be to handle connect() also in Hadoop using our selectors.
"
HADOOP-4232,Race condition in JVM reuse when more than one slot becomes free,"A race condition exists where there are two or more slots free and there are two or more tasks waiting to run. As an example, consider a case where there are two free slots and there are two tasks waiting to run. JVM_job1 and JVM_job2 are the two idle jvms in memory. A waiting task, task job1_t1, kills the JVM_job2 and spawns a new one, JVM_1_job1. While JVM_1_job1 is initializing (it is marked busy during initialization), JVM_job1 picks this task up and hence this becomes busy as well. Another waiting task, job3_t1 finds both the JVMs busy and doesn't spawn a new JVM."
HADOOP-4228,"dfs datanode metrics, bytes_read, bytes_written overflows due to incorrect type used.","bytes_read, and bytes_written metrics are using int (MetricsTimeVaryingInt) as counter.  This type is too small to store the bytes_read and bytes_written metrics.  Recommend to change this to long (metricsLongValue)."
HADOOP-4213,NPE in TestLimitTasksPerJobTaskScheduler,"The test is failed consistently.  It is also failed on Hudson.
{noformat}
Testsuite: org.apache.hadoop.mapred.TestLimitTasksPerJobTaskScheduler
Tests run: 5, Failures: 0, Errors: 5, Time elapsed: 0.391 sec

Testcase: testMaxRunningTasksPerJob took 0.328 sec
	Caused an ERROR
null
java.lang.NullPointerException
	at org.apache.hadoop.mapred.LimitTasksPerJobTaskScheduler.start(LimitTasksPerJobTaskScheduler.java:53)
	at org.apache.hadoop.mapred.TestJobQueueTaskScheduler.setUp(TestJobQueueTaskScheduler.java:197)

...
{noformat}"
HADOOP-4146,[Hive] null pointer exception on a join,"create table xx(aa int);
select a.* from xx a join xx b on a.aa = b.aa;


gets a nullpointer exception in join operator. close()

The testcase works fine when it is issued from the command line - but it fails from ant"
HADOOP-4137,NPE in GangliaContext.xdr_string (GangliaContext.java:195),"Exception in thread ""Timer thread for monitoring dfs"" java.lang.NullPointerException
        at org.apache.hadoop.metrics.ganglia.GangliaContext.xdr_string(GangliaContext.java:195)
        at org.apache.hadoop.metrics.ganglia.GangliaContext.emitMetric(GangliaContext.java:138)
        at org.apache.hadoop.metrics.ganglia.GangliaContext.emitRecord(GangliaContext.java:123)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.emitRecords(AbstractMetricsContext.java:304)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.timerEvent(AbstractMetricsContext.java:290)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.access$000(AbstractMetricsContext.java:50)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext$1.run(AbstractMetricsContext.java:249)
        at java.util.TimerThread.mainLoop(Unknown Source)
        at java.util.TimerThread.run(Unknown Source)

It looks like this caused the datanode to hang, though I accidentally killed the datanode before I could dump its stack."
HADOOP-4129,Memory limits of TaskTracker and Tasks should be in kiloBytes.,"HADOOP-3759 uses memory limits in kilo-bytes and HADOOP-3581 changed it to be in bytes. Because of this, TestHighRAMJobs is failing on Linux. We should change this behaviour so that all memory limits are considered to be in kilo-bytes."
HADOOP-4121,HistoryViewer initialization failure should log exception trace ,"If there is any exception in HistoryViewer's constructor, it throws an IOException. But the exception message should contain the exception trace."
HADOOP-4098,Update and add PHP & Python clients to hive packaging directory,php & python metastore server client libraries should be added to the hive packaging
HADOOP-4035,Modify the capacity scheduler (HADOOP-3445) to schedule tasks based on memory requirements and task trackers free memory,"HADOOP-3759 introduced configuration variables that can be used to specify memory requirements for jobs, and also modified the tasktrackers to report their free memory. The capacity scheduler in HADOOP-3445 should schedule tasks based on these parameters. A task that is scheduled on a TT that uses more than the default amount of memory per slot can be viewed as effectively using more than one slot, as it would decrease the amount of free memory on the TT by more than the default amount while it runs. The scheduler should make the used capacity account for this additional usage while enforcing limits, etc."
HADOOP-4018,limit memory usage in jobtracker,"We have seen instances when a user submitted a job with many thousands of mappers. The JobTracker was running with 3GB heap, but it was still not enough to prevent memory trashing from Garbage collection; effectively the Job Tracker was not able to serve jobs and had to be restarted.

One simple proposal would be to limit the maximum number of tasks per job. This can be a configurable parameter. Is there other things that eat huge globs of memory in job Tracker?"
HADOOP-3940,Reduce often attempts in memory merge with no work,"ReduceTask.ReduceCopier.ShuffleRamManager initializes numRequiredMapOutputs to 0, so one of the predicates in ShuffleRamManager::waitForDataToMerge, {{numPendingRequests < numRequiredMapOutputs}}, is false until the first map output is fetched and false again after the last map output is fetched. The InMemFSMergeThread thread will loop busily in this state."
HADOOP-3865,SecondaryNameNode runs out of memory,SecondaryNameNode has memory leak. If we leave secondary namenode to run for a while doing several checkpoints it runs out of heap.
HADOOP-3804,NPE in FSNamesystem.addStoredBlock(...),"{noformat}
2008-07-21 22:30:43,489 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 59403,
  call blockReceived(DatanodeRegistration(DN_HOST:58052, storageID=DS-YYYYYY, infoPort=55243, ipcPort=50020), [Lorg.apache.hadoop.hdfs.protocol.Block;@11e
725, [Ljava.lang.String;@15e4ae5) from DN_HOST:49527: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock(FSNamesystem.java:2800)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.blockReceived(FSNamesystem.java:3138)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.blockReceived(NameNode.java:637)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
{noformat}"
HADOOP-3776,NPE in NameNode with unknown blocks,"When a datanode has a block that NameNode does not have, it results in an NPE at the NameNode. And one of these cases results in an infinite loop of these errors because DataNode keeps invoking the same RPC that resulted in this NPE.

One way to reproduce :

 * On a single DN cluster, start writing a large file (something like {{'bin/hadoop fs -put 5Gb 5Gb'}})
 * Now, from a different shell, delete this file ({{bin/hadoop fs -rm 5Gb}})
 * Most likely you will hit this.
 * The cause is that when DataNode invokes {{blockReceived()}} to inform about the last block it received, the file is already deleted and results in an NPE at the namenode. The way DataNode works, it basically keep invoking the same RPC with same block and results in the same error.

When block does not exist in NameNode's blocksMap, it basically does not belong to the cluster. Let me know if you need the trace. Basically the NPE is at FSNamesystem.java:2800 (on trunk)."
HADOOP-3759,Provide ability to run memory intensive jobs without affecting other running tasks on the nodes,"In HADOOP-3581, we are discussing how to prevent memory intensive tasks from affecting Hadoop daemons and other tasks running on a node. A related requirement is that users be provided an ability to run jobs which are memory intensive. The system must provide enough knobs to allow such jobs to be run while still maintaining the requirements of HADOOP-3581."
HADOOP-3737,CompressedWritable throws OutOfMemoryError,"We were seeing OutOfMemoryErrors with stack traces like the following (Hadoop 0.17.0):

{noformat}
java.lang.OutOfMemoryError
        at java.util.zip.Deflater.init(Native Method)
        at java.util.zip.Deflater.<init>(Deflater.java:123)
        at java.util.zip.Deflater.<init>(Deflater.java:132)
        at org.apache.hadoop.io.CompressedWritable.write(CompressedWritable.java:71)
        at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:90)
        at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:77)
        at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1016)
        [...]
{noformat}

A Google search found the following long-standing issue in Java in which use of java.util.zip.Deflater causes an OutOfMemoryError:

[http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4797189]

CompressedWritable instantiates a Deflater, but does not call {{deflater.end()}}.  It should do that in order to release the Deflater's resources immediately, instead of waiting for the object to be finalized.

We applied this change locally and saw much improvement in the stability of memory usage of our app.

This may also affect the SequenceFile compression types, because org.apache.hadoop.io.compress.zlib.BuiltInZlib{Deflater,Inflater} extend java.util.zip.{Deflater,Inflater}.  org.apache.hadoop.io.compress.Compressor defines an end() method, but I do not see that this method is ever called."
HADOOP-3673,Deadlock in Datanode RPC servers,"There is a deadlock scenario in the way Lease Recovery is triggered using the Datanode RPC server via HADOOP-3310.

Each Datanode has dfs.datanode.handler.count handler threads (default of 3). These handler threads are used to support the generation-stamp-dance protocol as described in HADOOP-1700.

Let me try to explain the scenario with an example. Suppose, a cluster has two datanodes. Also, let's assume that dfs.datanode.handler.count is set to 1. Suppose that there are two clients, each writing to a separate file with a replication factor of 2. Let's assume that both clients encounter an IO error and triggers the generation-stamp-dance protocol. The first client may invoke recoverBlock on the first datanode while the second client may invoke recoverBlock on the second datanode. Now, each of the datanode will try to make a getBlockMetaDataInfo() to the other datanode. But since each datanode has only 1 server handler threads, both threads will block for eternity. Deadlock!"
HADOOP-3644,TestLocalJobControl test gets OutOfMemoryError on 64-bit Java,"The TestLocalJobControl unit test fails on 64-bit Java on Linux with an OutOfMemoryError. Here is the exact Java environment:

$ java -version
java version ""1.5.0_07""
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_07-b03)
Java HotSpot(TM) 64-Bit Server VM (build 1.5.0_07-b03, mixed mode)

The test runs fine with 32-bit Java. The problem is likely that some of the data structures become bigger when using 64-bit pointers. As a fix, I've suggested simply increasing the memory available to JUnit."
HADOOP-3638,Cache the iFile index files in memory to reduce seeks during map output serving,The iFile index files can be cached in memory to reduce seeks during map output serving.
HADOOP-3592,org.apache.hadoop.fs.FileUtil.copy() will leak input streams if the destination can't be opened,"FileUtil.copy()  relies on IOUtils.copyBytes() to close the incoming streams, which it does. Normally.

But if dstFS.create() raises any kind of IOException, then the inputstream ""in"", which was created in the line above, will never get closed, and hence be leaked.

      InputStream in = srcFS.open(src);
      OutputStream out = dstFS.create(dst, overwrite);
      IOUtils.copyBytes(in, out, conf, true);

Some try/catch wrapper around the open operations could close the streams if any exception gets thrown at that point in the copy process."
HADOOP-3590,Null pointer exception in JobTracker when the task tracker is not yet resolved,"2008-06-17 13:29:56,711 INFO org.apache.hadoop.mapred.JobTracker: Got heartbeat from: xxx (initialContact: false acceptNewTasks: true) with responseId: 0
2008-06-17 13:29:56,711 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 123, call heartbeat(org.apache.hadoop.mapred.TaskTrackerStatus@123, true, true, -1) from xxx error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
       at org.apache.hadoop.mapred.JobTracker.getParentNode(JobTracker.java:1327)
       at org.apache.hadoop.mapred.JobInProgress.findNewMapTask(JobInProgress.java:1142)
       at org.apache.hadoop.mapred.JobInProgress.obtainNewMapTask(JobInProgress.java:685)
       at org.apache.hadoop.mapred.JobTracker.getNewTaskForTaskTracker(JobTracker.java:1708)
       at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:1431)
       at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
       at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
       at java.lang.reflect.Method.invoke(Method.java:597)
       at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
----
Looks like a corner case. This happens when the task tracker just joins the JT and asks for a task to run. In a case where the task tracker is not yet resolved, this can lead to null pointer exception. Remember that the task trackers are  added to separate queue and resolved by a separate thread i.e there is no forced resolution for task trackers. There is no side effect of this bug since the task tracker will try again and also the job runs to completion."
HADOOP-3581,Prevent memory intensive user tasks from taking down nodes,"Sometimes user Map/Reduce applications can get extremely memory intensive, maybe due to some inadvertent bugs in the user code, or the amount of data processed. When this happens, the user tasks start to interfere with the proper execution of other processes on the node, including other Hadoop daemons like the DataNode and TaskTracker. Thus, the node would become unusable for any Hadoop tasks. There should be a way to prevent such tasks from bringing down the node."
HADOOP-3519,NPE in DFS FileSystem rename,"I think this is a regression:
{noformat}
% bin/hadoop fs -mkdir /a/b
% bin/hadoop fs -mv /a/b /c/d
mv: java.io.IOException: java.lang.NullPointerException
{noformat}"
HADOOP-3517,The last InMemory merge may be missed,"This is post HADOOP-3366. The inmem merge thread has the loop:
{code}
        while (!exitInMemMerge) {
            ramManager.waitForDataToMerge();
            doInMemMerge();
          }
{code}
The fetchOutputs, at the end of copying everything, does the following:
{code}
        exitInMemMerge = true; 
        ramManager.close();
{code}
Now if the merge thread is doing a merge (inside the doInMemMerge method) when the exitInMemMerge is set to true, the loop will break and the last merge of the files that got shuffled recently will be skipped. ramManager.close(), that internally does a final notify to the merge thread also won't have any effect in this case."
HADOOP-3506,Occasional NPE in Jets3tFileSystemStore,"In extraordinary circumstances (eg. S3 outages), calling S3FileSystem functions will throw NullPointerExceptions when trying to read from the filesystem. I've traced this down to calls to Jets3tFileSystemStore.get().

Both get() functions catch an S3ServiceException, and check its error code using a string comparison. However, the underlying libs3t library will sometimes produce an exception with a null error code string. This results in an NPE that propagates all the way to the S3FileSystem, and to the caller.

To fix this, Jets3tFileSystemStore lines 196 and 212 should be changed from:
bq.         if (e.getS3ErrorCode().equals(""NoSuchKey"")) {
to:
bq.         if (""NoSuchKey"".equals(e.getS3ErrorCode())) {

"
HADOOP-3503,Race condition when client and namenode start block recovery simultaneously,"When a client detects a error while writing to a block, it starts the generation-stamp-protocol to remove stale replicas. At the same time, if the namenode experiences a lease expiry event for that file, the namenode starts the generation-stamp-protocol for the same block. Now, the client and thr namenode ping-pongs trying to stamp the block replicas. This ping-pong can continue for a long time."
HADOOP-3501,deprecate InMemoryFileSystem,"As of HADOOP-2095, InMemoryFileSystem is no longer used.  Its design was optimized for a particular application and it is thus not a good general-purpose RAM-based FileSystem implementation, so it ought to be removed."
HADOOP-3489,NPE in SafeModeMonitor,"If dfsadmin issues -safemode leave command when name-node is in the extended period of safe mode the SafeModeMonitor throws the following exception:
{code}
Exception in thread ""org.apache.hadoop.dfs.FSNamesystem$SafeModeMonitor@dc86eb"" java.lang.NullPointerException
	at org.apache.hadoop.dfs.FSNamesystem$SafeModeMonitor.run(FSNamesystem.java:3914)
	at java.lang.Thread.run(Thread.java:619)
{code}
The problem is that when SafeModeMonitor.run() wakes up it tries to check whether it canLeave() the safe mode, but the safe mode is off already,
and therefore the ""safemode"" field is null."
HADOOP-3446,The reduce task should not flush the in memory file system before starting the reducer,"In the case where the entire reduce inputs fit in ram, we currently force the input to disk and re-read it before giving it to the reducer. It would be much better if we merged from the ramfs and any spills to feed the reducer its input."
HADOOP-3382,Memory leak when files are not cleanly closed,"{{FSNamesystem.internalReleaseCreate()}} in invoked on files that are open for writing but not cleanly closed. e.g. when client invokes {{abandonFileInProgress()}} or when lease expires. It deletes the last block if it has a length of zero. The block is deleted from the file INode but not from {{blocksMap}}. Then leaves a reference to such file until NameNode is restarted. When this happens  HADOOP-3381 multiplies amount of memory leak.
"
HADOOP-3381,INode interlinks can multiply effect of memory leaks,"Say a directory 'DIR' has a directory tree under it with 10000 files and directories. Each INode keeps refs to parent and children. When DIR is deleted, memory wise we essentially delete link from its parent (and delete the all the blocks from {{blocksMap}}). We don't modify its children. This is ok since this will form an island of references and will be gc-ed. Thats when everything is perfect. But if there is a bug that leaves a ref from a valid object (there is a suspect, I will another jira) to even one of these 10000 files, it could hold up all the INode and related objects. This can make a smaller mem leak many times more severe.


"
HADOOP-3320,NPE in NetworkTopology.getDistance(),"I am seeing the following exception:
{code}
08/04/28 20:15:09 ERROR dfs.NNThroughputBenchmark: java.lang.NullPointerException
	at org.apache.hadoop.net.NetworkTopology.getDistance(NetworkTopology.java:443)
	at org.apache.hadoop.dfs.ReplicationTargetChooser.getPipeline(ReplicationTargetChooser.java:457)
	at org.apache.hadoop.dfs.ReplicationTargetChooser.chooseTarget(ReplicationTargetChooser.java:126)
	at org.apache.hadoop.dfs.ReplicationTargetChooser.chooseTarget(ReplicationTargetChooser.java:72)
	at org.apache.hadoop.dfs.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1140)
	at org.apache.hadoop.dfs.NameNode.addBlock(NameNode.java:300)
	at org.apache.hadoop.dfs.NNThroughputBenchmark$BlockReportStats.addBlocks(NNThroughputBenchmark.java:786)
	at org.apache.hadoop.dfs.NNThroughputBenchmark$BlockReportStats.generateInputs(NNThroughputBenchmark.java:775)
	at org.apache.hadoop.dfs.NNThroughputBenchmark$OperationStatsBase.benchmark(NNThroughputBenchmark.java:203)
	at org.apache.hadoop.dfs.NNThroughputBenchmark.runBenchmark(NNThroughputBenchmark.java:1035)
	at org.apache.hadoop.dfs.NNThroughputBenchmark.main(NNThroughputBenchmark.java:1053)
{code}
It looks like the problem is in NetworkTopology.chooseRandom(String, String), which returns null in certain cases, but the value returned is never checked for null."
HADOOP-3184,"HOD gracefully exclude ""bad"" nodes during ring formation","HOD clusters sometimes fail to allocate due to a single ""bad"" node. During ring formation, the entire ring should not be dependent upon every single node being good. Instead, it should either exclude any ring member that does not adequately join the ring in a specified amount of time.

This is a frequent HOD user issue (although not directly caused by HOD).

Examples of bad nodes: Missing java, incorrect version of HOD or Hadoop, local name-cache corrupt, slow network links, drives just beginning to fail, etc.

Many of these conditions are known, and we can monitor for those separately, but this enhancement would shield users from unknown failure conditions that we haven't yet anticipated. This way, a user will get a cluster, instead of hanging indefinitely.
"
HADOOP-3146,DFSOutputStream.flush should be renamed as DFSOutputStream.fsync,"Starting fron hadoop-0.17, calling flush of dfs becomes very expensive.
The current implementation of flush should be renamed as sync.
"
HADOOP-3139,DistributedFileSystem.close() deadlock and FileSystem.closeAll() warning,"Koji found the following:

*DistributedFileSystem.close() deadlock*
My dfs -ls hang. 
Ctrl-Z showed a deadlock state.
{noformat}
""Thread-0"":
        at org.apache.hadoop.dfs.DistributedFileSystem.close(DistributedFileSystem.java:190)
        - waiting to lock <0xedde8788> (a org.apache.hadoop.dfs.DistributedFileSystem)
        at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:1231)
        - locked <0xee0baf88> (a org.apache.hadoop.fs.FileSystem$Cache)
        at org.apache.hadoop.fs.FileSystem.closeAll(FileSystem.java:169)
        at org.apache.hadoop.fs.FileSystem$ClientFinalizer.run(FileSystem.java:154)
        - locked <0xee0bae40> (a org.apache.hadoop.fs.FileSystem$ClientFinalizer)
""main"":
        at org.apache.hadoop.fs.FileSystem$Cache.remove(FileSystem.java:1201)
        - waiting to lock <0xee0baf88> (a org.apache.hadoop.fs.FileSystem$Cache)
        at org.apache.hadoop.fs.FileSystem.close(FileSystem.java:1085)
        at org.apache.hadoop.dfs.DistributedFileSystem.close(DistributedFileSystem.java:192)
        - locked <0xedde8788> (a org.apache.hadoop.dfs.DistributedFileSystem)
        at org.apache.hadoop.fs.FsShell.close(FsShell.java:1698)
        at org.apache.hadoop.fs.FsShell.main(FsShell.java:1712)

Found 1 deadlock.
{noformat}

*FileSystem.closeAll() warning*
{noformat}
08/03/31 16:48:42 INFO fs.FileSystem: FileSystem.closeAll() threw an exception:
java.io.IOException: HftpFileSystem(=org.apache.hadoop.dfs.HftpFileSystem@111111) and
Key(=null@hftp://namenode-nn:4444) do not match.
{noformat}"
HADOOP-3118,Namenode NPE while loading fsimage after a cluster upgrade from older disk format,"FSDirectory.unprotectedDelete: failed to remove /user/ran gadi/10Mb because it does not exist
2008-03-27 22:00:10,904 ERROR org.apache.hadoop.dfs.NameNode: 
java.lang.NullPointerException
         at
org.apache.hadoop.dfs.StringBytesWritable.<init>(StringBytesWritable.java:39)
         at
org.apache.hadoop.dfs.INodeFileUnderConstruction.<init>(INode.java:795)
         at org.apache.hadoop.dfs.FSEditLog.loadFSEdits(FSEditLog.java:528)
         at org.apache.hadoop.dfs.FSImage.loadFSEdits(FSImage.java:766)
         at org.apache.hadoop.dfs.FSImage.loadFSImage(FSImage.java:640)
         at org.apache.hadoop.dfs.FSImage.doUpgrade(FSImage.java:250)
         at
org.apache.hadoop.dfs.FSImage.recoverTransitionRead(FSImage.java:217)
         at
org.apache.hadoop.dfs.FSDirectory.loadFSImage(FSDirectory.java:80)
         at
org.apache.hadoop.dfs.FSNamesystem.initialize(FSNamesystem.java:274)
         at org.apache.hadoop.dfs.FSNamesystem.<init>(FSNamesystem.java:255)
         at org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:133)
         at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:178)
         at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:164)
         at org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:846)
         at org.apache.hadoop.dfs.NameNode.main(NameNode.java:855)

"
HADOOP-3113,DFSOututStream.flush() should flush data to real block file on DataNode.,"DFSOutputStream has a method called flush() that persists block locations on the namenode and sends all outstanding data to all datanodes in the pipeline. However, this data goes to the tmp file on the datanode(s). When the block is closed, the tmp files is renamed to be the real block file. If the datanode(s) dies before the block is compete, then entire block is lost. This behaviour wil be fixed in HADOOP-1700.

However, in the short term, a configuration paramater can be used to allow datanodes to write to the real block file directly, thereby avoiding writing to the tmp file. This means that data that is flushed successfully by a client does not get lost even if the datanode(s) or client dies.

The Namenode already has code to pick the largest replica (if multiple datanodes have different sizes of this block). Also, the namenode has code to not trigger replication request if the file is still being written to.

The only caveat that I can think of is that the block report periodicity should be much much smaller that the lease timeout period. A block report adds the being-written-to blocks to the blocksMap thereby avoiding any cleanup that a lease expiry processing might have otherwise done.

Not all requirements specified by HADOOP-1700 are supported by this approach, but it could still be helpful (in the short term) for a wide range of applications.



"
HADOOP-3112,Distcp fails with null pointer exception.,"Copy failed: java.lang.NullPointerException
        at org.apache.hadoop.io.serializer.SerializationFactory.<init>(SerializationFactory.java:52)
        at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:910)
        at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:846)
        at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:394)
        at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
        at org.apache.hadoop.util.CopyFiles.setup(CopyFiles.java:743)
        at org.apache.hadoop.util.CopyFiles.copy(CopyFiles.java:520)
        at org.apache.hadoop.util.CopyFiles.run(CopyFiles.java:591)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.util.CopyFiles.main(CopyFiles.java:607)

this is the null pointer exception you get when using 0.17 to distcp.

i was running using hod 
with hadoop --config hoddir distcp .....................
After investigating further with help from chris, we found out that it is using conf.getStrings which does not have a default. Also, hadoop default conf directory is not added to the classpath  when we run bin/hadoop on the client side. 
On copying hadoop-default.xml to my config directory it worked fine. 

we can add hadoop default conf directory to the classpath? or  use a default in the call for conf.getStrings(""io.serializations"")?

I am marking this as a blocker for someone to take a look. "
HADOOP-3108,NPE in FSDirectory.unprotectedSetPermission,"Not sure if this is fixed in later release, but I'm seeing many NPE in the namenode log.
Permission is disabled on this cluster.
{noformat} 
2008-03-27 03:22:39,984 INFO org.apache.hadoop.ipc.Server: IPC Server handler 18 on 8020, 
call setPermission(/user/knoguchi/file0, rwxr-xr-x) from 99.9.99.9:55555: 
error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.dfs.FSDirectory.unprotectedSetPermission(FSDirectory.java:411)
        at org.apache.hadoop.dfs.FSDirectory.setPermission(FSDirectory.java:405)
        at org.apache.hadoop.dfs.FSNamesystem.setPermission(FSNamesystem.java:716)
        at org.apache.hadoop.dfs.NameNode.setPermission(NameNode.java:297)
        at sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:409)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:899)
{noformat} "
HADOOP-3107,fsck failing with NPE,"2008-03-27 07:35:35,954 WARN /: /fsck?path=%2F:
From the namenode log, 

java.lang.NullPointerException
         at org.apache.hadoop.dfs.NamenodeFsck.check(NamenodeFsck.java:152)
         at org.apache.hadoop.dfs.NamenodeFsck.check(NamenodeFsck.java:153)
         at org.apache.hadoop.dfs.NamenodeFsck.fsck(NamenodeFsck.java:126)
         at org.apache.hadoop.dfs.FsckServlet.doGet(FsckServlet.java:48)
         at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)
         at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
         at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
         at
org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
         at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
         at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
         at
org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
         at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
         at org.mortbay.http.HttpServer.service(HttpServer.java:954)
         at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
         at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
         at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
         at
org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
         at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
         at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)"
HADOOP-3080,Remove flush calls from JobHistory,"The flush calls from JobHistory should be removed. This has performance impact when lots of events are being logged to the history files since the JT lock (e.g. lostTracker where the tracker had ran a lot of tasks, and we call failedTask in a loop, etc.)"
HADOOP-3070,"Trash not being expunged, Trash Emptier thread gone by NPE","We noticed that the users' trash were not being expunged by the namenode. 

jstack didn't show the Trash.Emptier thread and .out file showed 

Exception in thread ""Trash Emptier"" java.lang.NullPointerException
  at org.apache.hadoop.fs.Trash.expunge(Trash.java:146)
  at org.apache.hadoop.fs.Trash$Emptier.run(Trash.java:233)
  at java.lang.Thread.run(Thread.java:619)


It seems like this happens when it hits the user's directory which doesn't contain the .Trash."
HADOOP-3030,InMemoryFileSystem.reserveSpaceWithChecksum does not look at failures while reserving space for the file in question,"The return statement code in InMemoryFileSystem.reserveSpaceWithCheckSum looks like
{noformat}
  return (mfs.reserveSpace(f, size) && mfs.reserveSpace(getChecksumFile(f), checksumSize));
{noformat}

This should be broken up to check for successful reserveSpace for each of the components. In some cases, we might reserve space for the first component and fail while doing the same for the second (checksum file). This will lead to wastage of space since we don't un-reserve the space we got for the first component. This usually won't happen due to the policy associated with creating a file in the InMemoryFileSystem (since the checksum component is usually very small) but still it should be fixed."
HADOOP-2955,ant test fail for TestCrcCorruption with OutofMemory.,"TestCrcCorruption sometimes corrupts the metadata for crc and leads to corruption in the length of of bytes of checksum (second field in metadata). This does not happen always but somtimes since corruption is random in the test.

I put in a debug statement in the allocation to see how many bytes were being allocated and ran it for few times. This is one of the allocation in 
BlockSender:sendBlock() 

 int maxChunksPerPacket = Math.max(1,
                      (BUFFER_SIZE + bytesPerChecksum - 1)/bytesPerChecksum);
        int sizeofPacket = PKT_HEADER_LEN + 
        (bytesPerChecksum + checksumSize) * maxChunksPerPacket;
        LOG.info(""Comment: bytes to allocate "" + sizeofPacket);
        ByteBuffer pktBuf = ByteBuffer.allocate(sizeofPacket);


The output in one of the allocations is 

 dfs.DataNode (DataNode.java:sendBlock(1766)) - Comment: bytes to allocate 1232596786

So we should check for number of bytes being allocated in sendBlock (should be less than the block size? -- seems like a good default).

"
HADOOP-2934,NPE while loading  FSImage,"Andr Martin reported on core-user mailing list :

{noformat} 
[...]
2008-03-02 01:25:29,887 ERROR org.apache.hadoop.dfs.NameNode: java.lang.NullPointerException
    at org.apache.hadoop.dfs.FSImage.readINodeUnderConstruction(FSImage.java:950)
    at org.apache.hadoop.dfs.FSImage.loadFilesUnderConstruction(FSImage.java:919)
    at org.apache.hadoop.dfs.FSImage.loadFSImage(FSImage.java:749)
    at org.apache.hadoop.dfs.FSImage.loadFSImage(FSImage.java:634)
    at org.apache.hadoop.dfs.FSImage.recoverTransitionRead(FSImage.java:223)
    at org.apache.hadoop.dfs.FSDirectory.loadFSImage(FSDirectory.java:79)
    at org.apache.hadoop.dfs.FSNamesystem.initialize(FSNamesystem.java:261)
    at org.apache.hadoop.dfs.FSNamesystem.<init>(FSNamesystem.java:242)
    at org.apache.hadoop.dfs.NameNode.initialize(NameNode.java:131)
    at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:176)
    at org.apache.hadoop.dfs.NameNode.<init>(NameNode.java:162)
    at org.apache.hadoop.dfs.NameNode.createNameNode(NameNode.java:851)
    at org.apache.hadoop.dfs.NameNode.main(NameNode.java:860)
{noformat}

Block object should be allocated before calling {{readFields()}} in FSImage.java : {code}
BlockInfo[] blocks = new BlockInfo[numBlocks];
for (int i = 0; i < numBlocks; i++) {
  blocks[i].readFields(in);
}
{code}

"
HADOOP-2905,fsck -move triggers NPE in namenode,"If I run hadoop fsck / -move, then the fsck fails to move any corrupt files.  In the namenode logs, I see this error message repeated 3 times:

2008-02-26 21:19:07,500 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 10000, call mkdirs(/lost+found, null) from x.x.x.135:60819: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.dfs.INode.setPermission(INode.java:123)
        at org.apache.hadoop.dfs.INode.setPermissionStatus(INode.java:86)
        at org.apache.hadoop.dfs.INode.<init>(INode.java:79)
        at org.apache.hadoop.dfs.INodeDirectory.<init>(INode.java:319)
        at org.apache.hadoop.dfs.FSDirectory.mkdirs(FSDirectory.java:633)
        at org.apache.hadoop.dfs.FSNamesystem.mkdirsInternal(FSNamesystem.java:1569)
        at org.apache.hadoop.dfs.FSNamesystem.mkdirs(FSNamesystem.java:1544)
        at org.apache.hadoop.dfs.NameNode.mkdirs(NameNode.java:420)
        at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:409)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:910)
2008-02-26 21:19:07,503 WARN org.apache.hadoop.dfs.NameNode: Cannot initialize /lost+found .
"
HADOOP-2863,FSDataOutputStream should not flush() inside close().,"Why does FSDataOutputStream.close() call flush()? This stream itself does not store any data that it needs to flush. It is a wrapper and it should just invoke its outputstream's close().

For. e.g one bad side effect is that, in the case of DFSOutputStream which extends FSOutputSummer, flush() inside close sends the current data even though FSOutputSummer might have some data.. this left over data will be sent in side close() (so it sends data in two different packets instead of one). Other filesystems might have similar side effects.

I will submit a patch.

"
HADOOP-2814,NPE in datanode during TestDataTransferProtocol.,"The test passes. But there is an NPE in datanode (using branch-0.16) :
{noformat}
...
2008-02-13 21:25:37,534 INFO  dfs.TestDataTransferProtocol (TestDataTransferProtocol.java:sendRecvData(71)) - Testing : wrong bytesPerChecksum while writing
2008-02-13 21:25:37,535 INFO  dfs.DataNode (DataNode.java:writeBlock(1048)) - Receiving block blk_7408940144175038455 src: /127.0.0.1:4964
6 dest: /127.0.0.1:49637
2008-02-13 21:25:37,536 ERROR dfs.DataNode (DataNode.java:run(961)) - 127.0.0.1:49637:DataXceiver: java.lang.NullPointerException
        at org.apache.hadoop.dfs.DataNode$BlockReceiver.close(DataNode.java:2001)
        at org.apache.hadoop.io.IOUtils.closeStream(IOUtils.java:131)
        at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:1993)
        at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1074)
        at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:938)
        at java.lang.Thread.run(Thread.java:595)

2008-02-13 21:25:37,537 INFO  dfs.TestDataTransferProtocol (TestDataTransferProtocol.java:sendRecvData(87)) - Got EOF as expected.
...
{noformat}
"
HADOOP-2789,Race condition in ipc.Server prevents responce being written back to client.,"I encountered a race condition in ipc.Server when writing the response
back to the socket. Sometimes the write SelectKey is being canceled
when it should not be, and thus the full response never gets
written. This results in clients timing out on the socket while waiting for the response.

I am attaching a unit test that demonstrates the problem. It follows
closely the TestIPC test, however the socket output buffer is set
smaller than the result being sent back, so that partial writes
occur. I also put random sleep in the client to help provoke the race
condition.

On my machine this fails over half of the time.

Looking at the code in ipc.Server.java. The problem is manifested in
Responder.doAsyncWrite(). If I comment out the key.cancel() line, then
everything works fine. 

So we need to identify when to safely cancel the key.

I tried the following:

{noformat}
    private void doAsyncWrite(SelectionKey key) throws IOException {
      Call call = (Call)key.attachment();
      if (call == null) {
        return;
      }
      if (key.channel() != call.connection.channel) {
        throw new IOException(""doAsyncWrite: bad channel"");
      }
      if (processResponse(call.connection.responseQueue)) {
          synchronized(call.connection.responseQueue) {
              if (call.connection.responseQueue.size() == 0) {
                  LOG.info(""Cancelling key for call ""+call.toString()+ "" key: ""+ key.toString());
                  key.cancel();          // remove item from selector.
              } else {
                  LOG.warn(""NOT REALLY DONE: ""+call.toString()+ "" key: ""+ key.toString());
              }
          }
      }
    }
{noformat}

And this does catch some of the cases (EG, the LOG.warn message gets hit), but i still hit the race condition.
"
HADOOP-2765,setting memory limits for tasks,"here's the motivation:

we want to put a memory limit on user scripts to prevent runaway scripts from bringing down nodes. this setting is much lower than the max. memory that can be used (since most likely these tend to be scripting bugs). At the same time - for careful users, we want to be able to let them use more memory by overriding this limit.

there's no good way to do this. we can set ulimit in hadoop shell scripts - but they are very restrictive. there doesn't seem to be a way to do a setrlimit from Java - and setting a ulimit means that supplying a higher Xmx limit from the jobconf is useless (the java process will be limited by the ulimit setting when the tasktracker was launched).

what we have ended up doing (and i think this might help others as well) is to have a stream.wrapper option. the value of this option is a program through which streaming mapper and reducer scripts are execed. in our case, this wrapper is small C program to do a setrlimit and then exec of the streaming job. the default wrapper puts a reasonable limit on the memory usage - but users can easily override this wrapper (eg by invoking it with different memory limit argument). we can use the wrapper for other system wide resource limits (or any environment settings) as well in future.

This way - JVMs can stick to mapred.child.opts as the way to control memory usage. This setup has saved our ass on many occasions while allowing sophisticated users to use high memory limits.

Can submit patch if this sounds interesting."
HADOOP-2762,Better documentation of controls for memory limits on hadoop daemons and Map-Reduce tasks,"We have had a spate of questions about memory usage of hadoop daemons and Map-Reduce jobs and how to configure them. 

We should better document *mapred.child.java.opts* in the Map-Reduce tutorial and cluser_setup.html and link to http://hadoop.apache.org/core/docs/r0.15.3/cluster_setup.html#Configuring+the+Environment+of+the+Hadoop+Daemons. "
HADOOP-2758,Reduce memory copies when data is read from DFS,"Currently datanode and client part of DFS perform multiple copies of data on the 'read path' (i.e. path from storage on datanode to user buffer on the client). This jira reduces these copies by enhancing data read protocol and implementation of read on both datanode and the client. I will describe the changes in next comment.

Requirement is that this fix should reduce CPU used and should not cause regression in any benchmarks. It might not improve the benchmarks since most benchmarks are not cpu bound."
HADOOP-2756,NPE in DFSClient in hbase under load,"Saw this in logs:

{code}
2008-01-31 18:55:02,128 ERROR org.apache.hadoop.hbase.HRegionServer: Compaction failed for region TestTable,0009438931,1201805282651
java.lang.NullPointerException
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.close(DFSClient.java:2262)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:51)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:67)
        at org.apache.hadoop.hbase.HStoreFile.writeInfo(HStoreFile.java:365)
        at org.apache.hadoop.hbase.HStore.compact(HStore.java:1236) 
        at org.apache.hadoop.hbase.HRegion.compactStores(HRegion.java:775)
        at org.apache.hadoop.hbase.HRegion.compactIfNeeded(HRegion.java:707)
        at org.apache.hadoop.hbase.HRegionServer$CompactSplitThread.run(HRegionServer.java:253)
{code}

Look to see if the response data method needs to be made volatile (There's a test for null just before we use it on line #2262)."
HADOOP-2717,NPE while closing file.,"Saw this NPE in one of the hudson builds : 
{code}
java.lang.NullPointerException
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.close(DFSClient.java:2277)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:51)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:67)
	at org.apache.hadoop.dfs.TestCheckpoint.writeFile(TestCheckpoint.java:49)
	at org.apache.hadoop.dfs.TestCheckpoint.testSecondaryNamenodeError2(TestCheckpoint.java:231)
	at org.apache.hadoop.dfs.TestCheckpoint.testCheckpoint(TestCheckpoint.java:412)
{code}
{code}
        if (response != null) {
          response.join(); // line 2277
        }
{code}


"
HADOOP-2670,doDF frequently brings task down due to lack of memory,"we are running with -Xmx 1024M. Every once in a while, we see tasks failing because of:

java.io.IOException: java.io.IOException: Cannot allocate memory
	at java.lang.UNIXProcess.(UNIXProcess.java:148)
	at java.lang.ProcessImpl.start(ProcessImpl.java:65)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:451)
	at java.lang.Runtime.exec(Runtime.java:591)
	at java.lang.Runtime.exec(Runtime.java:464)
	at org.apache.hadoop.fs.DF.doDF(DF.java:60)
	at org.apache.hadoop.fs.DF.getAvailable(DF.java:99)
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:259)
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.createTmpFileForWrite(LocalDirAllocator.java:289)
	at org.apache.hadoop.fs.LocalDirAllocator.createTmpFileForWrite(LocalDirAllocator.java:155)
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.newBackupFile(DFSClient.java:1475)
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.openBackupStream(DFSClient.java:1442)
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.writeChunk(DFSClient.java:1600)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:140)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:122)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:112)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:86)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:39)
	at java.io.DataOutputStream.write(DataOutputStream.java:90)
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:822)
	at org.apache.hadoop.mapred.SequenceFileOutputFormat$1.write(SequenceFileOutputFormat.java:69)
	at org.apache.hadoop.mapred.ReduceTask$2.collect(ReduceTask.java:304)
	at com.facebook.hive.streaming.HiveJoin$JoinReduce.reduce(HiveJoin.java:546)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:322)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1743)

when the task re-runs - it succeeds. it seems like that this is an edge case where the garbage collector needs to be run before trying to spawn external process. (going to try it out). any other ideas?

"
HADOOP-2657,Enhancements to DFSClient to support flushing data at any point in time,"The HDFS Append Design (HADOOP-1700) requires that there be a public API to flush data written to a HDFS file that can be invoked by an application. This API (popularly referred to a fflush(OutputStream)) will ensure that data written to the DFSOutputStream is flushed to datanodes and any required metadata is persisted on Namenode.

This API has to handle the case when the client decides to flush after writing data that is not a exact multiple of io.bytes.per.checksum."
HADOOP-2538,NPE in TaskLog.java,"In the tasktracker web ui, if I go to

/tasklog?taskid=task_200801020752_0383_m_000000_0&all=true&plaintext=true

which corresponds to a short log (<4k), I get a 500 in the web ui, and this NPE in the tasktracker log:

2008-01-07 21:02:13,935 WARN /: /tasklog?taskid=task_200801020752_0383_m_000000_
0&all=true&plaintext=true: 
java.lang.NullPointerException
        at org.apache.hadoop.mapred.TaskLog.getTaskLogFile(TaskLog.java:48)
        at org.apache.hadoop.mapred.TaskLog$Reader.<init>(TaskLog.java:124)
        at org.apache.hadoop.mapred.TaskLogServlet.printTaskLog(TaskLogServlet.j
ava:44)
        at org.apache.hadoop.mapred.TaskLogServlet.doGet(TaskLogServlet.java:134
)

Note that /tasklog?taskid=task_200801020752_0383_m_000000_0&all=true&plaintext=true is an invalid url; the url should look like &plaintext=true&filter=STDOUT"
HADOOP-2486,Dropping records at reducer.  InMemoryFileSystem NPE.,"Note: I'm really not sure if this is a bug in my code or in mapred. 

With my mapreduce job without combiner,  I sometimes see   # of total Map output records != # of total Reduce input records. What's weird to me is, when I rerun my code with exact same input, usually I get an expected #map output recs == #reduce output recs.

Both jobs finish successfully. No failed tasks. No speculative execution. 

I ran separate linecount mapred jobs on both the input and the output to see if  the counters are reporting the correct number. 


When I looked at all the 513 reducer counter, I found single reducer with different counts for the two runs. 
Only error stood out in that  reducer userlog is, 
{noformat} 
2007-12-22 00:19:07,640 INFO org.apache.hadoop.mapred.ReduceTask: task_200712220008_0003_r_000024_0 done copying task_200712220008_0003_m_000288_0 output from qqq856.ppp.com.
2007-12-22 00:19:07,640 INFO org.apache.hadoop.mapred.ReduceTask: task_200712220008_0003_r_000024_0 Copying task_200712220008_0003_m_000327_0 output from qqq887.ppp.com.
2007-12-22 00:19:07,640 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:380)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)
	at org.apache.hadoop.fs.FileSystem.isDirectory(FileSystem.java:423)
	at org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:386)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:716)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:637)

2007-12-22 00:19:07,641 INFO org.apache.hadoop.mapred.ReduceTask: task_200712220008_0003_r_000024_0 done copying task_200712220008_0003_m_000228_0 output from qqq801.ppp.com.
2007-12-22 00:19:07,641 INFO org.apache.hadoop.mapred.ReduceTask: task_200712220008_0003_r_000024_0 Copying task_200712220008_0003_m_000337_0 output from qqq841.ppp.com.
{noformat} 

Could this error be somehow related to my having different # of records? 
"
HADOOP-2391,Speculative Execution race condition with output paths,"I am tracking a problem where when speculative execution is enabled, there is a race condition when trying to read output paths from a previously completed job.  More specifically when reduce tasks run their output is put into a working directory under the task name until the task in completed.  The directory name is something like workdir/_taskid.  Upon completion the output get moved into workdir.  Regular tasks are checked for this move and not considered completed until this move is made.  I have not verified it but all indications point to speculative tasks NOT having this same check for completion and more importantly removal when killed.  So what we end up with when trying to read the output of previous tasks with speculative execution enabled is the possibility that previous workdir/_taskid will be present when the output directory is read by a chained job.  Here is an error when supports my theory:

Generator: org.apache.hadoop.ipc.RemoteException: java.io.IOException: Cannot open filename /u01/hadoop/mapred/temp/generate-temp-1197104928603/_task_200712080949_0005_r_000014_1
        at org.apache.hadoop.dfs.NameNode.open(NameNode.java:234)
        at sun.reflect.GeneratedMethodAccessor64.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:389)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:644)
        at org.apache.hadoop.ipc.Client.call(Client.java:507)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:186)
        at org.apache.hadoop.dfs.$Proxy0.open(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
        at org.apache.hadoop.dfs.$Proxy0.open(Unknown Source)
        at org.apache.hadoop.dfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:839)
        at org.apache.hadoop.dfs.DFSClient$DFSInputStream.<init>(DFSClient.java:831)
        at org.apache.hadoop.dfs.DFSClient.open(DFSClient.java:263)
        at org.apache.hadoop.dfs.DistributedFileSystem.open(DistributedFileSystem.java:114)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1356)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1349)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1344)
        at org.apache.hadoop.mapred.SequenceFileOutputFormat.getReaders(SequenceFileOutputFormat.java:87)
        at org.apache.nutch.crawl.Generator.generate(Generator.java:429)
        at org.apache.nutch.crawl.Generator.run(Generator.java:563)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolBase.doMain(ToolBase.java:54)
        at org.apache.nutch.crawl.Generator.main(Generator.java:526)

I will continue to research this and post as I make progress on tracking down this bug."
HADOOP-2323,JobTracker.close() prints stack traces for exceptions that are not errors,"JobTracker.close() prints a stack trace for an interrupted exception even though it was the method that interrupted the thread that threw the exception. For example:

{code}
      this.expireTrackers.stopTracker();
      try {
        this.expireTrackersThread.interrupt();
        this.expireTrackersThread.join();
      } catch (InterruptedException ex) {
        ex.printStackTrace();
      }
{code}

Well of course it is going to catch an InterruptedException after it just interrupted the thread!

This is *not* an error and should  *not* be dumped to the logs!

In other circumstances, catching InterruptedException is entirely appropriate. Just not in close where you've told the thread to shutdown and then interrupted it to ensure it does!"
HADOOP-2095,Reducer failed due to Out ofMemory,"One of the reducers of my job failed with the following exceptions.
The failure caused the whole job fail eventually.
Java heapsize was 768MB and sort.io.mb was 140.


2007-10-23 19:24:06,100 WARN org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Intermediate Merge of the inmemory files threw an exception: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.io.compress.DecompressorStream.(DecompressorStream.java:43)
	at org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:71)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1345)
	at org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1231)
	at org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1154)
	at org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor.nextRawKey(SequenceFile.java:2726)
	at org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:2543)
	at org.apache.hadoop.io.SequenceFile$Sorter.merge(SequenceFile.java:2297)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$InMemFSMergeThread.run(ReduceTask.java:1311)
2007-10-23 19:24:06,102 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 done copying task_200710231912_0001_m_001428_0 output .
2007-10-23 19:24:06,185 INFO org.apache.hadoop.fs.FileSystem: Initialized InMemoryFileSystem: ramfs://mapoutput31952838/task_200710231912_0001_r_000020_2/map_1423.out-0 of size (in bytes): 209715200
2007-10-23 19:24:06,193 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)

2007-10-23 19:24:06,193 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001215_0 output from xxx
2007-10-23 19:24:06,188 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001211_0 output from xxx
2007-10-23 19:24:06,185 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryOutputStream.close(InMemoryFileSystem.java:161)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:49)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:64)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.close(ChecksumFileSystem.java:312)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:49)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:64)
	at org.apache.hadoop.mapred.MapOutputLocation.getFile(MapOutputLocation.java:253)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:713)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)

2007-10-23 19:24:06,199 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001247_0 output from .
2007-10-23 19:24:06,200 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)

2007-10-23 19:24:06,204 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001422_0 output from .
2007-10-23 19:24:06,207 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)

2007-10-23 19:24:06,209 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001278_0 output from .
2007-10-23 19:24:06,198 WARN org.apache.hadoop.mapred.TaskTracker: Error running child
java.io.IOException: task_200710231912_0001_r_000020_2The reduce copier failed
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:253)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1760)
2007-10-23 19:24:06,198 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)

2007-10-23 19:24:06,231 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001531_0 output from .
2007-10-23 19:24:06,197 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)

2007-10-23 19:24:06,237 INFO org.apache.hadoop.mapred.ReduceTask: task_200710231912_0001_r_000020_2 Copying task_200710231912_0001_m_001227_0 output from .
2007-10-23 19:24:06,196 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$FileAttributes.access$300(InMemoryFileSystem.java:366)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryFileStatus.(InMemoryFileSystem.java:378)
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:283)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)
	at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:449)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:738)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:665)

"
HADOOP-2054,Improve memory model for map-side sorts,"{{MapTask#MapOutputBuffer}} uses a plain-jane {{DataOutputBuffer}} which defaults to a buffer of size 32-bytes, and the {{DataOutputBuffer#write}} call doubles the underlying byte-array when it needs more space.

However for maps which output any decent amount of data (e.g. 128MB in examples/Sort.java) this means the buffer grows painfully slowly from 2^6 to 2^28, and each time this results in a new array being created, followed by an array-copy:

{noformat}
    public void write(DataInput in, int len) throws IOException {
      int newcount = count + len;
      if (newcount > buf.length) {
        byte newbuf[] = new byte[Math.max(buf.length << 1, newcount)];
        System.arraycopy(buf, 0, newbuf, 0, count);
        buf = newbuf;
      }
      in.readFully(buf, count, len);
      count = newcount;
    }
{noformat}

I reckon we could do much better in the {{MapTask}}, specifically... 

For e.g. we start with a buffer of size 1/4KB and quadruple, rather than double, upto, say 4/8/16MB. Then we resume doubling (or less).

This means that it quickly ramps up to minimize no. of {{System.arrayCopy}} calls and small-sized buffers to GC; and later start doubling to ensure we don't ramp-up too quickly to minimize memory wastage due to fragmentation.

Of course, this issue is about benchmarking and figuring if all this is worth it, and, if so, what are the right set of trade-offs to make.

Thoughts?"
HADOOP-2016,Race condition in removing a KILLED task from tasktracker,"I ran into a situation where a speculative task was killed by the JobTracker and the relevant TaskTracker got the right KillTaskAction, but the tasktracker continued to hold a reference to that task (although the task jvm was killed). The task continued to be in RUNNING state in both the JobTracker and that TaskTracker for ever. I suspect there is some race condition in reading/updating datastructures inside the taskCleanupThread & transmitHeartBeat."
HADOOP-2001,Deadlock in jobtracker,"My jobtracker deadlocked; the output from kill -QUIT is:

Found one Java-level deadlock:
=============================
""IPC Server handler 2 on 10001"":
  waiting to lock monitor 0x0813724c (object 0xd5175488, a org.apache.hadoop.mapred.JobInProgress),
  which is held by ""SocketListener0-1""
""SocketListener0-1"":
  waiting to lock monitor 0x081146d4 (object 0xd24d9c50, a org.apache.hadoop.mapred.JobTracker),
  which is held by ""IPC Server handler 2 on 10001""

Java stack information for the threads listed above:
===================================================
""IPC Server handler 2 on 10001"":
        at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:367)
        - waiting to lock <0xd5175488> (a org.apache.hadoop.mapred.JobInProgress)
        at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:1719)
        at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:1240)
        - locked <0xd24d9c50> (a org.apache.hadoop.mapred.JobTracker)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:1116)
        - locked <0xd24d9c50> (a org.apache.hadoop.mapred.JobTracker)
        at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:340)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:566)
""SocketListener0-1"":
        at org.apache.hadoop.mapred.JobTracker.finalizeJob(JobTracker.java:907)
        - waiting to lock <0xd24d9c50> (a org.apache.hadoop.mapred.JobTracker)
        at org.apache.hadoop.mapred.JobInProgress.garbageCollect(JobInProgress.java:1059)
        - locked <0xd5175488> (a org.apache.hadoop.mapred.JobInProgress)
        at org.apache.hadoop.mapred.JobInProgress.kill(JobInProgress.java:891)
        - locked <0xd5175488> (a org.apache.hadoop.mapred.JobInProgress)
        at org.apache.hadoop.mapred.jobdetails_jsp._jspService(jobdetails_jsp.java:158)
        at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:94)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
        at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
        at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
        at org.mortbay.http.HttpServer.service(HttpServer.java:954)
        at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
        at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
        at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
        at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
        at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)

Found 1 deadlock."
HADOOP-1973,NPE at JobTracker startup..,"At JT startup a bunch of these were thrown.. and the JT shutdown. 

2007-10-01 07:48:36,501 WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find record of 'previous' heartbeat for '[tracker_address]:/127.0.0.1:40205'; reinitializing the tasktracker
2007-10-01 07:48:36,504 WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find record of 'previous' heartbeat for '[tracker_address]:/127.0.0.1:57935'; reinitializing the tasktracker
2007-10-01 07:48:36,520 WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find record of 'previous' heartbeat for '[tracker_address]:/127.0.0.1:46305'; reinitializing the tasktracker
2007-10-01 07:48:36,523 WARN org.apache.hadoop.mapred.JobTracker: Serious problem, cannot find record of 'previous' heartbeat for '[tracker_address]:/127.0.0.1:55988'; reinitializing the tasktracker
2007-10-01 07:48:36,524 INFO org.apache.hadoop.ipc.Server: IPC Server handler 28 on 50020, call getFilesystemName() from [tracker_ip]:47361: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobTracker.getFilesystemName(JobTracker.java:1458)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:340)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)
"
HADOOP-1949,NPE in IPC handler.,"Noticed a few of the following traces during upgrade of a large cluster to 0.14.1 :

{noformat}
2007-09-26 17:21:40,134 WARN org.apache.hadoop.ipc.Server: IPC Server handler 20 on 8020, call 
processUpgradeCommand(org.apache.hadoop.dfs.BlockCrcUpgradeUtils$CrcInfoCommand@2b9c5c9d) 
from 192.0.0.100:40500: output error
java.lang.NullPointerException
        at org.apache.hadoop.ipc.SocketChannelOutputStream.flushBuffer(SocketChannelOutputStream.java:108)
        at org.apache.hadoop.ipc.SocketChannelOutputStream.write(SocketChannelOutputStream.java:89)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:585)
{noformat}


"
HADOOP-1895,sort fails with OutOfMemoryExceptions,"sort100
> 
> java.lang.OutOfMemoryError: Java heap space at
> java.util.Arrays.copyOf(Arrays.java:2786) at
> java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:94) at
> java.io.DataOutputStream.write(DataOutputStream.java:90) at
> org.apache.hadoop.io.BytesWritable.write(BytesWritable.java:137) at
> org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTa
> sk.java:349)
> at
> org.apache.hadoop.mapred.lib.IdentityMapper.map(IdentityMapper
> .java:40)
> at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50) at
> org.apache.hadoop.mapred.MapTask.run(MapTask.java:192) at
> org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1785)
> "
HADOOP-1885,Race condition in MiniDFSCluster shutdown,"Hudson has been sporadically failing tests that start- or follow tests that start- multiple datanodes in MiniDFSCluster, particularly on Solaris and Windows. The following appears to be at least partially responsible (much credit to Nigel for helping to discern this).

A common error:
{noformat}
java.io.IOException: Cannot remove data directory: /export/home/hudson/hudson/jobs/Hadoop-Nightly/workspace/trunk/build/test/data/dfs/data
	at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:126)
	at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:80)
	at org.apache.hadoop.dfs.TestFsck.testFsckNonExistent(TestFsck.java:96)
{noformat}

MiniDFSCluster starts multiple DataNodes by calling DataNode::createDataNode, which creates and starts a DataNode thread, assigns the instance to a static member, and returns the Runnable. Of course, each call from MiniDFSCluster overwrites this instance. Since DataNode::shutdown() calls join() on the same Thread, each subsequent join is essentially a noop after the first DataNode finishes. When MiniDFSCluster::shutdown() returns, it may not have released its resources, so the next MiniDFSCluster may fail to start."
HADOOP-1857,Ability to run a script when a task fails to capture stack traces,"This basically is for providing a better user interface for debugging failed
jobs. Today we see stack traces for failed tasks on the job ui if the job
happened to be a Java MR job. For non-Java jobs like Streaming, Pipes, the
diagnostic info on the job UI is not helpful enough to debug what might have
gone wrong. They are usually framework traces and not app traces.
We want to be able to provide a facility, via user-provided scripts, for doing
post-processing on task logs, input, output, etc. There should be some default
scripts like running core dumps under gdb for locating illegal instructions,
the last few lines from stderr, etc.  These outputs could be sent to the
tasktracker and in turn to the jobtracker which would then display it on the
job UI on demand.

"
HADOOP-1837,Insufficient space exception from InMemoryFileSystem after raising fs.inmemory.size.mb,"trying out larger in-memory file system (curious if that helped speed the sort phase). in this run - i had sized it to 500MB. There's plenty of RAM in the machine (8GB) and the tasks are launched with -Xmx2048 option (so there's plenty of heap space as well). However - observing this exception:

2007-09-04 13:47:51,718 INFO org.apache.hadoop.mapred.ReduceTask: task_0002_r_000002_0 Copying task_0002_m_000124_0 output from hadoop004.sf
2p.facebook.com.
2007-09-04 13:47:52,188 WARN org.apache.hadoop.mapred.ReduceTask: task_0002_r_000002_0 copy failed: task_0002_m_000124_0 from hadoop004.sf2p
.facebook.com
2007-09-04 13:47:52,189 WARN org.apache.hadoop.mapred.ReduceTask: java.io.IOException: Insufficient space
        at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem$InMemoryOutputStream.write(InMemoryFileSystem.java:181)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:38)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:91)
        at org.apache.hadoop.fs.ChecksumFileSystem$FSOutputSummer.close(ChecksumFileSystem.java:416)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:48)
        at org.apache.hadoop.fs.FSDataOutputStream$Buffer.close(FSDataOutputStream.java:72)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:92)
        at org.apache.hadoop.mapred.MapOutputLocation.getFile(MapOutputLocation.java:251)
        at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:680)
        at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:641)

2007-09-04 13:47:52,189 WARN org.apache.hadoop.mapred.ReduceTask: task_0002_r_000002_0 adding host hadoop004.sf2p.facebook.com to penalty bo
x, next contact in 64 seconds

so this ends up slowing stuff down since we backoff on the source host (even though it's not it's fault).  Looking at the code, seems like ReduceTask is trying to write more to InMemoryFileSystem than it should.

"
HADOOP-1771,streaming hang when IOException in MROutputThread. (NPE),"One streaming task hang and had stderr userlog as follows.

{code}
Exception in thread ""Thread-5"" java.lang.NullPointerException
         at java.lang.Throwable.printStackTrace(Throwable.java:460)
         at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run(PipeMapRed.java:352)
{code}

In PipeMapRed.java
{code}
351       } catch (IOException io) {
352         io.printStackTrace(log_);
353         outerrThreadsThrowable = io;
{code}

I guess log_ is  Null... Should call logStackTrace.

"
HADOOP-1696,NPE in TestDistributedUpgrade,"The TestDistributedUpgrade test fails once a while with the following stack trace:

java.lang.NullPointerException
    at org.apache.hadoop.dfs.FSImage.getDistributedUpgradeState(FSImage.java:1036)
    at org.apache.hadoop.dfs.FSImage.setFields(FSImage.java:411)
    at org.apache.hadoop.dfs.Storage$StorageDirectory.write(Storage.java:169)
    at org.apache.hadoop.dfs.UpgradeUtilities.createVersionFile(UpgradeUtilities.java:306)
    at org.apache.hadoop.dfs.TestDistributedUpgrade.testDistributedUpgrade(TestDistributedUpgrade.java:100)
"
HADOOP-1687,Name-node memory size estimates and optimization proposal.,"I've done some estimates on how much space our data structures take on the name-node per block, file and directory.

Brief overview of the data structures:
Directory tree (FSDirectory) is built of inodes. Each INode points either to an array of blocks
if it corresponds to a file or to a TreeMap<String, INode> of children INodes if it is a directory.
[Note: this estimates were made before Dhruba replaced the children TreeMap by ArrayList.]
Each block participates also in at least 2 more data structures.
BlocksMap contains a HashMap<Block, BlockInfo> of all blocks mapping a Block into a BlockInfo.
DatanodeDescriptor contains a TreeMap<Block, Block> of all blocks belonging to this data-node.
A block may or may not be contained also in other data-structures, like
{code}
UnderReplicatedBlocks
PendingReplicationBlocks
recentInvalidateSets
excessReplicateMap
{code}
Presence of a block in any of these structures is temporary and therefore I do not count them in my estimates.
The estimates can be viewed as lower bounds.

These are some classes that we are looking at here
{code}
class INode {
   String name;
   INode parent;
   TreeMap<String, INode> children;
   Block blocks[];
   short blockReplication;
   long modificationTime;
}

class Block {
   long blkid;
   long len;
}

class BlockInfo {
   FSDirectory.INode       inode;
   DatanodeDescriptor[]   nodes;
   Block                          block;
}
{code}

The calculations are made for a 64-bit java vm based on that
Reference size = 8 bytes
Object header size = 16 bytes
Array header size = 24 bytes

Commonly used objects:
TreeMap.Entry = 64 bytes. It has 5 reference fields
HashMap.Entry = 48 bytes. It has 3 reference fields
String header = 64 bytes.

The size of a file includes:
# Size of an empty file INode: INode.children = null, INode.blocks is a 0-length array, and file name is empty. (152 bytes)
# A directory entry of the parent INode that points to this file, which is a TreeMap.Entry. (64 bytes)
# file name length times 2, because String represents each name character by 2 bytes.
# Reference to the outer FSDirectory class (8 bytes)

The total: 224 + 2 * fileName.length

The size of a directory includes:
# Size of an empty directory INode: INode.children is an empty TreeMap, INode.blocks = null, and file name is empty. (192 bytes)
# A directory entry of the parent INode that points to this file, which is a TreeMap.Entry. (64 bytes)
# file name length times 2
# Reference to the outer FSDirectory class (8 bytes)

The total: 264 + 2 * fileName.length

The size of a block includes:
# Size of Block. (32 bytes)
# Size of BlockInfo. (64 + 8*replication bytes)
# Reference to the block from INode.blocks (8 bytes)
# HashMap.Entry referencing the block from BlocksMap. (48 bytes)
# References to the block from all DatanodeDescriptors it belongs to.
This is a TreeMap.Entry size times block replication. (64 * replication)

The total: 152 + 72 * replication

Typical object sizes:
Taking into account that typical file name is 10-15 bytes and our default replication is 3 we can say that typical sizes are
File size: 250
Directory size: 290
Block size: 368

||Object||size estimate (bytes)||typical size (bytes)||
|File|224 + 2 * fileName.length|250|
|Directory|264 + 2 * fileName.length|290|
|Block|152 + 72 * replication|368|

One of our clusters has
# Files:  10 600 000
# Dirs:      310 000
# Blocks: 13 300 000

Total Size (estimate): 7,63 GB
Memory used on the name-node (actual reported by jconsole after gc): 9 GB

This means that other data structures like NetworkTopology, heartbeats, datanodeMap, Host2NodesMap,
leases, sortedLeases, and multiple block replication maps occupy ~1.4 GB, which seems to be pretty high
and need to be investigated as well.

Based on the above estimates blocks should be the main focus of the name-node memory reduction effort.
Space used by a block is 50% larger compared to a file, and there is more blocks than files or directories.

Some ideas on how we can reduce the name-node size without substantially changing the data structures.
# INode.children should be an ArrayList instead of a TreeMap. Already done HADOOP-1565. (-48 bytes)
# Factor out the INode class into a separate class (-8 bytes)
# Create base INode class and derive file inode and directory inode classes from the base.
Directory inodes do not need to contain blocks and replication fields (-16 bytes)
File inodes do not need to contain children field (-8 bytes)
# String name should be replaced by a mere byte[]. (-(40 + fileName.length) ~ -50 bytes)
# Eliminate the Block object.
We should move Block fields into into BlockInfo and completely get rid of the Block object. (-16 bytes)
# Block object is referenced at least 5 times in our structures for each physical block.
The number of references should be reduced to just 2. (-24)
# Remove name field from INode. File or directory name is stored in the corresponding directory
entry and does need to be duplicated in the INode (-8 bytes)
# Eliminate INode.parent field. INodes are accessed through the directory tree, and the parent can
be remembered in a local variable while browsing the tree. There is no need to persistently store
the parent reference for each object. (-8 bytes)
# Need to optimize data-node to block map. Currently each DatanodeDescriptor holds a TreeMap of
blocks contained in the node, and we have an overhead of one TreeMap.Entry per block replica.
I expect we can reorganize datanodeMap in a way that it stores only 1 or 2 references per replica
instead of an entire TreeMap.Entry. (-48 * replication)

Note: In general TreeMaps turned out to be very expensive, we should avoid using them if possible.
Or implement a custom map structure, which would avoid using objects for each map entry.


This is what we will have after all the optimizations
||Object||size estimate (bytes)||typical size (bytes)||current typical size (bytes)||
|File|112 + fileName.length|125|250|
|Directory|144 + fileName.length|155|290|
|Block|112 + 24 * replication|184|368|
"
HADOOP-1675,Null pointer exception in InMemoryFileSystem,"In a job running release .13, I saw a lot of failures due to the following errors:

2007-08-03 16:13:39,516 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.reserveSpace(InMemoryFileSystem.java:361)
	at org.apache.hadoop.fs.InMemoryFileSystem.reserveSpaceWithCheckSum(InMemoryFileSystem.java:474)
	at org.apache.hadoop.mapred.MapOutputLocation.getFile(MapOutputLocation.java:220)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:680)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:641)


"
HADOOP-1636,constant should be user-configurable: MAX_COMPLETE_USER_JOBS_IN_MEMORY,"In JobTracker.java:   static final int MAX_COMPLETE_USER_JOBS_IN_MEMORY = 100;

This should be configurable."
HADOOP-1602,TaskLog.java buffers entire task userlog in memory,"While working on HADOOP-1524, I noticed that TaskLog.Reader.fetchAll() pulls the entire userlog into a giant byte[] and returns the byte[].  This won't work well for large logs.  TaskLog should return an InputStream instead."
HADOOP-1565,DFSScalability: reduce memory usage of namenode,"Experiments have demonstrated that a single file/block needs about 300 to 500 bytes of main memory on a 64-bit Namenode. This puts some limitations on the size of the file system that a single namenode can support. Most of this overhead occurs because a block and/or filename is inserted into multiple TreeMaps and/or HashSets.

Here are a few ideas that can be measured to see if an appreciable reduction of memory usage occurs:

1. Change FSDirectory.children from a TreeMap to an array. Do binary search in this array while looking up children. This saves a TreeMap object for every intermediate node in the directory tree.
2. Change INode from an inner class. This saves on one ""parent object"" reference for each INODE instance. 4 bytes per inode.
3. Keep all DatanodeDescriptors in an array. BlocksMap.nodes[] is currently a 64-bit reference to the DatanodeDescriptor object. Instead, it can be a 'short'. This will probably save about 16 bytes per block.
4. Change DatanodeDescriptor.blocks from a SortedTreeMap to a HashMap? Block report processing CPU cost can increase.

For the records: TreeMap has the following fields:
	Object key;
	Object value;
	Entry left = null;
	Entry right = null;
	Entry parent;
	boolean color = BLACK;

and HashMap object:
	final Object key;
	Object value;
	final int hash;
	Entry next;
"
HADOOP-1541,ipc.Server INFO message shouldn't include an Exception trace,"I see a lot of these in the NN log.  I don't think an INFO message should contain an error message and stack trace.

2007-06-28 00:21:51,057 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call getFileInfo(/user/hadoopqa/mapred.loadtest/intermediateouts) from 2.2.2.2:47476: error: java.io.IOException: File does not exist
java.io.IOException: File does not exist
        at org.apache.hadoop.dfs.FSDirectory.getFileInfo(FSDirectory.java:716)
        at org.apache.hadoop.dfs.FSNamesystem.getFileInfo(FSNamesystem.java:1178)
        at org.apache.hadoop.dfs.NameNode.getFileInfo(NameNode.java:479)
        at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:340)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:566)
"
HADOOP-1529,user logs do not seem to be flushed,"The user logs of applications using pipes interface often do not seem to have the user logs flushed. In particular, log messages from the close() method are often missing."
HADOOP-1513,A likely race condition between the creation of a directory and checking for its existence in the DiskChecker class,"Got this exception in a job run. It looks like the problem is a race condition between the creation of a directory and checking for its existence. Specifically, the line:
if (!dir.exists() && !dir.mkdirs()), doesn't seem safe when invoked by multiple processes at the same time. 

2007-06-21 07:55:33,583 INFO org.apache.hadoop.mapred.MapTask: numReduceTasks: 1
2007-06-21 07:55:33,818 WARN org.apache.hadoop.fs.AllocatorPerContext: org.apache.hadoop.util.DiskChecker$DiskErrorException: can not create directory: /export/crawlspace/kryptonite/ddas/dfs/data/tmp
	at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:26)
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.createPath(LocalDirAllocator.java:211)
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:248)
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.createTmpFileForWrite(LocalDirAllocator.java:276)
	at org.apache.hadoop.fs.LocalDirAllocator.createTmpFileForWrite(LocalDirAllocator.java:155)
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.newBackupFile(DFSClient.java:1171)
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.(DFSClient.java:1136)
	at org.apache.hadoop.dfs.DFSClient.create(DFSClient.java:342)
	at org.apache.hadoop.dfs.DistributedFileSystem$RawDistributedFileSystem.create(DistributedFileSystem.java:145)
	at org.apache.hadoop.fs.ChecksumFileSystem$FSOutputSummer.(ChecksumFileSystem.java:368)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:254)
	at org.apache.hadoop.io.SequenceFile$Writer.(SequenceFile.java:675)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:165)
	at org.apache.hadoop.examples.RandomWriter$Map.map(RandomWriter.java:137)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:46)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:189)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1740)

2007-06-21 07:55:33,821 WARN org.apache.hadoop.mapred.TaskTracker: Error running child"
HADOOP-1479,NPE in HStore#get if StoreFile only has keys < than passed key,HStore#get throws a NPE because it doesn't allow MapFile.Reader#getClosest returning null. MapFile.Reader#getClosest returns null if passed a key that is > than all keys contained in the MapFile.
HADOOP-1461,Corner-case deadlock in TaskTracker,"Thanks to Koji for the attached stack-trace...

Summary:

main()
  -> offerService()
    -> markUnresponsiveTasks (locks the TaskTracker here)
      -> purgeTask() 
        -> removeTaskFromJob (waiting to lock the RunningJob object)

taskCleanup
  -> purgeJob (locks the RunningJob object)
    -> TIP.jobHasFinished()
      -> TIP.cleanup (waiting to lock the TaskTracker)

-*-*-

Clear-case of ordering issues during synchronization... it's a corner-case since it depends on the child-vm getting unresponsive _and_ the cleanup thread kicking in; which is why I'm marking this for 0.14.0 rather than 0.13.0 - what do others think about this?

-*-*-

Two possible solutions to break the deadlock cycle:

a) Make TaskTracker.purgeJob a synchronized method, thus it locks the TaskTracker before locking the RunningJob method.
b) Make the TaskTracker.tasks map a *Collections.synchronizedMap*, thus doing away with the need to lock the TaskTracker in TIP.cleanup

I'd prefer a) since the TaskTracker.tasks is referenced in multiple places in synchronized methods... and hence is a less intrusive change.

-*-*- 

Thoughts?
"
HADOOP-1399,Provide the ability to cache column data in memory,"Bigtable allows column families to be served out of memory to reduce disk accesses.

Issues with this are:
- need region server row/value caching and block caching
- maintaining read cache coherency while writes are on-going."
HADOOP-1388,Possible Null Pointer Dereference in taskdetails.jsp,Possible null pointer dereference of TaskStatus[]
HADOOP-1360,Possible null pointer dereference of thisAuthority in FileSystem.checkPath(Path),"FileSystem.java line 227

    if (!(this.getUri().getScheme().equals(uri.getScheme()) &&
          (thisAuthority == null && thatAuthority == null)
          || thisAuthority.equals(thatAuthority)))

I'm not convinced that this couldn't produce a NPE on thisAuthority.  This logic should be simplified to ensure it's correctness"
HADOOP-1355,Possible null pointer dereference in TaskLogAppender.append(LoggingEvent),"TaskLogAppender.java line 49

this.layout is checked for null on line 43, then it is dereferenced on line 49"
HADOOP-1354,Null pointer dereference of paths in FsShell.dus(String),"FsShell.java line 372
has a guaranteed NPE.

Perhaps && was supposed to be ||"
HADOOP-1353,Null pointer dereference of nodeInfo in FSNamesystem.removeDatanode(DatanodeID),"FSNamesystem.java line 1816
Guaranteed NPE."
HADOOP-1346,Provide alternatives to merge sort while sorting map output values in memory,"Currently we have only do a merge sort while sorting map output. We can have alternatives to this for the user to choose from, in particular, QuickSort could provide a good improvement."
HADOOP-1319,"NPE in TaskLog.getTaskLogDir, as called from tasklog.jsp","Calling TaskCompletionEvent.getTaskTrackerHttp() gives me an url that looks like http://tasktracker.host:50060/tasklog.jsp?plaintext=true&taskid=task_0264_m_000083_0&all=true.  If I try to access that URL, I get a Jetty 500 error.  In my tasktracker logs, I then see:

2007-05-02 21:32:16,107 WARN /: /tasklog.jsp?taskid=task_0261_m_000000_0&all=true&
plaintext=true: 
java.lang.NullPointerException
        at org.apache.hadoop.mapred.TaskLog.getTaskLogDir(TaskLog.java:49)
        at org.apache.hadoop.mapred.TaskLog.access$000(TaskLog.java:33)
        at org.apache.hadoop.mapred.TaskLog$Reader.<init>(TaskLog.java:313)
        at org.apache.hadoop.mapred.tasklog_jsp.printTaskLog(tasklog_jsp.java:26)
        at org.apache.hadoop.mapred.tasklog_jsp._jspService(tasklog_jsp.java:232)
        at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:94)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
        at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplication
Handler.java:475)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567
)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
        at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationCo
ntext.java:635)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
        at org.mortbay.http.HttpServer.service(HttpServer.java:954)
        at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
        at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
        at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
        at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:24
4)
        at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)
"
HADOOP-1264,OutOfMemoryError while running sort example,"The problem is reproducible, and I get this stacktrace:

java.io.IOException: Job failed!
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:604)
        at org.apache.hadoop.examples.Sort.main(Sort.java:115)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:143)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:40)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:155)


java.lang.OutOfMemoryError: Java heap space
        at java.util.Arrays.copyOf(Arrays.java:2786)
        at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:94)
        at java.io.DataOutputStream.write(DataOutputStream.java:90)
        at org.apache.hadoop.io.BytesWritable.write(BytesWritable.java:138)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:318)
        at org.apache.hadoop.mapred.lib.IdentityMapper.map(IdentityMapper.java:39)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:48)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:175)
        at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1445)"
HADOOP-1253,ConcurrentModificationException and NPE in JobControl,"toArrayList(Hashtable jobs) in JobControl.java isn't synchronized and it resulted in a ConcurrentModificationException.
checkRunningState in Job.java can throw a NullPointerException if running = jc.getJob(this.mapredJobID) fails, leaving running null."
HADOOP-1241,Null PointerException in processReport when namenode is restarted,"INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 8020 call error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.dfs.FSNamesystem.shouldNodeShutdown(FSNamesystem.java:3341)
        at org.apache.hadoop.dfs.FSNamesystem.processReport(FSNamesystem.java:2075)
        at org.apache.hadoop.dfs.NameNode.blockReport(NameNode.java:661)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:339)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:573)
INFO org.apache.hadoop.dfs.StateChange: BLOCK* NameSystem.registerDatanode: node registration from xx.xx.xx.xx:50010 storage DS-355824822
INFO org.apache.hadoop.dfs.NameNode: BLOCK* NameSystem.registerDatanode: node from name: xx.xx.xx.xx:50010
INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/xx.xx.xx.xx:50010
INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/xx.xx.xx.xx:50010
"
HADOOP-1193,Map/reduce job gets OutOfMemoryException when set map out to be compressed,One of my jobs quickly fails with the OutOfMemoryException when I set the map out to be compressed. But it worked fine with release 0.10.
HADOOP-1186,deadlock in Abstract Metrics Context,"There appears to be a lock-inversion deadlock in AbstractMetricsContext.

When using ganglia metrics, sometimes the jobtracker will start timing out requests.  The logs then reveal:

2007-03-30 13:59:50,942 WARN org.apache.hadoop.ipc.Server: Call queue overflow discarding oldest call heartbeat(org.apache.hadoop.mapred.Task
TrackerStatus@1c19919, false, true, 407) from 10.255.62.129:50215

A kill -QUIT dump shows:

""IPC Server handler 6 on 10001"" daemon prio=1 tid=0x08515c08 nid=0x526a waiting for monitor entry [0x4e6f4000..0x4e6f4f40]
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.createRecord(AbstractMetricsContext.java:192)
        - waiting to lock <0x5a562c98> (a org.apache.hadoop.metrics.ganglia.GangliaContext)
        at org.apache.hadoop.mapred.JobInProgress.<init>(JobInProgress.java:130)
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:1384)
        - locked <0x5a446330> (a org.apache.hadoop.mapred.JobTracker)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:336)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:559)
...
""Timer-0"" prio=1 tid=0x08664040 nid=0x5274 waiting for monitor entry [0x4e36d000..0x4e36df40]
        at org.apache.hadoop.mapred.JobTracker.getRunningJobs(JobTracker.java:944)
        - waiting to lock <0x5a446330> (a org.apache.hadoop.mapred.JobTracker)
        at org.apache.hadoop.mapred.JobTracker$JobTrackerMetrics.doUpdates(JobTracker.java:429)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.timerEvent(AbstractMetricsContext.java:275)
        - locked <0x5a562c98> (a org.apache.hadoop.metrics.ganglia.GangliaContext)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.access$000(AbstractMetricsContext.java:48)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext$1.run(AbstractMetricsContext.java:242)
        at java.util.TimerThread.mainLoop(Unknown Source)
        at java.util.TimerThread.run(Unknown Source)
"
HADOOP-1167,InMemoryFileSystem uses synchronizedtMaps with maps that are locked anyways,The InMemoryFileSystem uses synchronizedMaps and then guards each access to them by locking the FileSystem. There is also insufficient synchronization in create.
HADOOP-1140,Deadlock bug involving the o.a.h.metrics package,"Hi David,

Our nightly benchmarks are occasionally failing (2 to 4 of them per night) due to this deadlock in the JT that looks to be caused by Simon.  Do you have time to fix this in the morning?

Thanks,
Nige



Found one Java-level deadlock:
=============================
""expireLaunchingTasks"":
  waiting to lock monitor 0x08141b44 (object 0x57eafdd0, a org.apache.hadoop.mapred.JobTracker),
  which is held by ""IPC Server handler 8 on 50020""
""IPC Server handler 8 on 50020"":
  waiting to lock monitor 0x08141630 (object 0x57de46b8, a com.yahoo.simon.hadoop.metrics.SimonContext),
  which is held by ""Timer-0""
""Timer-0"":
  waiting to lock monitor 0x08141b44 (object 0x57eafdd0, a org.apache.hadoop.mapred.JobTracker),
  which is held by ""IPC Server handler 8 on 50020""

Java stack information for the threads listed above:
===================================================
""expireLaunchingTasks"":
        at org.apache.hadoop.mapred.JobTracker$ExpireLaunchingTasks.run(JobTracker.java:152)
        - waiting to lock <0x57eafdd0> (a org.apache.hadoop.mapred.JobTracker)
        at java.lang.Thread.run(Thread.java:619)
""IPC Server handler 8 on 50020"":
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.createRecord(AbstractMetricsContext.java:192)
        - waiting to lock <0x57de46b8> (a com.yahoo.simon.hadoop.metrics.SimonContext)
        at org.apache.hadoop.mapred.JobInProgress.<init>(JobInProgress.java:130)
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:1383)
        - locked <0x57eafdd0> (a org.apache.hadoop.mapred.JobTracker)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:336)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:559)
""Timer-0"":
        at org.apache.hadoop.mapred.JobTracker.getRunningJobs(JobTracker.java:943)
        - waiting to lock <0x57eafdd0> (a org.apache.hadoop.mapred.JobTracker)
        at org.apache.hadoop.mapred.JobTracker$JobTrackerMetrics.doUpdates(JobTracker.java:429)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.timerEvent(AbstractMetricsContext.java:275)
        - locked <0x57de46b8> (a com.yahoo.simon.hadoop.metrics.SimonContext)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.access$000(AbstractMetricsContext.java:48)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext$1.run(AbstractMetricsContext.java:242)
        at java.util.TimerThread.mainLoop(Timer.java:512)
        at java.util.TimerThread.run(Timer.java:462)

Found 1 deadlock. "
HADOOP-1129,The DFSClient hides IOExceptions in flush,"The DFS client uses a couple of classes that are extensions of FilterOutputStream that should override close, because the default close catches and ignores IOExceptions from flush."
HADOOP-1116,"Add maxmemory=""256m"" in the junit call of build-contrib.xml","When testing some very custom code, TestSymlink failed due to an OutOfMemoryError."
HADOOP-1112,Race condition in Hadoop metrics,"AbstractMetricsContext has non-synchronized accesses to the HashMap bufferedData.
"
HADOOP-1109,"Streaming, NPE when reading sequencefile ","When using StreamSequenceRecordReader, I get

java.lang.NullPointerException
	at org.apache.hadoop.streaming.StreamInputFormat.getRecordReader(StreamInputFormat.java:127)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:139)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1445)"
HADOOP-1091,  NPE from Simon in JT stdout ,"
Seen in JT std out:

Exception in thread ""Timer-0"" java.lang.NullPointerException
        at com.yahoo.simon.hadoop.metrics.Client.computeBlurbSize(Unknown Source)
        at com.yahoo.simon.hadoop.metrics.Client.sendBlurb(Unknown Source)
        at com.yahoo.simon.hadoop.metrics.SimonContext.emitRecord(Unknown Source)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.timerEvent(AbstractMetricsContext.java:295)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext.access$000(AbstractMetricsContext.java:48)
        at org.apache.hadoop.metrics.spi.AbstractMetricsContext$1.run(AbstractMetricsContext.java:242)
        at java.util.TimerThread.mainLoop(Timer.java:512)
        at java.util.TimerThread.run(Timer.java:462) 

There are (at least) two bugs:

   (1) o.a.h.metrics.MetricsRecord.setTag(String name, String value) will
   cause this problem to happen (later) if value==null.  It should treat a
   null value as equivalent to an empty string.
   (2) o.a.h.mapred.Counters.getGroupNames returns a collection which may
   be getting updated concurrently.  It needs to make a copy.
"
HADOOP-1077,Race condition in fetching map outputs (might lead to hung reduces),"Sometimes when a map task is lost while the map-output fetch is happening from the TT for that task, and the lost map has successfully executed on some other node, the event for that successful execution is lost at the fetching TT. The fetching TT might eventually fail to fetch the output for the lost task, but then since the event for the new run of the lost map might also have been lost, the fetching TT might hang.

This ""hung"" problem was discovered while working on HADOOP-1060."
HADOOP-1063,MiniDFSCluster exists a race condition that lead to data node resources are not properly released,"In MiniDFSCluster, there is a possibility that a data node gets shutted down before it is constructed. This leads to the situation that the data node's resources are not properly released. In Cygwin I observe that the data node directory is still kept locked after a miniDFSCluster is shut down."
HADOOP-1062,Checksum error in InMemoryFileSystem,"Getting the following error in the tasktracker log on 2 attempts:
2007-03-05 14:59:50,320 WARN  mapred.TaskRunner - task_0001_r_000005_0 Intermediate Merge of the inmemory files threw an exception: org.apache.hadoop.fs.ChecksumException: Checksum error: /trank/n
utch-0.9-dev/filesystem/mapred/local/task_0001_r_000005_0/map_2.out at 16776192
        at org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.verifySum(ChecksumFileSystem.java:250)
        at org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.readBuffer(ChecksumFileSystem.java:207)
        at org.apache.hadoop.fs.ChecksumFileSystem$FSInputChecker.read(ChecksumFileSystem.java:163)
        at org.apache.hadoop.fs.FSDataInputStream$PositionCache.read(FSDataInputStream.java:41)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
        at java.io.DataInputStream.readFully(DataInputStream.java:178)
        at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:57)
        at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:91)
        at org.apache.hadoop.io.SequenceFile$Reader.readBuffer(SequenceFile.java:1300)
        at org.apache.hadoop.io.SequenceFile$Reader.seekToCurrentValue(SequenceFile.java:1363)
        at org.apache.hadoop.io.SequenceFile$Reader.nextRawValue(SequenceFile.java:1656)
        at org.apache.hadoop.io.SequenceFile$Sorter$SegmentDescriptor.nextRawValue(SequenceFile.java:2579)
        at org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.next(SequenceFile.java:2351)
        at org.apache.hadoop.io.SequenceFile$Sorter.writeFile(SequenceFile.java:2226)
        at org.apache.hadoop.mapred.ReduceTaskRunner$InMemFSMergeThread.run(ReduceTaskRunner.java:820)

When I changed fs.inmemory.size.mb to 0 (was 75 - default) the reduce completes successfully.
Could it be related to HADOOP-1027 or HADOOP-1014?

- Espen"
HADOOP-1049,race condition in setting up ipc connections,"While running svn head, I get:

[junit] 2007-02-27 19:11:17,707 INFO  ipc.Client (Client.java:run(281)) - java.lang.NullPointerException
    [junit] 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:251)

There is a race condition between when the threads are created above and when the IO streams are set up below."
HADOOP-1035,StackOverflowError in FSDataSet,"[hadoop.org.apache.hadoop.dfs.DataNode] DataXCeiver
java.lang.StackOverflowError
at java.nio.ByteBuffer.wrap([BII)Ljava.nio.ByteBuffer;(Unknown Source)
at java.nio.ByteBuffer.wrap([B)Ljava.nio.ByteBuffer;(Unknown Source)
at java.lang.StringCoding$CharsetSE.encode([CII)[B(Unknown Source)
at java.lang.StringCoding.encode(Ljava.lang.String;[CII)[B(Unknown Source)
at java.lang.String.getBytes(Ljava.lang.String;)[B(Unknown Source)
at java.io.UnixFileSystem.rename0(Ljava.io.File;Ljava.io.File;)Z(Native Method)
at java.io.UnixFileSystem.rename(UnixFileSystem.java:265)
at java.io.File.renameTo(File.java:1192)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:89)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:105)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)
at org.apache.hadoop.dfs.FSDataset$FSDir.addBlock(FSDataset.java:95)

I do not have the end of the stacktrace, but it is sure it happens in DataNode.DataXceiver.writeBlock().

This error occurs after applying the patch provided in HADOOP-1034 that permits to see such exceptions in log files.
"
HADOOP-1012,OutOfMemoryError in reduce,"I'm seeing OutOfMemoryErrors from a reduce in each of DFSIO Benchmark and RandomWriter.  No stack traces are given.  Snipets from the TaskTracker logs are below.  I believe I first saw this on February 3rd during tests that I run weekly.

=====
DFSIO
=====
...
2007-02-10 18:25:20,201 INFO org.apache.hadoop.mapred.TaskRunner: task_0005_r_000000_0 Copying of all map outputs complete. Initiating the last merge on the remaining files in ramfs://mapoutput9105104
2007-02-10 18:25:20,771 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:21,773 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:23,280 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:24,607 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:25,960 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:27,105 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:28,982 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:29,984 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:31,481 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:33,379 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:34,478 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:35,656 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:36,758 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:42,593 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:43,600 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:46,573 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:48,791 INFO org.apache.hadoop.mapred.TaskTracker: task_0005_r_000000_0 0.33333334% reduce > copy (9000 of 9000 at 0.00 MB/s)
2007-02-10 18:25:49,828 WARN org.apache.hadoop.mapred.TaskRunner: Merge of the inmemory files threw an exception: java.lang.OutOfMemoryError: Java heap space
...

============
RandomWriter
============
...
2007-02-11 03:58:00,887 INFO org.apache.hadoop.mapred.TaskRunner: task_0001_r_000000_3 Copying of all map outputs complete. Initiating the last merge on the remaining files in ramfs://mapoutput6576294
2007-02-11 03:58:01,681 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:02,921 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:03,923 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:05,375 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:06,742 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:08,818 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:09,821 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:11,406 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:13,277 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:14,280 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:15,282 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:16,284 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:18,401 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:19,403 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:20,636 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:37,860 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000000_3 0.33333334% reduce > copy (8890 of 8890 at 0.00 MB/s)
2007-02-11 03:58:37,898 WARN org.apache.hadoop.mapred.TaskRunner: task_0001_r_000000_3 Child Error
java.lang.OutOfMemoryError: Java heap space
..."
HADOOP-1008,NPE in org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue,"I think this is the same issue as HADOOP-917

java.lang.NullPointerException
	at org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:2392)
	at org.apache.hadoop.io.SequenceFile$Sorter.merge(SequenceFile.java:2087)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:498)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:191)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1372)"
HADOOP-973,NPE in FSDataset during heavy Namenode load,"Running namenode delete benchmark, I saw many of these NPE's traces in a datanode log:

...
2007-02-04 16:17:53,744 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-949112377379974621
2007-02-04 16:17:53,744 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_748220495971269869
2007-02-04 16:17:54,619 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_658746956471887871
2007-02-04 16:17:56,752 ERROR org.apache.hadoop.dfs.DataNode: Exception: java.lang.NullPointerException
        at org.apache.hadoop.dfs.FSDataset.invalidate(FSDataset.java:519)
        at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:410)
        at org.apache.hadoop.dfs.DataNode.run(DataNode.java:1033)
        at java.lang.Thread.run(Thread.java:595)
2007-02-04 16:18:01,754 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3329089msec
2007-02-04 16:18:02,577 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1657305102826276927
2007-02-04 16:18:02,577 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_589129256174830133
..."
HADOOP-969,deadlock in job tracker RetireJobs,"The JobTracker deadlocks because RetireJobs grabs locks in the wrong order. The call stacks look like:

""IPC Server handler 5 on 50020"":
       at org.apache.hadoop.mapred.JobTracker.getNewTaskForTaskTracker(JobTracker.java:1108)
       - waiting to lock <0x74487a80> (a java.util.Vector)
       - locked <0x744874b0> (a org.apache.hadoop.mapred.JobTracker)
       at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:992)
       - locked <0x744874b0> (a org.apache.hadoop.mapred.JobTracker)
       at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
       at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
       at java.lang.reflect.Method.invoke(Method.java:585)
       at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:337)
       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:538)
""retireJobs"":
       at org.apache.hadoop.mapred.JobTracker.removeJobTasks(JobTracker.java:782)
       - waiting to lock <0x744874b0> (a org.apache.hadoop.mapred.JobTracker)
       at org.apache.hadoop.mapred.JobTracker.access$300(JobTracker.java:42)
       at org.apache.hadoop.mapred.JobTracker$RetireJobs.run(JobTracker.java:312)
       - locked <0x74487bb0> (a java.util.ArrayList)
       - locked <0x74487a80> (a java.util.Vector)
       - locked <0x74487a58> (a java.util.TreeMap)
       at java.lang.Thread.run(Thread.java:595)

Found 1 deadlock.

"
HADOOP-963,improve the stack trace returned by RPC client,"Currently, the RemoteException thrown from calls to RPCs include the stack trace from the RPC thread rather than the user's thread. "
HADOOP-917,NPE in org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue,"After nutch started using hadoop 0.10.1 the following Exception started to appear:

java.lang.NullPointerException
	at org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:2158)
	at org.apache.hadoop.io.SequenceFile$Sorter.merge(SequenceFile.java:1892)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:498)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:191)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1367)

Anyone know the cure?"
HADOOP-903,TestPread occasionally fails with exception trace mentioned below,"Impossible situation: could not find target position 8192 
java.io.IOException: Impossible situation: could not find target position 8192 
        at org.apache.hadoop.dfs.DFSClient$DFSInputStream.read(DFSClient.java:873) 
        at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:61) 
        at org.apache.hadoop.fs.FSDataInputStream$Checker.readFully(FSDataInputStream.java:155) 
        at org.apache.hadoop.fs.FSDataInputStream$PositionCache.readFully(FSDataInputStream.java:212) 
        at org.apache.hadoop.fs.FSDataInputStream$Buffer.readFully(FSDataInputStream.java:265) 
        at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:315) 
        at org.apache.hadoop.dfs.TestPread.pReadFile(TestPread.java:92) 
        at org.apache.hadoop.dfs.TestPread.testPreadDFS(TestPread.java:119)"
HADOOP-902,NPE in DFSOutputStream.closeBackupStream(),"After HADOOP-757 is checked in, Devraj noticed following NPE:

java.lang.NullPointerException
at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.closeBackupStream(DFSClient.java:972)
at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.endBlock(DFSClient.java:1219)
at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.flush(DFSClient.java:1181)
at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.write(DFSClient.java:1163)
at org.apache.hadoop.fs.FSDataOutputStream$Summer.write(FSDataOutputStream.java:85)
at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:114)
at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
at java.io.DataOutputStream.flush(DataOutputStream.java:106)
at java.io.FilterOutputStream.close(FilterOutputStream.java:140)
at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:558)
at org.apache.hadoop.mapred.SequenceFileOutputFormat$1.close(SequenceFileOutputFormat.java:72)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:331)
at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1367)

I will submit a patch after confirming its ok for backupStream to be null at this stage.
"
HADOOP-898,namenode generates infinite stream of null pointers,"My namenode is generating a constant stream of NullPointerExceptions. The log looks like:

2007-01-17 19:51:27,461 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3
on 50000 call error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.dfs.FSNamesystem.addStoredBlock(FSNamesystem.java:1621)
        at org.apache.hadoop.dfs.FSNamesystem.processReport(FSNamesystem.java:1563)
        at org.apache.hadoop.dfs.NameNode.blockReport(NameNode.java:573)
        at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:589)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:337)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:538)
"
HADOOP-875,memory model is not accurate enough for map side sorts,I configured a sort (IdentityMapper) with large compressed values with the map output buffer (io.sort.mb) set to 300mb and the child jvm heap size set to 900mb and some of the maps were running out of memory deterministically. I suspect that some part of the data path is not handling large values well and is consuming large amounts of ram.
HADOOP-849,randomwriter fails with 'java.lang.OutOfMemoryError: Java heap space' in the 'reduce' task,"Reproducible, tried to increase the child jvm's heapsize via 
<property>
  <name>mapred.child.java.opts</name>
  <value>-Xmx512m</value>
</property>

without any difference, still fails.

Need to investigate further."
HADOOP-815,Investigate and fix the extremely large memory-footprint of JobTracker,"The JobTracker's memory footprint seems excessively large, especially when many jobs are submitted.

Here is the 'top' output of a JobTracker which has scheduled ~1k jobs thus far:

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                     
31877 arunc     19   0 2362m 261m  13m S 14.0 12.9  24:48.08 java  

Clearly VIRTual memory of 2364Mb v/s 261Mb of RESident memory is symptomatic of this issue..."
HADOOP-803,Reducing memory consumption on Namenode : Part 1,"
There appears to be some places in Namenode that allow reducing memory consumption without intrusive code or feature changes. This bug is an initial attempt making those changes. Please include your thoughts as well. 

One change I am planning to make : 

Currently one copy of each block exists for each of the replicas and one copy for blockMap. I think they are all supposed to be same.
"
HADOOP-791,deadlock issue in taskstracker.,"the stack trace--
""main"":
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.createStatus(TaskTracker.java:880)
        - waiting to lock <0xea101658> (a org.apache.hadoop.mapred.TaskTracker$TaskInProgress)
        at org.apache.hadoop.mapred.TaskTracker.transmitHeartBeat(TaskTracker.java:489)
        - locked <0x75505f00> (a org.apache.hadoop.mapred.TaskTracker)
        at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:442)
        at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:720)
        at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:1374)
""taskCleanup"":
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.cleanup(TaskTracker.java:1072)
        - waiting to lock <0x75505f00> (a org.apache.hadoop.mapred.TaskTracker)
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.jobHasFinished(TaskTracker.java:1013)
        - locked <0xea101658> (a org.apache.hadoop.mapred.TaskTracker$TaskInProgress)
        at org.apache.hadoop.mapred.TaskTracker$1.run(TaskTracker.java:144)
        at java.lang.Thread.run(Thread.java:595)
Found 1 deadlock.

The jobhasfinished method and transmitHeart beat lock the tasktracker and tip in a different order. Also , before emitting HeartBeat we should be updating the status and removing entries from runningtasks. Currently this is done after the heartbeat."
HADOOP-782,"TaskTracker.java:killOverflowingTasks & TaskTracker.java:markUnresponsiveTasks only put the tip in tasksToCleanup queue, they don't update the runningJobs","Both killOverflowingTasks and markUnresponsiveTasks only put the tip in 'tasksToCleanup' queue, they should also call 'removeTaskFromJob' to update the 'runningJobs' map to reflect the fact that the task is no longer running. Thoughts?
"
HADOOP-764,The memory consumption of processReport() in the namenode can be reduced,"The FSNamesystem.processReport() method converts the blocklist for a datanode into an array by calling node.getBlocks(). Although this memory allocation is transient, it could possibly require the garbage-collector to work that much harder. 

The method Block.getBlocks() should be deprecated. Code that currently uses this method should instead iterate over the Collection."
HADOOP-750,race condition on stalled map output fetches,"I've seen reduces getting killed because of a race condition in the ReduceTaskRunner.  In the logs it looks like:

2006-11-27 08:40:44,795 WARN org.apache.hadoop.mapred.TaskRunner: Map output copy stalled on http://kry2296.inktomisearch.com:7030/mapOutput?map=task_0001_m_015626_0
...
2006-11-27 09:16:41,361 INFO org.apache.hadoop.mapred.TaskRunner: task_0001_r_000658_0 Need 52 map output(s)
2006-11-27 09:16:41,361 INFO org.apache.hadoop.mapred.TaskRunner: task_0001_r_000658_0 Got 39 known map output location(s); scheduling...
2006-11-27 09:16:41,361 INFO org.apache.hadoop.mapred.TaskRunner: task_0001_r_000658_0 Scheduled 0 of 39 known outputs (0 slow hosts and 39 dup hosts)
...
2006-11-27 09:16:47,071 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000658_0 0.3328575% reduce > copy (28679 of 28720 at 0.76 MB/s) >
...
2006-11-27 09:16:47,338 INFO org.apache.hadoop.mapred.TaskRunner: task_0001_r_000658_0 done copying task_0001_m_015462_0 output from node1
...
2006-11-27 09:36:51,398 INFO org.apache.hadoop.mapred.TaskTracker: task_0001_r_000658_0: Task failed to report status for 1204 seconds. Killing.

Basically, the handling of the stall has a race condition that leaves the fetcher in a bad state. At the end of the fetch, all of the tasks finish and their results never get handled. When the thread times out, all of the map output copiers are waiting for things to fetch and the prepare thread is waiting for results."
HADOOP-723,Race condition exists in the method MapOutputLocation.getFile,"There seems to be a race condition in the way the Reduces copy the map output files from the Maps. If a copier is blocked in the connect method (in the beginning of the method MapOutputLocation.getFile) to a Jetty on a Map, and the MapCopyLeaseChecker detects that the copier was idle for too long, it will go ahead and issue a interrupt (read 'kill') to this thread and create a new Copier thread. However, the copier, currently blocked trying to connect to Jetty on a Map, doesn't actually get killed until the connect timeout expires and as soon as the connect comes out (with an IOException), it will delete the map output file which actually could have been (successfully) created by the new Copier thread. This leads to the Sort phase for that reducer failing with a FileNotFoundException.
One simple way to fix this is to not delete the file if the file was not created within this getFile method."
HADOOP-695,Unexpected NPE from the next method of StreamLineRecordReader fails map/reduce jobs,"For some reason that I do not have much idea, if input of a map/reduce job is gzipped, an unexpected null pointer may be returned from UTF8ByteArrayUtils.readline in the next method of StreamLineRecordReader. However the pointer is read before a null pointer check is performed. Thus a NPE may be thrown and fail the job."
HADOOP-690,NPE in jobcontrol,"While running a few jobs I got this exception:

Exception in thread ""Thread-10"" java.lang.NullPointerException
        at org.apache.hadoop.mapred.jobcontrol.Job.checkRunningState(Job.java:246)
        at org.apache.hadoop.mapred.jobcontrol.Job.checkState(Job.java:264)
        at org.apache.hadoop.mapred.jobcontrol.JobControl.checkRunningJobs(JobControl.java:211)
        at org.apache.hadoop.mapred.jobcontrol.JobControl.run(JobControl.java:280)

It looks like this was just when all the jobs finished."
HADOOP-678, Investigate direct buffer leaks and fix them.,"
""direct memory"" leaks are suspected in NameNode running out of memory. At this point I don't have much more information.

Please add any info you have if you have looked in to NameNode memory. I am taking a look at Server.java in hadoop.ipc.
"
HADOOP-637,ipc.Server has memory leak -- serious issue for namenode server,"In my environment (running a lot of batch processes each of which reads, creates, and deletes a lof of  files in dfs) the namenode server can run out of memory rather quickly (in a few hours on a 150 node cluster). The netbeans profiler shows an increasing number of direct byte buffers not garbage collected. The documentation on java.nio.ByteBuffer indicates that their allocation might (and obviously does) happen outside the normal gc-collected heap, and, therefore, it is required that direct byte buffers should only be used for long-lived objects.

ipc.Server seems to use a 4KB direct byte buffer for every connection, but, worse, for every RPC call. If I replace the latter ones with non-direct byte buffers, the memory footprint of the namenode server increases only slowly, but even then it is just a matter of time (since I started it 24 hours ago, it leaked by about 300-400MB). If the performance increase by using direct buffers is a requirement, I would suggest to use a static pool.

Although my environment abuses the namenode server in unusual manner, I would imagine that the memory footprint of the namenode server creeps up slowly everywhere"
HADOOP-614,Sporadic TestEmptyJobWithDFS failure due to NPE is JobTracker.submitJob(),"org.apache.hadoop.mapred.TestEmptyJobWithDFS has failed a couple of times (low reproducibility) with the following exception:

2006-10-17 21:48:24,875 INFO  ipc.Server (Server.java:run(516)) - Server handler 2 on 50050 call error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:1020)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:385)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:514)

Complete test log attached."
HADOOP-600,Race condition in JobTracker updating the task tracker's status while declaring it lost,There was a case where the JobTracker lost track of a set of tasks that were on a task tracker. It appears to be a race condition because the ExpireTrackers thread doesn't lock the JobTracker while updating the state. The fix would be to build a list of dead task trackers and then lock the job tracker while updating their status.
HADOOP-570,"Map tasks may fail due to out of memory, if the number of reducers are moderately big","
Map tasks may fail due to out of memory, if the number of reducers are moderately big. 
In my case, I set child task heap size to 1GB, turned on compression for the mapoutput files. 
The average size of input records is about 30K (I don't know the variation though). 
A lot of map tasks failed due to out of memory when the number of reducers was at 400 and higher.
The number of reducers can be somewhat higher (as high as 800) if the compression for the mapoutput files was off).
This problem will impose a hard limit on the scalability of map/reduce clusters.

One possible solution to this problem is to let the mapper to write out single map output file, 
and then to perform sort/partition as a separate phrase. 
his will also make it unnecessary for  the reducers to perform sort on individual portions from mappers. 
Rather, the reducers should just perform merge operations on the map output files directly. 
This may even allow the possibility of dynamically collect some statistics of  the map outputs and 
use the stats to drive the partition on the mapper side, and obtain the optimal merge plan on the reducer side!
 "
HADOOP-487,misspelt DFS host name gives null pointer exception in getProtocolVersion,"I'm trying to construct a DistributedFileSystem but I have the wrong hostname.

It doesn't work.  It throws an exception.  Fair enough.  

However, it throws a null pointer exception inside $Proxy0.getProtocolVersion, the code that checks whether we have the right protocol version, rather than giving us any exception we could understand or taking an exception in code to which we have sources so we have a way of understanding the problem.

-dk
"
HADOOP-459,libhdfs leaks memory when writing to files,hdfsWrite leaks memory when called repeatedly. The same probably applies to repeated reads using hdfsRead
HADOOP-458,libhdfs corrupts memory,"in getJNIEnv() not enough space for optHadoopClassPath is allocated, corrupting the memory."
HADOOP-358,NPE in Path.equals,"An NPE is raised in Path.equals when testing the method with two unequal pathes and with the first one having no drive.

This is due to operator precedence: && has a higher priority level than ?:

See http://java.sun.com/docs/books/tutorial/java/nutsandbolts/expressions.html

See attached patch (just added some parenthesis and a testcase)."
HADOOP-316,job tracker has a deadlock,"The JobTracker has a deadlock in the ExpireLaunchingTasks stuff.

In particular, it locks the JobTracker and launchingTasks inconsistently.

This deadlocks has been observed in the wild and causes the JobTracker to stop responding to rpc and http (other than the root page)."
HADOOP-287,Speed up SequenceFile sort with memory reduction,I replaced the merge sort with a quick sort and it yielded approx 30% improvement in sort time. It also reduced the memory requirement for sorting because the sort is done in place.
HADOOP-277,Race condition in Configuration.getLocalPath(),"(attached: a patch to fix the problem, and a logfile showing the problem occuring twice)

There is a race condition in Configuration.java:

       Path file = new Path(dirs[index], path);
       Path dir = file.getParent();
       if (fs.exists(dir) || fs.mkdirs(dir)) {
         return file;

If two threads simultaneously process this code with the same target directory, fs.exists() will return false, but from fs.mkdirs() only one of the two threads will return true. From the Java documentation:
 ""returns: true if and only if the directory was created, along with all necessary parent directories; false otherwise""

That is, if the first thread successfully creates the directory, the second will not, and therefore return false, even though the directory exists.

This was really happening. We use four temporary directories, and we had reducers failing all over the place with  bizarre impossible errors. I modified the ReduceTaskRunner to output the filename that it creates to find the problem, and the log output is below.

Here you can see copies initiated for two files that hash to the same temp directory, simultaneously. map_4.out is created in the correct directory (/data2...), but map_15.out is created in the next directory (/data3...) becuase of this race condition. Minutes later, when the appender tries to locate the file, that race condition does not occur (the directory already exists), and the appender looks for the file map_15.out in the correct directory, where it does not exist.

060605 142414 task_0001_r_000009_1 Copying task_0001_m_000004_0 output from rmr05.
060605 142414 task_0001_r_000009_1 Copying task_0001_m_000015_0 output from rmr04.
...
060605 142416 task_0001_r_000009_1 done copying task_0001_m_000004_0 output from rmr05 into /data2/tmp/mapred/local/task_0001_r_000009_1/map_4.out
...
060605 142418 task_0001_r_000009_1 done copying task_0001_m_000015_0 output from rmr04 into /data3/tmp/mapred/local/task_0001_r_000009_1/map_15.out
...
060605 142531 task_0001_r_000009_1 0.31808624% reduce > append > /data2/tmp/mapred/local/task_0001_r_000009_1/map_4.out
...
060605 142725 task_0001_r_000009_1 java.io.FileNotFoundException: /data2/tmp/mapred/local/task_0001_r_000009_1/map_15.out


"
HADOOP-270,possible deadlock when shut down a datanode thread,"The DataNode class provides a method ""shutdown"" that can be used to notify a data node thread to abort itself gracefully. In addition this method waits for its data receiving server to terminate. This may cause possible deadlock if the method is called by the data receiving server."
HADOOP-219,SequenceFile#handleChecksumException NPE,"The SequenceFile#handleChecksumException assumes the conf data member has been set.  It will not be set if we use the 'Reader(FileSystem fs, Path file, int bufferSize, long start, long length)' constructor.  The latter is used by ReduceTask Sorter:


java.lang.NullPointerException
	at org.apache.hadoop.io.SequenceFile$Reader.handleChecksumException(SequenceFile.java:407)
	at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:400)
	at org.apache.hadoop.io.SequenceFile$Sorter$MergeStream.next(SequenceFile.java:837)
	at org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:881)
	at org.apache.hadoop.io.SequenceFile$Sorter$MergePass.run(SequenceFile.java:766)
	at org.apache.hadoop.io.SequenceFile$Sorter.mergePass(SequenceFile.java:702)
	at org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:528)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:253)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:787)
"
HADOOP-151,RPC code has socket leak?,"In RPC.java, the field named CLIENT should be neither static, nor a field of RPC. It should be (a) a private nonstatic field of InvocationHandler(),and (just further down), (b) a local variable in the RPC.call() method below.  The comment above the declaration was a bit of giveaway: 

   //TODO mb@media-style.com: static client or non-static client?
  private static Client CLIENT;	

  private static class Invoker implements InvocationHandler {
    private InetSocketAddress address;

    public Invoker(InetSocketAddress address, Configuration conf) {
      this.address = address;
      CLIENT = (Client) conf.getObject(Client.class.getName());
      if(CLIENT == null) {
          CLIENT = new Client(ObjectWritable.class, conf);
          conf.setObject(Client.class.getName(), CLIENT);
      }
    }

    public Object invoke(Object proxy, Method method, Object[] args)
      throws Throwable {
      ObjectWritable value = (ObjectWritable)
        CLIENT.call(new Invocation(method, args), address);
      return value.get();
    }
  }

  /** Construct a client-side proxy object that implements the named protocol,
   * talking to a server at the named address. */
  public static Object getProxy(Class protocol, InetSocketAddress addr, Configuration conf) {
    return Proxy.newProxyInstance(protocol.getClassLoader(),
                                  new Class[] { protocol },
                                  new Invoker(addr, conf));
  }

  /** Expert: Make multiple, parallel calls to a set of servers. */
  public static Object[] call(Method method, Object[][] params,
                              InetSocketAddress[] addrs, Configuration conf)
    throws IOException {

    Invocation[] invocations = new Invocation[params.length];
    for (int i = 0; i < params.length; i++)
      invocations[i] = new Invocation(method, params[i]);
    CLIENT = (Client) conf.getObject(Client.class.getName());
    if(CLIENT == null) {
        CLIENT = new Client(ObjectWritable.class, conf);
        conf.setObject(Client.class.getName(), CLIENT);
    }
    Writable[] wrappedValues = CLIENT.call(invocations, addrs);
    
    if (method.getReturnType() == Void.TYPE) {
      return null;
    }

    Object[] values =
      (Object[])Array.newInstance(method.getReturnType(),wrappedValues.length);
    for (int i = 0; i < values.length; i++)
      if (wrappedValues[i] != null)
        values[i] = ((ObjectWritable)wrappedValues[i]).get();
    
    return values;
  }. 
"
HADOOP-139,Deadlock in LocalFileSystem lock/release,"LocalFileSystem lock/release methods marked synchronized and inside they lock file channel - this produces deadlock situation. Let's see how it happens: 
1. First thread locks the file and starts some long-running process.
2. Second thread tries to lock the file and it blocks inside channel lock method. It  keeps LocalFileSystem instance ""locked"" as well. 
3. First thread finished it's processing and tries to release lock - it blocks because LocalFileSystem instance is ""locked"" by second thread - both threads are waiting to each other. 
"
HADOOP-135,Potential deadlock in JobTracker.,"org.apache.hadoop.mapred.JobTracker.RetireJobs.run()
locks resources in this order
                synchronized (jobs) {
                    synchronized (jobInitQueue) {
                        synchronized (jobsByArrival) {

org.apache.hadoop.mapred.JobTracker.submitJob()
locks resources in a different order
        synchronized (jobs) {
            synchronized (jobsByArrival) {
                synchronized (jobInitQueue) {

This potentially can lead to a deadlock.
Unless there is common lock on top of it in which case these
three locks are redundant."
HADOOP-69,Unchecked lookup value causes NPE in FSNamesystemgetDatanodeHints,
HADOOP-64,DataNode should be capable of managing multiple volumes,"The dfs Datanode can only store data on a single filesystem volume. When a node runs its disks JBOD this means running a Datanode per disk on the machine. While the scheme works reasonably well on small clusters, on larger installations (several 100 nodes) it implies a very large number of Datanodes with associated management overhead in the Namenode.

The Datanod should be enhanced to be able to handle multiple volumes on a single machine."
HADOOP-44,RPC exceptions should include remote stack trace,"Remote exceptions currently only report the exception string.  Instead they should report the entire remote stack trace, as a string, to facilitate debugging."
